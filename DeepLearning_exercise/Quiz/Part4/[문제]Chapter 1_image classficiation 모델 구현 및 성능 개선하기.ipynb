{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"image classficiation 모델 구현 및 성능 개선하기(문제수정).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMJfJRcqY+kY3878HuG7tTQ"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"S-EygPkLZGHO"},"source":["# 주제: CNN을 이용한 Image Classification 구현하고 성능 개선하기"]},{"cell_type":"markdown","metadata":{"id":"eTnghmuFBrEQ"},"source":["## 실습 가이드\n","    1. 데이터를 다운로드하여 Colab에 불러옵니다.\n","    2. 필요한 라이브러리는 import 가능합니다.\n","    3. 코드는 위에서부터 아래로 순서대로 실행합니다.\n","\n","## 데이터 소개\n","    - 이번 주제는 Intel image classification dataset을 사용합니다.\n","    - Intel image classification dataset은 buildings, forest, mountains, glacier, sea, street 6개의 class로 구성되어 있습니다.\n","    - 파일은 하나의 압축파일로 구성되며 압축파일은 다음과 같이 구성되어 있습니다.\n","    - 모든 데이터는 각 class 이름에 해당되는 directory 아래에 있습니다.    \n","\n","    1. seg_train\n","      - training용 data\n","      \n","    2. seg_test\n","      - test/validation용 data\n","      - label 있음\n","      - 이번 실습에서는 validation data로 사용\n","\n","    3. set_pred\n","      - test용 data\n","      - label 없음\n","      - 이번 실습에서는 사용하지 않음\n","\n","- 원본 데이터 출처: https://www.kaggle.com/puneet6060/intel-image-classification\n","\n","## 문제 소개\n","    - 이번 실습에서는 image classification model을 만들어서 학습하고, 성능을 향상하기 위한 방법들을 찾아서 학습해보도록 하겠습니다.\n","\n","## 최종 목표    \n","    - pre-trained CNN 활용 방법 이해\n","    - CNN의 성능을 올리기 위한 다양한 방법 습득\n","\n","- 출제자: 이진원 강사"]},{"cell_type":"markdown","metadata":{"id":"6WdJtwIxbcO8"},"source":["## Step 1. 데이터 다운로드 및 전처리"]},{"cell_type":"code","metadata":{"id":"XCKaEggRYUp3"},"source":["## library를 import 합니다\n","## 추가로 필요한 library가 있으면 추가로 import 해도 좋습니다\n","import os\n","import numpy as np\n","import random\n","from datetime import datetime\n","import time\n","import math\n","import gdown\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.applications import *\n","from tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D, Softmax\n","\n","AUTOTUNE = tf.data.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DeRxJjJeK-r"},"source":["## Hyper-Parameter 설정\n","# image resolution\n","RES = 224\n","# class 수 \n","N_CLASS = 6\n","# batch size\n","N_BATCH = 64\n","# epoch 수\n","N_EPOCH = 50\n","# learning rate\n","LR = 0.0001"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGwb0M49Fi8w"},"source":["### 문제 1. 데이터 불러오기\n","\n","    - data는 아래 url(google drive)에 저장되어 있습니다.(tar 파일)\n","    - gdown library를 이용하여 data를 다운받고, 현재 directory에 tar파일 압축을 풀어줍니다.\n","    "]},{"cell_type":"code","metadata":{"id":"RpjjjdrcblT7"},"source":["data_url = 'https://drive.google.com/uc?id=1bDyPlWP3AczXJbBmmjSGuAJXY7R_IjeJ'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zh9d9_JVdVt6"},"source":["## data download 받기(gdown.download 사용)\n","##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0KojmocCQ4GB"},"source":["    - 아래와 같이 train dataset은 train_dir, validation dataset은 val_dir로 경로를 설정합니다"]},{"cell_type":"code","metadata":{"id":"gqUqA9w4dltR"},"source":["data_dir = \".\"\n","train_dir = os.path.join(data_dir, 'seg_train', 'seg_train')\n","val_dir = os.path.join(data_dir, 'seg_test', 'seg_test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9htihLMRSzB"},"source":["!ls $train_dir"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DejhR8haRDKR"},"source":["### 문제 2. dataset 만들기\n","    - keras.preprocessing.image_dataset_from_directory를 이용하여 training용 dataset(이름: train_ds), validation용 dataset(이름: val_ds)를 만듭니다.\n","    - 위 hyperparameter를 참조하여 image_size와 batch_size를 설정합니다.\n","    - training data는 shuffle=True로 설정합니다."]},{"cell_type":"code","metadata":{"id":"nl-K0s8NRBnn"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBH2toe4YeDn"},"source":["### 문제 3. training data, validation data 갯수 확인\n","    - 위 dataset 생성시에 나오는 log에서 training data와 validation data의 갯수를 확인하여, 각각 N_TRAIN, N_VAL 변수에 저장합니다."]},{"cell_type":"code","metadata":{"id":"VCEqnjkfYD8n"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_1kec2ZYuqn"},"source":["### 문제 4. class list 만들기\n","    - class 이름을 저장하고 있는 list를 생성합니다"]},{"cell_type":"code","metadata":{"id":"rHvou1tSYYlW"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vSCqI6QsZHm3"},"source":["    - data 공급 속도를 빠르게 하기 위하여 dataset에 prefetch를 적용합니다"]},{"cell_type":"code","metadata":{"id":"7nh3O8ZcY5PO"},"source":["train_ds = train_ds.prefetch(AUTOTUNE)\n","val_ds = val_ds.prefetch(AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkVQc9jWZQA_"},"source":["### 문제 5. dataset 확인하기\n","    - train_ds에서 batch를 5개 읽어와서 각 batch의 첫번째 image를 화면에 출력합니다.\n","    - 위 class list에서 image에 대한 label을 찾아서 title로 넣습니다."]},{"cell_type":"code","metadata":{"id":"n29C9LzPZM2O"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rZvDgAjZoPnQ"},"source":["## Step 2. Pretrained MobileNetV3로 Training 하기\n","이번 Step에서는 MobileNetV3를 이용하여 image classification을 학습해보겠습니다."]},{"cell_type":"markdown","metadata":{"id":"y4q152ifrbUm"},"source":["    - pretrained MobileNetV3는 tensorflow.keras.applications에서 기본으로 제공합니다.\n","    - 아래와 같이 pretrained MobileNetV3 model을 다운받습니다.\n","  "]},{"cell_type":"code","metadata":{"id":"APX32Os3n-t1"},"source":["from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n","mobilenetv3 = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(RES, RES, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3aj4YpI6_xXH"},"source":["mobilenetv3.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5g7Zz42z-Tfz"},"source":["### 문제 6. Intel image classification을 위한 MobileNetV3 model 만들기    \n","    - functional API를 활용하여 6개의 class를 classification하는 model을 만들어봅시다.\n","    - fully connected layer는 1개만 추가하고, batchnorm을 사용합니다.\n","    - MobileNetV3에 data가 들어가기 전에 preprocess_input을 적용하여 input data가 preprocessing될 수 있도록 합니다."]},{"cell_type":"code","metadata":{"id":"pmeNCzT2GUAU"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQyHvNatEdA7"},"source":["  ### 문제 7. 학습하기\n","    - SGD를 사용하여 model을 학습합니다.(총 epoch수는 N_EPOCH으로 설정)\n","    - learning rate은 위에서 정한 hyperparameter(LR)을 사용합니다.\n","    - loss는 cross entropy를 사용합니다."]},{"cell_type":"code","metadata":{"id":"qQq1e6wMEWXo"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eSPTMXbZGVzv"},"source":["### 문제 8. Optimizer 변경하기\n","    - 같은 model에서 optimizer만 Adam으로 변경하여 학습해봅시다."]},{"cell_type":"code","metadata":{"id":"sqDaT0MZIByY"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XzYQv0x4kq8Q"},"source":["## Step3. Model 성능 올리기\n","\n","이번 Step에서는 다양한 방법을 사용하여 MobileNetV3의 성능을 올려보도록 하겠습니다."]},{"cell_type":"markdown","metadata":{"id":"bwjLGPIMm2k4"},"source":["### 문제 9. Data augmentation 사용하기\n","    - training data에 data augmentation을 적용해봅시다.\n","    - dataset을 만들 때 training data를 256x256으로 resize합니다.\n","    - augmentation function을 만들고, 224x224로 random crop합니다.\n","    - horizontal flip도 random으로 적용합니다.\n","    - augmentation을 하였으므로 training epoch을 100으로 키웁니다.\n","    - optimizer와 다른 hyperparameter는 수정하지 않고 training합니다."]},{"cell_type":"code","metadata":{"id":"5JSse9y1rF7K"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nYhAKZuCeUt"},"source":["### 문제 10. cutmix 알고리즘 구현을 위한 dataset 재생성\n","    - data augmentation 방법 중 하나인 cutmix를 구현해봅시다.\n","    - 논문은 https://arxiv.org/abs/1905.04899 에서 확인할 수 있습니다.\n","    - 알고리즘에 대한 간략한 설명은 맨 첫부분에 이론강의로 제공되니, 강의를 시청하고 문제를 푸는 것도 좋습니다.\n","\n","    - cutmix를 위해서는 사전에 label이 one-hot encoding되어 있어야 하므로, dataset을 수정하여 label이 one-hot이 되도록 합니다."]},{"cell_type":"code","metadata":{"id":"XUvIc3tsS0bI"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOZt8-8PURqn"},"source":["    - 아래 코드를 실행하여 제대로 one-hot encoding이 되어있는지 확인해봅시다"]},{"cell_type":"code","metadata":{"id":"qcpzaJVKUL5I"},"source":["for images, labels in train_ds.take(1):  \n","  print(labels[0].numpy())\n","for images, labels in val_ds.take(1):  \n","  print(labels[0].numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0P-Pq7FmUgoo"},"source":["### 문제 11. cutmix 알고리즘 구현\n","    - cutmix 알고리즘을 구현해봅시다.\n","    - cutmix라는 함수를 만들어서 구현합니다.\n","    - 위에서 생성한 dataset에 map으로 적용할 수 있도록 images, labels를 입력으로 받습니다."]},{"cell_type":"code","metadata":{"id":"UJfX3qHr04Zz"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VkXMEWCEUwxY"},"source":["### 문제 12. cutmix 적용 및 확인\n","    - 작성한 cutmix 알고리즘을 train_ds에 적용하고, 문제 5에서와 같이 확인해봅니다.\n","    - 앞에서 적용했던 random crop과 random flip도 함께 적용합니다."]},{"cell_type":"code","metadata":{"id":"EOZ-1I6iUvaV"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpAigjp6WoTf"},"source":["### 문제 13. cutmix 적용하여 training\n","    - model을 새로 생성하고 학습하여 결과를 확인해봅시다.\n","    - 다른 hyperparameter는 이전과 동일하게 하여 결과를 비교해봅시다."]},{"cell_type":"code","metadata":{"id":"QSho-qiAXKDr"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PXqBeSbnjIXE"},"source":["### 문제 14. Bigger resolution\n","    - input image resolution을 320x320으로 키워봅시다.\n","    - random crop을 적용하기 전 resolution은 330x330으로 설정합니다.\n","    - resolution에 맞게 train_ds와 val_ds를 다시 생성하고, data augmentation을 동일하게 적용합니다.\n","\n","  "]},{"cell_type":"code","metadata":{"id":"f2-oT0MqjjU9"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rE224CVNc_CH"},"source":["### 문제 15. Learning rate warmup + cosine decay 구현하기\n","    - custom learning rate scheduler를 만들어서 warm up과 cosine anealing을 구현해봅시다.\n","    - max_lr, warmup_steps, decay_steps 세가지 항목을 입력을 받을 수 있도록 합니다. \n","    - max_lr은 최대 learning rate, warmup_steps는 warm up이 끝나는 step 수, decay steps는 cosine decay가 끝나는 step 수를 의미합니다.\n","    - keras.optimizers.schedules.LearningRateSchedule를 상속하여 subclass로 만듭니다.\n","    - 자세한 사항은 아래 링크들을 참고하시면 됩니다.\n","https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule\n","\n","https://www.tensorflow.org/tutorials/text/transformer"]},{"cell_type":"code","metadata":{"id":"JyN7qQHENGBL"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iJVDWpPeDyWE"},"source":["### 문제 16. Learning rate scheduling visualization\n","    - 위에서 작성한 learning rate scheduling class가 제대로 동작하는지 적당한 값을 넣고 graph를 그려서 확인해봅시다."]},{"cell_type":"code","metadata":{"id":"cNx1CF-ZEAYr"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ug28r-PUr_j9"},"source":["### 문제 17. Label smoothing 적용하여 학습하기\n","    - 위에서 새로 적용한 모든 것들(resolution, epoch 수, learning rate scheduling)을 다 반영하고, label smoothing까지 적용하여 학습해봅시다.\n","    - max_lr은 LR로, warmup_steps는 3 epoch에 해당하는 step수, decay_steps는 N_EPOCH에 해당하는 step수만큼으로 설정합니다.\n","    - label smoothing 값은 0.1로 설정합니다."]},{"cell_type":"code","metadata":{"id":"VdzS5bDIz6ud"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l6VD1O3EtwaZ"},"source":["### 문제 18. Learning rate decay(계단식) 적용하여 학습하기\n","    - 계단식으로 learning rate decay를 적용해봅시다.\n","    - 매 30 epoch마다 1/10로 learning rate을 decay 시키도록 하여 학습해봅시다.\n","    - 구현은 keras.optimizers.schedules.ExponentialDecay API를 활용합니다.\n","https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay"]},{"cell_type":"code","metadata":{"id":"EhE7yLteyp2z"},"source":["##### CODE HERE #####"],"execution_count":null,"outputs":[]}]}