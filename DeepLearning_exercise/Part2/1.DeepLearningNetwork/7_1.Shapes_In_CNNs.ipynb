{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-1: Shapes in CNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-1: Shapes in the Feature Extrators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28, 3)\n",
      "After conv1: (32, 28, 28, 5)\n",
      "W/B: (3, 3, 3, 5)/(5,)\n",
      "After conv1_pool: (32, 14, 14, 5)\n",
      "After conv2: (32, 14, 14, 5)\n",
      "W/B: (3, 3, 5, 5)/(5,)\n",
      "After conv2_pool: (32, 7, 7, 5)\n",
      "After flatten: (32, 245)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 3\n",
    "n_conv_filters = 5\n",
    "k_size = 3\n",
    "pool_size, pool_strides = 2, 2\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "conv1 = Conv2D(filters = n_conv_filters, kernel_size = k_size,\n",
    "               padding = 'same', activation = 'relu')\n",
    "conv1_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "\n",
    "conv2 = Conv2D(filters = n_conv_filters, kernel_size = k_size,\n",
    "               padding = 'same', activation = 'relu')\n",
    "conv2_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "print(\"Input: {}\".format(x.shape))\n",
    "# Input: (32, 28, 28, 3)\n",
    "\n",
    "\n",
    "x = conv1(x)\n",
    "print(\"After conv1: {}\".format(x.shape))\n",
    "# After conv1: (32, 28, 28, 5) : same padding 으로 설정했기 떄문에 W, H값이 바뀌지 않지만 \n",
    "#                               filter 갯수가 5개 였기 떄문에 5채널로 바뀜\n",
    "W, B = conv1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "\n",
    "x = conv1_pool(x)\n",
    "print(\"After conv1_pool: {}\".format(x.shape))\n",
    "# After conv1_pool: (32, 14, 14, 5) \n",
    "\n",
    "\n",
    "x = conv2(x)\n",
    "print(\"After conv2: {}\".format(x.shape))\n",
    "\n",
    "W, B = conv2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "\n",
    "x = conv2_pool(x)\n",
    "print(\"After conv2_pool: {}\".format(x.shape))\n",
    "\n",
    "x = flatten(x)\n",
    "print(\"After flatten: {}\".format(x.shape))\n",
    "# After flatten: (32, 245)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-2: Shapes in the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature : (25, 28, 28, 3)\n",
      "W/B: (3, 50)/(50,)\n",
      "After dense1: (25, 28, 28, 50)\n",
      "W/B: (50, 25)/(25,)\n",
      "After dense2: (25, 28, 28, 25)\n",
      "W/B: (25, 10)/(10,)\n",
      "After dense3: (25, 28, 28, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 3\n",
    "\n",
    "n_neurons = [50, 25, 10]\n",
    "dense1 = Dense(units = n_neurons[0], activation = 'relu')\n",
    "dense2 = Dense(units = n_neurons[1], activation = 'relu')\n",
    "dense3 = Dense(units = n_neurons[2], activation = 'softmax')\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "print(\"Input feature : {}\".format(x.shape))\n",
    "x = dense1(x)\n",
    "W, B = dense1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense1: {}\".format(x.shape))\n",
    "\n",
    "x = dense2(x)\n",
    "W, B = dense2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense2: {}\".format(x.shape))\n",
    "\n",
    "x = dense3(x)\n",
    "W, B = dense3.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense3: {}\".format(x.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-3: Shapes in the Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "tf.Tensor(2.3876739, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "y = tf.random.uniform(minval = 0, maxval = 10,\n",
    "                      shape = (32, ),\n",
    "                      dtype = tf.int32)\n",
    "\n",
    "y = tf.one_hot(y, depth = 10)\n",
    "# print(y)\n",
    "\n",
    "loss_object = CategoricalCrossentropy()\n",
    "loss = loss_object(y, x)\n",
    "print(loss.shape)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
