{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-3 : Activation Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code. 1-3-1: Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (1, 5)\n",
      "[[-1.3544159   0.7045493   0.03666191  0.86918795  0.43842277]]\n",
      "Sigmoid(Tensorflow): (1, 5)\n",
      "[[0.20514935 0.6691957  0.5091645  0.70457673 0.6078832 ]]\n",
      "\n",
      "Sigmoid(man): (1, 5)\n",
      "[[0.20514935 0.6691957  0.5091645  0.70457673 0.6078832 ]]\n",
      "\n",
      "Tanh(Tensorflow): (1, 5)\n",
      "[[-0.87509155  0.6072475   0.03664547  0.7009613   0.41233623]]\n",
      "\n",
      "Tanh(man): (1, 5)\n",
      "[[-0.8750916   0.60724753  0.03664549  0.7009614   0.41233623]]\n",
      "\n",
      "ReLu(Tensorflow): (1, 5)\n",
      "[[0.         0.7045493  0.03666191 0.86918795 0.43842277]]\n",
      "\n",
      "ReLu(man): (1, 5)\n",
      "[[0.         0.7045493  0.03666191 0.86918795 0.43842277]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "x = tf.random.normal(shape=(1,5)) # input setting\n",
    "\n",
    "#imp. activation function\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "# forward propagation\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "\n",
    "# forward propagation(manual)\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
    "y_relu_man = maximum(0, x)\n",
    "\n",
    "print(\"x: {}\\n{}\".format(x.shape, x.numpy()))\n",
    "print(\"Sigmoid(Tensorflow): {}\\n{}\\n\".format(y_sigmoid_tf.shape, y_sigmoid_tf.numpy()))\n",
    "print(\"Sigmoid(man): {}\\n{}\\n\".format(y_sigmoid_man.shape, y_sigmoid_man.numpy()))\n",
    "\n",
    "print(\"Tanh(Tensorflow): {}\\n{}\\n\".format(y_tanh_tf.shape, y_tanh_tf.numpy()))\n",
    "print(\"Tanh(man): {}\\n{}\\n\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n",
    "\n",
    "print(\"ReLu(Tensorflow): {}\\n{}\\n\".format(y_relu_tf.shape, y_relu_tf.numpy()))\n",
    "print(\"ReLu(man): {}\\n{}\\n\".format(y_relu_man.shape, y_relu_man.numpy()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code. 1-3-2: Activation in Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN with Sigmoid: (1, 1)\n",
      "[[0.6933557]]\n",
      "AN with Tanh: (1, 1)\n",
      "[[-0.9479435]]\n",
      "AN with ReLU: (1, 1)\n",
      "[[0.]]\n",
      "\n",
      "============================================================\n",
      "\n",
      "Activation value(Tensorflow): (1, 1)\n",
      "[[0.6933557]]\n",
      "Activation value(manual): (1, 1)\n",
      "[[0.6933557]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "x = tf.random.normal(shape=(1, 5)) # input setting\n",
    "\n",
    "# imp. artificial neurons\n",
    "dense_sigmoid = Dense(units = 1, activation = 'sigmoid')\n",
    "dense_tanh = Dense(units = 1, activation = 'tanh')\n",
    "dense_relu = Dense(units = 1, activation = 'relu')\n",
    "\n",
    "# forward propagation\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "\n",
    "# forward propagation(tensorflow)\n",
    "print(\"AN with Sigmoid: {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
    "\n",
    "print(\"AN with Tanh: {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
    "\n",
    "print(\"AN with ReLU: {}\\n{}\".format(y_relu.shape, y_relu.numpy()))\n",
    "\n",
    "# forward propagation(manual)\n",
    "print(\"\\n============================================================\\n\")\n",
    "\n",
    "W, B = dense_sigmoid.get_weights()\n",
    "z = tf.linalg.matmul(x, W) + B\n",
    "a = 1 / (1 + exp(-z))\n",
    "\n",
    "print(\"Activation value(Tensorflow): {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
    "print(\"Activation value(manual): {}\\n{}\".format(a.shape, a.numpy()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code. 1-4-1: Artificial Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation:  relu\n",
      "y_tf: (1, 1)\n",
      "[[0.4924237]]\n",
      "\n",
      "y_man: (1, 1)\n",
      "[[0.4924237]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "# activation = 'sigmoid'\n",
    "# activation = 'tanh'\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10)) # input setting\n",
    "\n",
    "dense = Dense(units = 1, activation=activation) # imp. an affine + activation\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "# calculate activation value manually\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "if activation == 'sigmoid':\n",
    "    y_man = 1 / (1 + exp(-y_man))\n",
    "\n",
    "elif activation == 'tanh':\n",
    "    y_man = (exp(y_man) - exp(-y_man)) / (exp(y_man) + exp(-y_man))\n",
    "\n",
    "elif activation == 'relu':\n",
    "    y_man = maximum(0, y_man)\n",
    "    \n",
    "print('Activation: ', activation)\n",
    "print('y_tf: {}\\n{}\\n'.format(y_tf.shape, y_tf.numpy()))\n",
    "print('y_man: {}\\n{}\\n'.format(y_man.shape, y_man.numpy()))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-5 : Minibatches"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code. 1-5-1: Shapes of Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 10)\n",
      "Shape of x: (8, 10)\n",
      "Shape of W: (10, 1)\n",
      "Shape of B: (1,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 8, 10 # set input parmas\n",
    "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
    "print(x.shape)\n",
    "\n",
    "dense = Dense(units = 1, activation = 'relu') # imp. an AN\n",
    "y = dense(x) # forward propagation\n",
    "\n",
    "W, B = dense.get_weights() # get weight/bias\n",
    "\n",
    "# print result\n",
    "print(\"Shape of x: {}\".format(x.shape))\n",
    "print(\"Shape of W: {}\".format(W.shape))\n",
    "print(\"Shape of B: {}\".format(B.shape))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code. 1-5-2: Output Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape: \n",
      " (4, 1)\n",
      "Output(TF): \n",
      " [[0.25007227]\n",
      " [0.5523918 ]\n",
      " [0.8002374 ]]\n",
      "Output(MAN): \n",
      " [[0.25007227]\n",
      " [0.5523918 ]\n",
      " [0.8002374 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 3, 4 # set input parmas\n",
    "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
    "\n",
    "dense = Dense(units = 1, activation = 'sigmoid')\n",
    "y_tf = dense(x)\n",
    " \n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "y_man = 1 / (1 + exp(-y_man))\n",
    "\n",
    "print(\"W shape: \\n\", W.shape)\n",
    "print(\"Output(TF): \\n\",y_tf.numpy())\n",
    "print(\"Output(MAN): \\n\",y_man.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
