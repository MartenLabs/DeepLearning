{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-1: Shapes in CNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-1: Shapes in the Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (32, 28, 28, 3)\n",
      "After conv1: (32, 28, 28, 5)\n",
      "After conv1_pool:(32, 14, 14, 5)\n",
      "After conv2: (32, 14, 14, 5)\n",
      "W/B: (3, 3, 5, 5)/(5,)\n",
      "After conv2_pool: (32, 7, 7, 5)\n",
      "After flatten:(32, 245)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 3\n",
    "n_conv_filters = 5\n",
    "k_size = 3\n",
    "pool_size, pool_strides = 2, 2\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "conv1 = Conv2D(filters = n_conv_filters, kernel_size = k_size,\n",
    "               padding = 'same', activation = 'relu')\n",
    "conv1_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "\n",
    "\n",
    "\n",
    "conv2 = Conv2D(filters = n_conv_filters, kernel_size = k_size,\n",
    "               padding = 'same', activation = 'relu')\n",
    "conv2_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "print(\"Input: {}\".format(x.shape))\n",
    "# Input: (32, 28, 28, 3)\n",
    "\n",
    "x = conv1(x)\n",
    "print(\"After conv1: {}\".format(x.shape))\n",
    "# After conv1: (32, 28, 28, 5) : same padding 으로 설정했기 떄문에 W, H값이 바뀌지 않지만 \n",
    "#                               filter 갯수가 5개 였기 떄문에 5채널로 바뀜\n",
    "x = conv1_pool(x)\n",
    "print(\"After conv1_pool:{}\".format(x.shape))\n",
    "# After conv1_pool:(32, 14, 14, 5)\n",
    "\n",
    "x = conv2(x)\n",
    "print(\"After conv2: {}\".format(x.shape))\n",
    "\n",
    "W, B = conv2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "\n",
    "x = conv2_pool(x)\n",
    "print(\"After conv2_pool: {}\".format(x.shape))\n",
    "\n",
    "x = flatten(x)\n",
    "print(\"After flatten:{}\".format(x.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-2: Shapes in the Calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature: (32, 245)\n",
      "W/B: (245, 50)/(50,)\n",
      "After dense1: (32, 50)\n",
      "W/B: (50, 25)/(25,)\n",
      "After dense2: (32, 25)\n",
      "W/B :(25, 10)/(10,)\n",
      "After dense3: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "\n",
    "n_neurons = [50, 25, 10]\n",
    "dense1 = Dense(units = n_neurons[0], activation = 'relu')\n",
    "dense2 = Dense(units = n_neurons[1], activation = 'relu')\n",
    "dense3 = Dense(units = n_neurons[2], activation = 'softmax')\n",
    "\n",
    "\n",
    "print(\"Input feature: {}\".format(x.shape))\n",
    "x = dense1(x)\n",
    "W, B = dense1.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense1: {}\".format(x.shape))\n",
    "\n",
    "x = dense2(x)\n",
    "W, B = dense2.get_weights()\n",
    "print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense2: {}\".format(x.shape))\n",
    "\n",
    "x = dense3(x)\n",
    "W, B = dense3.get_weights()\n",
    "print(\"W/B :{}/{}\".format(W.shape, B.shape))\n",
    "print(\"After dense3: {}\".format(x.shape))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-3: Shapes in the Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n",
      "()\n",
      "tf.Tensor(2.544219, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "\n",
    "y = tf.random.uniform(minval = 0, maxval = 10,\n",
    "                      shape = (32, ),\n",
    "                      dtype = tf.int32)\n",
    "\n",
    "y = tf.one_hot(y, depth = 10)\n",
    "print(y)\n",
    "\n",
    "loss_object = CategoricalCrossentropy()\n",
    "loss = loss_object(y, x)\n",
    "print(loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-1: Implementation of CNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-1: Implementation with Sequential Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 3)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation = 'relu'\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "print(x.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = n_conv_neurons[0], kernel_size = k_size, padding = padding,\n",
    "                 activation = activation))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = pool_strides))\n",
    "\n",
    "model.add(Conv2D(filters = n_conv_neurons[1], kernel_size = k_size, padding = padding,\n",
    "                 activation = activation))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = pool_strides))\n",
    "\n",
    "model.add(Conv2D(filters = n_conv_neurons[2], kernel_size = k_size, padding = padding,\n",
    "                 activation = activation))\n",
    "model.add(MaxPooling2D(pool_size = pool_size, strides = pool_strides))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = n_dense_neurons[0], activation = activation))\n",
    "model.add(Dense(units = n_dense_neurons[1], activation = activation))\n",
    "model.add(Dense(units = n_dense_neurons[2], activation = 'softmax'))\n",
    "\n",
    "predictions = model(x)\n",
    "print(predictions.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for n_conv_neurons in n_conv_neurons:\n",
    "    model.add(Conv2D(filters = n_conv_neurons, kernel_size = k_size, padding = padding,\n",
    "                     activation = activation))\n",
    "    model.add(MaxPooling2D(pool_size = pool_size, strides = pool_strides))\n",
    "model.add(Flatten())\n",
    "\n",
    "for n_dense_neuron in n_dense_neurons:\n",
    "    model.add(Dense(units = n_dense_neurons, activation = activation))\n",
    "model.add(Dense(units = n_dense_neuron[-1], activation = 'softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-2: Implementation with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28, 28, 3)\n",
      "(4, 28, 28, 10)\n",
      "(4, 14, 14, 10)\n",
      "(4, 14, 14, 20)\n",
      "(4, 7, 7, 20)\n",
      "(4, 7, 7, 30)\n",
      "(4, 3, 3, 30)\n",
      "(4, 270)\n",
      "(4, 50)\n",
      "(4, 30)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "\n",
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(filters = n_conv_neurons[0], kernel_size = k_size, padding = padding,\n",
    "                            activation = activation)\n",
    "        self.conv1_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        \n",
    "        self.conv2 = Conv2D(filters = n_conv_neurons[1], kernel_size = k_size, padding = padding,\n",
    "                            activation = activation)\n",
    "        self.conv2_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        \n",
    "        self.conv3 = Conv2D(filters = n_conv_neurons[2], kernel_size = k_size, padding = padding,\n",
    "                            activation = activation)\n",
    "        self.conv3_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units = n_dense_neurons[0], activation = activation)\n",
    "        self.dense2 = Dense(units = n_dense_neurons[1], activation = activation)\n",
    "        self.dense3 = Dense(units = n_dense_neurons[2], activation = 'softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv1_pool(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv2_pool(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print(x.shape)\n",
    "        x = self.conv3_pool(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        print(x.shape)\n",
    "        x = self.dense2(x)\n",
    "        print(x.shape)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation = 'relu'\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "model = TestCNN()\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-3: Implementation with Sequential + Layer Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense \n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters = n_neurons, kernel_size = k_size, padding = padding,\n",
    "                           activation = activation)\n",
    "        \n",
    "        self.conv_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "    \n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation = 'relu'\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(MyConv(n_conv_neurons[0]))\n",
    "model.add(MyConv(n_conv_neurons[1]))\n",
    "model.add(MyConv(n_conv_neurons[2]))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = n_dense_neurons[0], activation = activation))\n",
    "model.add(Dense(units = n_dense_neurons[1], activation = activation))\n",
    "model.add(Dense(units = n_dense_neurons[2], activation = 'softmax'))\n",
    "\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-1-4: Implementation with Model and Layer Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters = n_neurons, kernel_size = k_size, padding = padding,\n",
    "                           activation = activation)\n",
    "        self.conv_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "    \n",
    "        self.conv1 = MyConv(n_conv_neurons[0])\n",
    "        self.conv2 = MyConv(n_conv_neurons[1])\n",
    "        self.conv3 = MyConv(n_conv_neurons[2])\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units = n_dense_neurons[0], activation = activation)\n",
    "        self.dense2 = Dense(units = n_dense_neurons[1], activation = activation)\n",
    "        self.dense3 = Dense(units = n_dense_neurons[2], activation = 'softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "N, n_H, n_W, n_C = 4, 28, 28, 3\n",
    "n_conv_neurons = [10, 20, 30]\n",
    "n_dense_neurons = [50, 30, 10]\n",
    "k_size, padding = 3, 'same'\n",
    "activation = 'relu'\n",
    "pool_size, pool_strides = 2, 2\n",
    "\n",
    "x = tf.random.normal(shape = (N, n_H, n_W, n_C))\n",
    "\n",
    "model = TestCNN()\n",
    "y = model(x)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "class MyConv(Layer):\n",
    "    def __init__(self, n_neuron):\n",
    "        super(MyConv, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters = n_neuron, kernel_size = k_size, padding = padding,\n",
    "                           activation = activation)\n",
    "        \n",
    "        self.conv_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.conv_pool(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TestCNN(Model):\n",
    "    def __init__(self):\n",
    "        super(TestCNN, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = Sequential()\n",
    "        self.feature_extractor.add(MyConv(n_conv_neurons[0]))\n",
    "        self.feature_extractor.add(MyConv(n_conv_neurons[1]))\n",
    "        self.feature_extractor.add(MyConv(n_conv_neurons[2]))\n",
    "        self.feature_extractor.add(Flatten())\n",
    "        \n",
    "        self.classifier = Sequential()\n",
    "        self.classifier.add(Dense(units = n_dense_neurons[0], activation = activation))\n",
    "        self.classifier.add(Dense(units = n_dense_neurons[1], activation = activation))\n",
    "        self.classifier.add(Dense(units = n_dense_neurons[2], activation = 'softmax'))\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = TestCNN()\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-2: Implementation of LeNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-2-1: LeNet with Model Sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "(32, 28, 28, 1)\n",
      "\n",
      "conv1 x \n",
      "(32, 28, 28, 6)\n",
      "\n",
      "conv1_pool x \n",
      "(32, 14, 14, 6)\n",
      "\n",
      "conv2 x \n",
      "(32, 10, 10, 16)\n",
      "\n",
      "conv2_pool x \n",
      "(32, 5, 5, 16)\n",
      "\n",
      "conv3 x \n",
      "(32, 1, 1, 120)\n",
      "\n",
      "flatten x \n",
      "(32, 120)\n",
      "\n",
      "dense1 x \n",
      "(32, 84)\n",
      "\n",
      "dense2 x \n",
      "(32, 10)\n",
      "\n",
      "predictions: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(filters = 6, kernel_size = 5, padding = 'same',\n",
    "                            activation = 'tanh')\n",
    "        self.conv1_pool = AveragePooling2D(pool_size = 2, strides = 2)\n",
    "        \n",
    "        self.conv2 = Conv2D(filters = 16, kernel_size = 5, padding = 'valid',\n",
    "                            activation = 'tanh')\n",
    "        self.conv2_pool = AveragePooling2D(pool_size = 2, strides = 2)\n",
    "        \n",
    "        self.conv3 = Conv2D(filters = 120, kernel_size = 5, padding = 'valid',\n",
    "                            activation = 'tanh')\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units = 84, activation = 'tanh')\n",
    "        self.dense2 = Dense(units = 10, activation = 'softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        print('x: \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        print('\\nconv1 x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.conv1_pool(x)\n",
    "        print('\\nconv1_pool x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print('\\nconv2 x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.conv2_pool(x)\n",
    "        print('\\nconv2_pool x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print('\\nconv3 x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        print('\\nflatten x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        print('\\ndense1 x \\n{}'.format(x.shape))\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        print('\\ndense2 x \\n{}'.format(x.shape))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "x = tf.random.normal(shape = (32, 28, 28, 1))\n",
    "predictions = model(x)\n",
    "print('\\npredictions:',predictions.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.7-2-2: LeNet with Hybrid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) uint8\n",
      "(60000,) uint8\n",
      "(60000, 28, 28, 1) float32\n",
      "tf.Tensor(2.349094, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, AveragePooling2D, Flatten, Dense\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "class ConvLayer(Layer):\n",
    "    def __init__(self, filters, padding, pool = True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.pool = pool\n",
    "        self.filters = filters\n",
    "        self.padding = padding \n",
    "        \n",
    "        self.conv = Conv2D(filters = self.filters, kernel_size = 5, padding = self.padding,\n",
    "                           activation = 'tanh')\n",
    "        if self.pool == True:\n",
    "            self.conv_pool = AveragePooling2D(pool_size = 2, strides = 2)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.pool == True:\n",
    "            x = self.conv_pool(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvLayer(filters = 6, padding = 'same')\n",
    "        self.conv2 = ConvLayer(filters = 16, padding = 'valid')\n",
    "        self.conv3 = ConvLayer(filters = 120, padding = 'valid', pool = False)\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        self.dense1 = Dense(units = 84, activation = 'tanh')\n",
    "        self.dense2 = Dense(units = 10, activation = 'softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "print(train_images.shape, train_images.dtype)\n",
    "print(train_labels.shape, train_labels.dtype)\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis = 3).astype(np.float32)\n",
    "print(train_images.shape, train_images.dtype)\n",
    "\n",
    "train_labels = train_labels.astype(np.int32)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "model = LeNet()\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "\n",
    "for images, labels in train_dataset:\n",
    "    predictions = model(images)\n",
    "    loss = loss_object(labels, predictions)\n",
    "    print(loss)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1)\n",
      "tf.Tensor(2.301944, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# LeNet        Filter Size      Filters     Padding     Strides     Activation      Output\n",
    "# input                            1                                                28 | 28 | 1\n",
    "\n",
    "# Conv1             5              6           2           1           tanh         28 | 28 | 6\n",
    "# AvgPool1          2              -           0           2                        14 | 14 | 6\n",
    "# Conv2             5             16           0           1           tanh         10 | 10 | 16\n",
    "# AvgPool2          2              -           0           2                         5 |  5 | 16\n",
    "# Conv3             5             120          0           1           tanh          1 |  1 | 120\n",
    "\n",
    "# Flatten                                                                          120 |\n",
    "# Dense1                          84                                   tanh         84 |\n",
    "# Dense2                          10                                   softmax      10 |\n",
    "\n",
    "class ConvLayer(Layer):\n",
    "    def __init__(self, filters, padding, pool = True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "        self.pool = pool\n",
    "        \n",
    "        self.conv = Conv2D(filters = self.filters, kernel_size = 5, padding = self.padding, \n",
    "                           activation = 'tanh')\n",
    "        \n",
    "        if self.pool == True:\n",
    "            self.conv_pool = AveragePooling2D(pool_size = 2, padding = 'valid', strides = 2)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        x = self.conv(x)\n",
    "        \n",
    "        if self.pool == True:\n",
    "            x = self.conv_pool(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "\n",
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvLayer(filters = 6, padding = 'same')\n",
    "        self.conv2 = ConvLayer(filters = 16, padding = 'valid')\n",
    "        self.conv3 = ConvLayer(filters = 120, padding = 'valid', pool = False)\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(units = 84, activation = 'tanh')\n",
    "        self.dense2 = Dense(units = 10, activation = 'softmax')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "(test_images, test_labels), _ = mnist.load_data()\n",
    "# print(test_images.shape)\n",
    "\n",
    "test_images = np.expand_dims(test_images, axis = 3).astype(np.float32)\n",
    "test_labels = test_labels.astype(np.int32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "dataset = dataset.batch(32)\n",
    "\n",
    "model = LeNet()\n",
    "loss_object = SparseCategoricalCrossentropy()\n",
    "for image, label in dataset:\n",
    "    print(image.shape)\n",
    "    predict = model(image)\n",
    "    loss = loss_object(label, predict)\n",
    "    \n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
