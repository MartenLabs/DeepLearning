{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 1개, neuron 1개 인 Affine Function을 작성하고 x, w, b, y의 shape과 값을 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "y_tf : [[16.478283]]\n",
      "y_man : [[16.478283]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "x = tf.constant([[10.]])\n",
    "dense = Dense(units = 1, activation = 'linear')\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print(f'y_tf : {y_tf}')\n",
    "print(f'y_man : {y_man}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w, b를 각각 10, 20으로 직접 지정해서 입력1, 출력1인 Affine Function을 작성하고 각 값을 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tf: [[120.]]\n",
      "y_man: [[120.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "w, b = tf.constant(10.), tf.constant(20.)\n",
    "w_init, b_init = tf.keras.initializers.Constant(w), Constant(b)\n",
    "\n",
    "dense = Dense(units = 1, \n",
    "              activation = 'linear',\n",
    "              kernel_initializer = w_init,\n",
    "              bias_initializer = b_init)\n",
    "\n",
    "x = tf.constant([[10.]])\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print(f'y_tf: {y_tf}')\n",
    "\n",
    "print(f'y_man: {y_man}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input: (1x10) feature, output 1인 Affine Function을 작성하시오\n",
    "*input의 shape은 random.uniform을 사용하여 출력*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_tf: [[-16.308933]]\n",
      "y_man: [[-16.308933]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "x = tf.random.uniform(shape=(1, 10), minval=0, maxval=10)\n",
    "\n",
    "dense = Dense(units = 1, activation = 'linear')\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "\n",
    "print(f'y_tf: {y_tf}')\n",
    "print(f'y_man: {y_man}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid, tanh, relu Activation function을 tensorflow로 부터 불러오고 (1, 5) 인풋을 각각의 Activation function에 넣어보시오.\n",
    "### 또한 각각의 Activation function을 직접 구현하고 인풋을 넣어 tensorflow와 값 차이가 있는지 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9576263  0.9997423  0.9989411  0.5167665  0.99961996]] : [[0.9576263  0.9997423  0.9989411  0.5167665  0.99961996]]\n",
      "\n",
      "[[0.9960918  0.99999994 0.9999978  0.06699046 0.99999976]] : [[0.9960918  0.9999999  0.9999978  0.06699047 0.99999964]]\n",
      "\n",
      "[[3.1179297  8.263412   6.849456   0.06709099 7.8749514 ]] : [[3.1179297  8.263412   6.849456   0.06709099 7.8749514 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "x = tf.random.uniform(shape = (1, 5), minval=0, maxval=10)\n",
    "\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "y_sigmoid_man = 1 / (1 + exp(-x))\n",
    "y_tanh_man = ((exp(x) - exp(-x))/ (exp(x) + exp(-x)))\n",
    "y_relu_man = maximum(0, x)\n",
    "\n",
    "print('{} : {}\\n'.format(y_sigmoid_tf, y_sigmoid_man))\n",
    "print('{} : {}\\n'.format(y_tanh_tf, y_tanh_man))\n",
    "print('{} : {}\\n'.format(y_relu_tf, y_relu_man))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid, tanh, relu를 Activation function으로 가지는 각각의 Dense Layer를 만들고 (1, 10)짜리 인풋을 통과시켜 값을 확인하시오.\n",
    "### 또한 직접 affine function 및 activation function을 구현하여 인풋을 넣었을 때 tensorflow와 차이가 있는지 확인하시오.\n",
    "\n",
    "W와 B는 직접 지정하여 사용하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11977383]] : [[0.11977383]]\n",
      "[[0.9976726]] : [[0.9976727]]\n",
      "[[1.9307554]] : [[1.9307554]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "x = tf.random.uniform(shape = (1, 10), minval=0, maxval=10)\n",
    "\n",
    "dense_sigmoid = Dense(units = 1, activation = 'sigmoid')\n",
    "dense_tanh = Dense(units = 1, activation = 'tanh')\n",
    "dense_relu = Dense(units = 1, activation = 'relu')\n",
    "\n",
    "y_sigmoid_tf = dense_sigmoid(x)\n",
    "y_tanh_tf = dense_tanh(x)\n",
    "y_relu_tf = dense_relu(x)\n",
    "\n",
    "W_sig, B_sig = dense_sigmoid.get_weights()\n",
    "W_tanh, B_tanh = dense_tanh.get_weights()\n",
    "W_relu, B_relu = dense_relu.get_weights()\n",
    "\n",
    "z_sig_man = tf.linalg.matmul(x, W_sig) + B_sig\n",
    "z_tanh_man = tf.linalg.matmul(x, W_tanh) + B_tanh\n",
    "z_relu_man = tf.linalg.matmul(x, W_relu) + B_relu\n",
    "\n",
    "y_sig_man = 1 / (1 + exp(-z_sig_man))\n",
    "y_tanh_man = ((exp(z_tanh_man) - exp(-z_tanh_man)) / (exp(z_tanh_man) + exp(-z_tanh_man)))\n",
    "y_relu_man = maximum(0, z_relu_man)\n",
    "\n",
    "print(f'{y_sigmoid_tf} : {y_sig_man}')\n",
    "\n",
    "print(f'{y_tanh_tf} : {y_tanh_man}')\n",
    "\n",
    "print(f'{y_relu_tf} : {y_relu_man}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8, 10)짜리 input을 sigmoid activation을 가지는 dense 1 자리 네트워크에 넣었을 때 W와 ,B를 예측해보고 그 값을 출력해 보시오 \n",
    "### 또한 affine function과 sigmoid 함수를 직접 구현해보고 tensorflow와 값 차이가 있는지 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: \" \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.math import exp\n",
    "\n",
    "x = tf.random.uniform(shape = (8, 10), minval=0, maxval=10)\n",
    "\n",
    "dense = Dense(units = 1, activation = 'sigmoid')\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print(f'W: {W.shape}')\n",
    "print(f'B: {B.shape}')\n",
    "\n",
    "z_man = tf.linalg.matmul(x, W) + B\n",
    "y_man = 1 / (1 + exp(-z_man))\n",
    "\n",
    "print(f'y_tf : {y_tf}')\n",
    "print(f'y_tf_shape : {y_tf.shape}')\n",
    "\n",
    "print(f'y_man : {y_man}')\n",
    "print(f'y_man_shape: {y_man.shape}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60d0139203b9048f6760b29fcc1cae1f975d3ed607ab404bf4727a6aedb2c178"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
