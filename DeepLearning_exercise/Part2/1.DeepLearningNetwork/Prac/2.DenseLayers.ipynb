{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid activation function과 3개의 neuron을 가지는 Dense Layer를 구현하시오 또한 w와 ouput을 예상해 보고 맞는지 확인하시오.\n",
    "input은 (8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: (10, 3)\n",
      "B: (3,)\n",
      "y_tf: (8, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "x = tf.random.uniform(shape = (8, 10), minval=0, maxval=10)\n",
    "\n",
    "dense = Dense(units = 3, activation = 'sigmoid')\n",
    "y_tf = dense(x)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print(f'W: {W.shape}')\n",
    "print(f'B: {B.shape}')\n",
    "print(f'y_tf: {y_tf.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3개의 뉴런을 가지고 sigmoid activation function을 가지는 dense layer를 구현하시오. \n",
    "단 dot product까지 메뉴얼로 구현하시오 \n",
    "\n",
    "input = (4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.math import exp \n",
    "\n",
    "N, n_feature = 4, 10\n",
    "x = tf.random.normal(shape = (N, n_feature))\n",
    "\n",
    "n_neurons = 3\n",
    "dense = Dense(units = n_neurons)\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "Z = tf.linalg.matmul(x, W) + B\n",
    "y_man = 1 / (1 + exp(-Z))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3, 5개의 뉴런으로 구성된 casecaded dense layer를 구현하고 각 레이어의 w와 output을 예상하여 맞는지 확인하시오\n",
    "activation function = sigmoid\n",
    "\n",
    "input (4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1: (10, 3), B1: (3,)\n",
      "W2: (3, 5), B2: (5,)\n",
      "y_tf : (4, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "N, n_feature = 4, 10\n",
    "x = tf.random.normal(shape = (N, n_feature))\n",
    "\n",
    "n_neurons = [3, 5]\n",
    "dense1 = Dense(units = n_neurons[0], activation = 'sigmoid')\n",
    "dense2 = Dense(units = n_neurons[1], activation = 'sigmoid')\n",
    "\n",
    "A1 = dense1(x)\n",
    "Y = dense2(A1)\n",
    "\n",
    "W1, B1 = dense1.get_weights()\n",
    "W2, B2 = dense2.get_weights()\n",
    "\n",
    "print(f'W1: {W1.shape}, B1: {B1.shape}')\n",
    "print(f'W2: {W2.shape}, B2: {B2.shape}')\n",
    "print(f'y_tf : {y_tf.shape}')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10+=10 ~ 90 개의 뉴런을 가지는 9개의 레이어로 구성된 cascaded dense layer를 구현하고 각 레이어에서의 w와 output을 예상하여 맞는지 확인하시오\n",
    "activation function = relu\n",
    "\n",
    "input (4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dense layer  1\n",
      "(4, 10)\n",
      "After dense layer  2\n",
      "(4, 20)\n",
      "After dense layer  3\n",
      "(4, 30)\n",
      "After dense layer  4\n",
      "(4, 40)\n",
      "After dense layer  5\n",
      "(4, 50)\n",
      "After dense layer  6\n",
      "(4, 60)\n",
      "After dense layer  7\n",
      "(4, 70)\n",
      "After dense layer  8\n",
      "(4, 80)\n",
      "After dense layer  9\n",
      "(4, 90)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 4, 10\n",
    "x = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "n_neurons = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "dense_layers = list()\n",
    "for n_neuron in n_neurons:\n",
    "    dense = Dense(units = n_neuron, activation = 'relu')\n",
    "    dense_layers.append(dense)\n",
    "\n",
    "for dense_idx, dense_layer in enumerate(dense_layers):\n",
    "    x = dense_layer(x)\n",
    "    print(\"After dense layer \", dense_idx + 1)\n",
    "    print(x.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 ~ 5개의 뉴런을 가지는 3개의 cascaded dense layer를 리스트로 구현하고 각각의 레이어의 w와 b또한 레이어로 받아와 메뉴얼로 직접 구현하시오\n",
    "activation function = sigmoid\n",
    "\n",
    "input (4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : (4, 3)\n",
      "2 : (4, 4)\n",
      "3 : (4, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "\n",
    "N, n_feature = 4, 10\n",
    "x = tf.random.uniform(shape = (N, n_feature), minval=0, maxval=10)\n",
    "\n",
    "n_neurons = [3, 4, 5]\n",
    "\n",
    "dense_layers = list()\n",
    "for n_neuron in n_neurons:\n",
    "    dense = Dense(units = n_neuron, activation = 'sigmoid')\n",
    "    dense_layers.append(dense)\n",
    "    \n",
    "for dense_idx, dense_layer in enumerate(dense_layers):\n",
    "    x = dense_layer(x)\n",
    "    print(f'{dense_idx + 1} : {x.shape}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential module 을 사용하여 2-dense layer를 구성하시오\n",
    "첫번째 레이어는 10개 neuron, 두번째 레이어는 20개 neuron\n",
    "\n",
    "activation function = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 10, activation = 'sigmoid'))\n",
    "model.add(Dense(units = 20, activation = 'sigmoid'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestModel 클래스를 만들고 클래스 내부에서 2-dense layer를 구성하시오\n",
    "첫번째 레이어는 10개 neuron, 두번째 레이어는 20개 neuron\n",
    "\n",
    "activation function = sigmoid\n",
    "\n",
    "또한 외부에서 dense1과 dense2 를 각각 호출해 보시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.dense.Dense object at 0x2c82523b0>\n",
      "<keras.layers.core.dense.Dense object at 0x2c820e740>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class TestModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.dense1 = Dense(units = 10, activation = 'sigmoid')\n",
    "        self.dense2 = Dense(units = 20, activation = 'sigmoid')\n",
    "        \n",
    "model = TestModel()\n",
    "print(model.dense1)\n",
    "print(model.dense2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dense layer를 Sequential method 와 model-subclassing을 사용하여 각각 만들어보고 값을 비교헤 보시오\n",
    "\n",
    "input = (4, 10)\n",
    "\n",
    "activation = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4744179  0.4556607  0.5971656  0.6394634  0.3875144  0.52563816\n",
      "  0.43298894 0.30838153 0.5336382  0.5797377  0.45272702 0.4773281\n",
      "  0.56071126 0.5533781  0.5101585  0.4922217  0.52431935 0.38400197\n",
      "  0.32515097 0.38186225]\n",
      " [0.4411303  0.59813666 0.5525005  0.5296096  0.45743543 0.5997154\n",
      "  0.4382422  0.28978643 0.38607633 0.47189233 0.41443586 0.47827104\n",
      "  0.67634004 0.59491235 0.42593262 0.63855505 0.59525836 0.5142735\n",
      "  0.31336522 0.31418127]\n",
      " [0.50068575 0.5169516  0.62400734 0.64536846 0.41101146 0.5678675\n",
      "  0.41517314 0.34340933 0.58745295 0.67568636 0.3626207  0.45998982\n",
      "  0.6649222  0.63115585 0.46858963 0.54193985 0.53662753 0.3746325\n",
      "  0.2953601  0.33806658]\n",
      " [0.46492204 0.4827816  0.6255137  0.6753331  0.36783153 0.54012716\n",
      "  0.43082318 0.287515   0.5962438  0.6531561  0.40321413 0.46177453\n",
      "  0.5781588  0.5689942  0.50599235 0.49654326 0.48523912 0.37202537\n",
      "  0.32833618 0.3680963 ]]\n",
      "tf.Tensor(\n",
      "[[0.51627    0.62345856 0.40616623 0.67159903 0.6929626  0.30788738\n",
      "  0.5033771  0.48393676 0.68139875 0.67265314 0.44649932 0.6099738\n",
      "  0.55320686 0.3157983  0.5103303  0.4460179  0.5045462  0.54177696\n",
      "  0.65677977 0.3810621 ]\n",
      " [0.5030737  0.663282   0.39508808 0.5709611  0.732407   0.4301536\n",
      "  0.55471027 0.5374889  0.65004265 0.6500051  0.35491452 0.6576608\n",
      "  0.5219255  0.36202058 0.52405983 0.55064386 0.45337525 0.56742585\n",
      "  0.6276056  0.3338199 ]\n",
      " [0.52425885 0.6051155  0.38838068 0.58498764 0.7061973  0.38429302\n",
      "  0.4921063  0.48994243 0.5424844  0.6000482  0.43237385 0.61497414\n",
      "  0.6102535  0.38160405 0.48078766 0.5214967  0.4580077  0.47882107\n",
      "  0.61711645 0.39928633]\n",
      " [0.5555723  0.6258168  0.38495907 0.5967746  0.7197575  0.34274712\n",
      "  0.4800903  0.534026   0.6415073  0.62700504 0.4125144  0.62325406\n",
      "  0.5104374  0.3645918  0.4880564  0.49818668 0.49363446 0.5541676\n",
      "  0.6204765  0.34659088]], shape=(4, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "x = tf.random.normal(shape=(4,10))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 10, activation = 'sigmoid'))\n",
    "model.add(Dense(units = 20, activation = 'sigmoid'))\n",
    "\n",
    "Y = model(x)\n",
    "print(Y.numpy())\n",
    "\n",
    "\n",
    "class TestModel(Model):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.dense1 = Dense(units = 10, activation = 'sigmoid')\n",
    "        self.dense2 = Dense(units = 20, activation = 'sigmoid')\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        A1 = self.dense1(x)\n",
    "        Y = self.dense2(A1)\n",
    "        return Y\n",
    "    \n",
    "testModel = TestModel()\n",
    "Y = testModel(x)\n",
    "print(Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가변 nueron을 가지는 n-dense layer 클래스를 설계하고 call 함수를 호출하여 출력을 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "class TestModel(Model):\n",
    "    def __init__(self, n_neurons):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.dense_layers = list()\n",
    "        \n",
    "        for n_neuron in self.n_neurons:\n",
    "            self.dense_layers.append(Dense(units = n_neuron, activation = 'sigmoid'))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for dense_layer in self.dense_layers:\n",
    "            x = dense_layer(x)\n",
    "        return x\n",
    "    \n",
    "x = tf.random.uniform(shape = (10, 20), minval=0, maxval=10)   \n",
    "n_neurons = [3, 5, 7, 9]\n",
    "model = TestModel(n_neurons)\n",
    "\n",
    "y = model(x)\n",
    "print(y.shape) \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각각 10, 20 개의 neuron을 가지는 2-dense layer를 만들고 각 layer의 Weight와 Bias및 기타 학습 대상이 되는 var들을 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60d0139203b9048f6760b29fcc1cae1f975d3ed607ab404bf4727a6aedb2c178"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
