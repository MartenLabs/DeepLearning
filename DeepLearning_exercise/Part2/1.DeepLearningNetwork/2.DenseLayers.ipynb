{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1: Dense Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.2-1-1: Shapes of Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Input/Weight/Bias =====\n",
      "X:  (8, 10)\n",
      "W:  (10, 3)\n",
      "B:  (3,)\n",
      "Y:  (8, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 8, 10\n",
    "\n",
    "X = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "n_neuron = 3\n",
    "dense = Dense(units=n_neuron, activation='sigmoid')\n",
    "Y = dense(X)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "print(\"===== Input/Weight/Bias =====\")\n",
    "print(\"X: \", X.shape)\n",
    "print(\"W: \", W.shape)\n",
    "print(\"B: \", B.shape)\n",
    "print(\"Y: \", Y.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.2-1-2: Output Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[0.41390273 0.20940256 0.37677005]\n",
      " [0.83916765 0.85222584 0.47000486]\n",
      " [0.13364716 0.20498145 0.6551169 ]\n",
      " [0.25150403 0.2082321  0.55692154]]\n",
      "Y(with matrix multiplication: \n",
      ") [[0.41390273 0.20940256 0.37677005]\n",
      " [0.83916765 0.85222584 0.47000486]\n",
      " [0.13364716 0.20498145 0.6551169 ]\n",
      " [0.25150403 0.2082321  0.55692154]]\n",
      "X shape:  (4, 10)\n",
      "x:  tf.Tensor(\n",
      "[-1.3544159   0.7045493   0.03666191  0.86918795  0.43842277 -0.53439844\n",
      " -0.07710292  1.5658046  -0.1012345  -0.2744975 ], shape=(10,), dtype=float32)\n",
      "x:  tf.Tensor(\n",
      "[ 1.420466    1.2609465  -0.4364091  -1.963399   -0.06452482 -1.056841\n",
      "  1.0019135   0.6735137   0.06987705 -1.4077919 ], shape=(10,), dtype=float32)\n",
      "x:  tf.Tensor(\n",
      "[ 1.0278524   0.2797411  -0.01347954  1.8451811   0.9706112  -1.0242516\n",
      " -0.6544423  -0.29738778 -1.3240397   0.28785658], shape=(10,), dtype=float32)\n",
      "x:  tf.Tensor(\n",
      "[-0.87579006 -0.08856997  0.6921164   0.842157   -0.06378508  0.9280078\n",
      " -0.6039788  -0.17669262  0.04221032  0.29037958], shape=(10,), dtype=float32)\n",
      "Y(with dot products:) \n",
      " [[0.41390271 0.20940257 0.37677005]\n",
      " [0.83916763 0.85222582 0.47000482]\n",
      " [0.13364714 0.20498143 0.65511686]\n",
      " [0.25150406 0.20823211 0.55692151]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.math import exp\n",
    "from tensorflow.linalg import matmul\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 4, 10\n",
    "X = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "n_neuron = 3\n",
    "dense = Dense(units = n_neuron, activation = 'sigmoid')\n",
    "Y_tf = dense(X)\n",
    "\n",
    "W, B = dense.get_weights()\n",
    "print(\"Y(Tensorflow): \\n\", Y_tf.numpy())\n",
    "\n",
    "# calc with matrix multiplication\n",
    "Z = matmul(X, W) + B\n",
    "Y_man_matmul = 1 / (1 + exp(-Z))\n",
    "print(\"Y(with matrix multiplication: \\n)\", Y_man_matmul.numpy())\n",
    "\n",
    "# print('W',W)\n",
    "print('X shape: ', X.shape)\n",
    "# calc with dot products\n",
    "Y_man_vec = np.zeros(shape=(N, n_neuron))\n",
    "# print(Y_man_vec)\n",
    "for x_idx in range(N):\n",
    "    x = X[x_idx, :]\n",
    "    # print('x: ', x)\n",
    "    \n",
    "    for nu_idx in range(n_neuron):\n",
    "        w, b = W[:, nu_idx], B[nu_idx]\n",
    "        # print('w: ', w)\n",
    "        z = tf.reduce_sum(x * w) + b\n",
    "        a = 1 / (1 + np.exp(-z))\n",
    "        Y_man_vec[x_idx, nu_idx] = a\n",
    "\n",
    "print(\"Y(with dot products:) \\n\", Y_man_vec)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2: Cascaded Dense Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.2-2-1: Shape of Cascaded Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4, 10)\n",
      "\n",
      "W1:  (10, 3)\n",
      "B1:  (3,)\n",
      "A1: (4, 3)\n",
      "\n",
      "W2:  (3, 5)\n",
      "B2:  (5,)\n",
      "Y: (4, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 4, 10\n",
    "X = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "n_neurons = [3, 5]\n",
    "dense1 = Dense(units=n_neurons[0], activation='sigmoid')\n",
    "dense2 = Dense(units=n_neurons[1], activation='sigmoid')\n",
    "\n",
    "# forward propagation\n",
    "A1 = dense1(X)\n",
    "Y = dense2(A1)\n",
    "\n",
    "# get weight/bias\n",
    "W1, B1 = dense1.get_weights()\n",
    "W2, B2 = dense2.get_weights()\n",
    "\n",
    "print(\"X: {}\\n\".format(X.shape))\n",
    "print(\"W1: \", W1.shape)\n",
    "print(\"B1: \", B1.shape)\n",
    "\n",
    "print(\"A1: {}\\n\".format(A1.shape))\n",
    "\n",
    "print(\"W2: \", W2.shape)\n",
    "print(\"B2: \", B2.shape)\n",
    "\n",
    "print(\"Y: {}\\n\".format(Y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code.2-2-2: Dense Layers with Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Input:  (4, 10)\n",
      "After dense layer  1\n",
      "(4, 10) \n",
      "\n",
      "After dense layer  2\n",
      "(4, 20) \n",
      "\n",
      "After dense layer  3\n",
      "(4, 30) \n",
      "\n",
      "After dense layer  4\n",
      "(4, 40) \n",
      "\n",
      "After dense layer  5\n",
      "(4, 50) \n",
      "\n",
      "After dense layer  6\n",
      "(4, 60) \n",
      "\n",
      "After dense layer  7\n",
      "(4, 70) \n",
      "\n",
      "After dense layer  8\n",
      "(4, 80) \n",
      "\n",
      "After dense layer  9\n",
      "(4, 90) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 4, 10\n",
    "X = tf.random.normal(shape=(N, n_feature))\n",
    "\n",
    "n_neurons = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "dense_layers = list()\n",
    "for n_neuron in n_neurons:\n",
    "    dense = Dense(units=n_neuron, activation='relu')\n",
    "    dense_layers.append(dense)\n",
    "    \n",
    "print(len(dense_layers))\n",
    "print(\"Input: \", X.shape)\n",
    "for dense_idx, dense in enumerate(dense_layers):\n",
    "    X = dense(X)\n",
    "    print(\"After dense layer \", dense_idx+1);\n",
    "    print(X.shape, '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code.2-2-3: Output Calculators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(Tensorflow): \n",
      " [[0.49491575 0.44732755 0.4787393  0.44284943 0.5818738 ]\n",
      " [0.5008767  0.4300911  0.46937752 0.4436389  0.5907325 ]\n",
      " [0.49400163 0.44131932 0.47426486 0.44184828 0.5875968 ]\n",
      " [0.49765313 0.45043254 0.4806611  0.4473359  0.57554144]]\n",
      "Y(Manual): \n",
      " [[0.49491575 0.44732755 0.4787393  0.44284943 0.5818738 ]\n",
      " [0.5008767  0.4300911  0.46937752 0.4436389  0.5907325 ]\n",
      " [0.49400163 0.44131932 0.47426486 0.44184828 0.5875968 ]\n",
      " [0.49765313 0.45043254 0.4806611  0.4473359  0.57554144]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp\n",
    "from tensorflow.linalg import matmul\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 4, 10\n",
    "X = tf.random.normal(shape=(N, n_feature))\n",
    "X_cp = tf.identity(X)\n",
    "\n",
    "n_neurons = [3, 4, 5]\n",
    "\n",
    "dense_layers = list()\n",
    "for n_neuron in n_neurons:\n",
    "    dense = Dense(units=n_neuron, activation='sigmoid')\n",
    "    dense_layers.append(dense)\n",
    "    \n",
    "\n",
    "# forward propagation(Tensorflow)\n",
    "W, B = list(), list()\n",
    "for dense_idx, dense in enumerate(dense_layers):\n",
    "    X = dense(X)\n",
    "    w, b = dense.get_weights()\n",
    "    W.append(w)\n",
    "    B.append(b)\n",
    "print(\"Y(Tensorflow): \\n\", X.numpy())\n",
    "\n",
    "\n",
    "# forward propagation(Manual)\n",
    "for layer_idx in range(len(n_neurons)):\n",
    "    w, b = W[layer_idx], B[layer_idx]\n",
    "\n",
    "    X_cp = matmul(X_cp, w) + b\n",
    "    X_cp = 1 / (1 + exp(-X_cp))\n",
    "print(\"Y(Manual): \\n\", X_cp.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
