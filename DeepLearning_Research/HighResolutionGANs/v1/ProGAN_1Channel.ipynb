{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.2.0+cu118\n",
      "torchvision: 0.17.0+cu118\n",
      "ignite: 0.4.13\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import ignite\n",
    "\n",
    "print(*map(lambda m: \": \".join((m.__name__, m.__version__)), (torch, torchvision, ignite)), sep=\"\\n\")\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "\n",
    "if 'CUDA_LAUNCH_BLOCKING' in os.environ:\n",
    "    del os.environ['CUDA_LAUNCH_BLOCKING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "# import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "import torch.autograd as autograd\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "import ignite.distributed as idist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_list = [\"4x4\", \"8x8\", \"16x16\", \"32x32\", \"64x64\", \"128x128\", \"256x256\", \"512x512\"]\n",
    "channel_list = [256, 128, 128, 64, 64, 32, 16, 8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class WSConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, gain=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale = (gain / (in_channels * kernel_size ** 2)) ** 0.5\n",
    "\n",
    "        # self.bias.shape: (out_channels)\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0], 1, 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch_size, C, H, W) / (batch_size, 1, H, W)\n",
    "        out = x / torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class UpDownSampling(nn.Module):\n",
    "\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.interpolate(x, scale_factor=self.size, mode=\"nearest\")\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class GeneratorConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, step, scale_size):\n",
    "        super().__init__()\n",
    "        self.up_sampling = UpDownSampling(size=scale_size)\n",
    "\n",
    "        # (C_(step-1), H, W) -> (C_step, H, W)\n",
    "        self.conv1 = WSConv2d(in_channels=channel_list[step-1], out_channels=channel_list[step], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # (C_step, H, W) -> (C_step, H, W)\n",
    "        self.conv2 = WSConv2d(in_channels=channel_list[step], out_channels=channel_list[step], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.pn = PixelNorm()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.scaled = self.up_sampling(x)\n",
    "        \n",
    "        out = self.conv1(self.scaled)\n",
    "        out = self.leakyrelu(out)\n",
    "        out = self.pn(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.leakyrelu(out)\n",
    "        out = self.pn(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, steps):\n",
    "        super().__init__()\n",
    "\n",
    "        self.steps = steps\n",
    "\n",
    "        self.init = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "\n",
    "            # (z_dim, 1, 1) -> (C_0, 4, 4)\n",
    "            nn.ConvTranspose2d(in_channels=channel_list[0], out_channels=channel_list[0], kernel_size=4, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            # (C_0, 4, 4) -> (C_0, 4, 4)\n",
    "            WSConv2d(in_channels=channel_list[0], out_channels=channel_list[0], kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm()\n",
    "        )\n",
    "\n",
    "        self.init_torgb = WSConv2d(in_channels=channel_list[0], out_channels=1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        self.prog_blocks = nn.ModuleList([self.init])\n",
    "        self.torgb_layers = nn.ModuleList([self.init_torgb])\n",
    "        \n",
    "        # append blocks that are not init block.\n",
    "        for step in range(1, self.steps+1):\n",
    "            self.prog_blocks.append(GeneratorConvBlock(step, scale_size=2))\n",
    "            self.torgb_layers.append(WSConv2d(in_channels=channel_list[step], out_channels=1, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "\n",
    "    def fade_in(self, alpha, upsampling, generated):\n",
    "        return alpha * generated + (1 - alpha) * upsampling\n",
    "\n",
    "\n",
    "    def forward(self, x, alpha):\n",
    "        out = self.prog_blocks[0](x)\n",
    "\n",
    "        if self.steps == 0:\n",
    "            return self.torgb_layers[0](out)\n",
    "\n",
    "        for step in range(1, self.steps+1):\n",
    "            out = self.prog_blocks[step](out)\n",
    "\n",
    "        upsampling = self.torgb_layers[step-1](self.prog_blocks[step].scaled)\n",
    "        generated = self.torgb_layers[step](out)\n",
    "\n",
    "        return self.fade_in(alpha, upsampling, generated)\n",
    "\n",
    "\n",
    "\n",
    "class DiscriminatorConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, step):\n",
    "        super().__init__()\n",
    "\n",
    "        # (C_step, H, W) -> (C_step, H, W)\n",
    "        self.conv1 = WSConv2d(in_channels=channel_list[step], out_channels=channel_list[step], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # (C_step, H, W) -> (C_(step-1), H, W)\n",
    "        self.conv2 = WSConv2d(in_channels=channel_list[step], out_channels=channel_list[step-1], kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # (C_(step-1), H/2, W/2)\n",
    "        self.downsample = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.leakyrelu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.leakyrelu(out)\n",
    "\n",
    "        out = self.downsample(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MinibatchStd(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mean of minibatch's std\n",
    "        # (1) -> (batch_size, 1, H, W)\n",
    "        batch_statistics = (torch.std(x, dim=0).mean().repeat(x.size(0), 1, x.size(2), x.size(3)))\n",
    "\n",
    "        # (batch_size, C, H, W) -> (batch_size, C+1, H, W)\n",
    "        return torch.cat((x, batch_statistics), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, steps):\n",
    "        super().__init__()\n",
    "        # progressive growing blocks\n",
    "        self.prog_blocks = nn.ModuleList([])\n",
    "\n",
    "        # fromrgb layers\n",
    "        self.fromrgb_layers = nn.ModuleList([])\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.steps = steps\n",
    "        \n",
    "        # append blocks that are not final block.\n",
    "        for step in range(steps, 0, -1):\n",
    "            self.prog_blocks.append(DiscriminatorConvBlock(step))\n",
    "            self.fromrgb_layers.append(WSConv2d(in_channels=1, out_channels=channel_list[step], kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "        # append final block\n",
    "        self.fromrgb_layers.append(\n",
    "            WSConv2d(in_channels=1, out_channels=channel_list[0], kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "\n",
    "        # append final block\n",
    "        self.prog_blocks.append(\n",
    "            nn.Sequential(\n",
    "                MinibatchStd(),\n",
    "                WSConv2d(in_channels=channel_list[0]+1, out_channels=channel_list[0], kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                WSConv2d(in_channels=channel_list[0], out_channels=channel_list[0], kernel_size=4, stride=1, padding=0),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                WSConv2d(in_channels=channel_list[0], out_channels=1, kernel_size=1, stride=1, padding=0),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # downsample\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    \n",
    "    def fade_in(self, alpha, downscaled, out):\n",
    "        return alpha * out + (1 - alpha) * downscaled\n",
    "\n",
    "    \n",
    "    def forward(self, x, alpha):\n",
    "        # (3, H, W) -> (C, H, W)\n",
    "        out = self.leakyrelu(self.fromrgb_layers[0](x))\n",
    "\n",
    "        if self.steps == 0: # i.e, image size is 4x4\n",
    "            \n",
    "            # (C, 4, 4) -> (1, 1, 1)\n",
    "            out = self.prog_blocks[-1](out)\n",
    "\n",
    "            # (1, 1, 1) -> (1)\n",
    "            # out.size(0) = batch_size\n",
    "            return out.view(out.size(0), -1)\n",
    "        \n",
    "\n",
    "        downscaled = self.leakyrelu(self.fromrgb_layers[1](self.avgpool(x)))\n",
    "        out = self.prog_blocks[0](out)\n",
    "\n",
    "        out = self.fade_in(alpha, downscaled, out)\n",
    "        \n",
    "        for i in range(1, self.steps+1):\n",
    "            out = self.prog_blocks[i](out)\n",
    "\n",
    "        return out.view(out.size(0), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, directory_list, resolution):\n",
    "        self.directory_list = directory_list\n",
    "        self.resolution = resolution\n",
    "\n",
    "\n",
    "    def image_to_tensor(self, path, res):\n",
    "        img = Image.open(path).convert('L').resize(res)\n",
    "\n",
    "        tensor_img = transforms.ToTensor()(img)\n",
    "        tensor_img = tensor_img.type(torch.float16)\n",
    "\n",
    "        return tensor_img\n",
    "\n",
    "\n",
    "    def dataset_to_tensor(self, directory_path):\n",
    "        files = os.listdir(directory_path)\n",
    "        tensor_dataset = torch.zeros((len(files), 1, *self.resolution)).type(torch.float16)\n",
    "\n",
    "        for i in range(len(files)):\n",
    "            tensor_dataset[i] = self.image_to_tensor(f\"{directory_path}/{files[i]}\", self.resolution)\n",
    "        \n",
    "        return tensor_dataset\n",
    "\n",
    "\n",
    "    def extract_dataset(self):\n",
    "        dataset_pair = []\n",
    "\n",
    "        for directory_path in self.directory_list:\n",
    "            dataset_pair.append(self.dataset_to_tensor(directory_path))\n",
    "\n",
    "        return dataset_pair\n",
    "    \n",
    "\n",
    "def make_gif(paths, save_path, fps=500):\n",
    "    img, *imgs = [Image.open(path) for path in paths]\n",
    "    img.save(fp=save_path, format=\"GIF\", append_images=imgs, save_all=True, duration=fps, loop=1)\n",
    "\n",
    "\n",
    "def merge_test_pred(pred):\n",
    "\n",
    "    test_size = pred.size(0)\n",
    "    \n",
    "    # ex) test_size = 30 -> height = 5, weight = 6\n",
    "    for i in range(int(np.sqrt(test_size)), test_size+1):\n",
    "        if test_size % i == 0:\n",
    "            n_height = max(i, test_size//i)\n",
    "            n_weight = min(i, test_size//i)\n",
    "            break\n",
    "    \n",
    "    image_size = (\n",
    "        1024 - (1024 % n_weight),\n",
    "        1024 - (1024 % n_height)\n",
    "    )\n",
    "\n",
    "    one_image_size = (image_size[0] // n_weight, image_size[1] // n_height)\n",
    "\n",
    "    image = Image.new('RGB', image_size)\n",
    "\n",
    "    for w in range(n_weight):\n",
    "        for h in range(n_height):\n",
    "            img = transforms.ToPILImage()(pred[n_height*w + h])\n",
    "            img = img.resize(one_image_size)\n",
    "\n",
    "            image.paste(img, (one_image_size[0] * w, one_image_size[1] * h))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for resolution in resolution_list:\n",
    "#     resolution_pair = tuple(map(int, resolution.split(\"x\")))\n",
    "\n",
    "#     dataset = Dataset(\n",
    "#         directory_list=[\"HighResolution/train/0\", \"HighResolution/valid/0\", \"HighResolution/train/1\", \"HighResolution/valid/1\"],\n",
    "#         resolution=resolution_pair\n",
    "#     )\n",
    "\n",
    "#     train_0, train_1, valid_0, valid_1 = dataset.extract_dataset()\n",
    "\n",
    "#     save_paths = [\n",
    "#         f\"HighResolution/torch/{resolution}/train_0.pt\",\n",
    "#         f\"HighResolution/torch/{resolution}/train_1.pt\",\n",
    "#         f\"HighResolution/torch/{resolution}/valid_0.pt\",\n",
    "#         f\"HighResolution/torch/{resolution}/valid_1.pt\"\n",
    "#     ]\n",
    "\n",
    "#     for path in save_paths:\n",
    "#         dir_name = os.path.dirname(path)\n",
    "#         if not os.path.exists(dir_name):\n",
    "#             os.makedirs(dir_name)  # os.makedirs는 중간에 없는 모든 디렉토리도 함께 생성합니다.\n",
    "    \n",
    "#     torch.save(train_0, save_paths[0])\n",
    "#     torch.save(train_1, save_paths[1])\n",
    "#     torch.save(valid_0, save_paths[2])\n",
    "#     torch.save(valid_1, save_paths[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "\tTrain\n",
      "\t\tG Loss: 4.826616443378825,\tD Loss: 0.18266554680508626\n",
      "\tValid\n",
      "\t\tG Loss: 1.7781939763648837, \t D Loss: 0.2346630996348811\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "\tTrain\n",
      "\t\tG Loss: 1.5964399399891707,\tD Loss: 0.29654669153018737\n",
      "\tValid\n",
      "\t\tG Loss: 1.356944572691824, \t D Loss: 0.5694004005076838\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "\tTrain\n",
      "\t\tG Loss: 1.196754296061019,\tD Loss: 0.4410310446376532\n",
      "\tValid\n",
      "\t\tG Loss: 1.646931430872749, \t D Loss: 1.0314142622199713\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "\tTrain\n",
      "\t\tG Loss: 1.0774847495723778,\tD Loss: 0.5185965194668568\n",
      "\tValid\n",
      "\t\tG Loss: 1.1328490294662177, \t D Loss: 1.1070281664530437\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "\tTrain\n",
      "\t\tG Loss: 1.0107502761021467,\tD Loss: 0.552499748451609\n",
      "\tValid\n",
      "\t\tG Loss: 1.2224884079951865, \t D Loss: 1.2352785549911798\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "\tTrain\n",
      "\t\tG Loss: 0.9949071025344688,\tD Loss: 0.5638256081393067\n",
      "\tValid\n",
      "\t\tG Loss: 1.608266645786809, \t D Loss: 1.3762229353773827\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "\tTrain\n",
      "\t\tG Loss: 1.0183146008303468,\tD Loss: 0.5628231050262988\n",
      "\tValid\n",
      "\t\tG Loss: 1.0003587919123031, \t D Loss: 1.1920153042849373\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "\tTrain\n",
      "\t\tG Loss: 1.0939472023869905,\tD Loss: 0.5479195252270765\n",
      "\tValid\n",
      "\t\tG Loss: 1.3799690499025232, \t D Loss: 1.2092153874098086\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "\tTrain\n",
      "\t\tG Loss: 1.11759879261675,\tD Loss: 0.5426561551194795\n",
      "\tValid\n",
      "\t\tG Loss: 1.4147297903603198, \t D Loss: 1.1458556172894496\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "\tTrain\n",
      "\t\tG Loss: 1.0999907616158606,\tD Loss: 0.5422484706824934\n",
      "\tValid\n",
      "\t\tG Loss: 0.9788579695365008, \t D Loss: 1.154996257202298\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "\tTrain\n",
      "\t\tG Loss: 1.1594464938405533,\tD Loss: 0.5356049478893549\n",
      "\tValid\n",
      "\t\tG Loss: 0.634628510942646, \t D Loss: 1.2120907704035442\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "\tTrain\n",
      "\t\tG Loss: 1.1452506872969614,\tD Loss: 0.5269892266098882\n",
      "\tValid\n",
      "\t\tG Loss: 0.8052536681586621, \t D Loss: 1.1607543417051727\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "\tTrain\n",
      "\t\tG Loss: 1.243790284848549,\tD Loss: 0.5356628340734563\n",
      "\tValid\n",
      "\t\tG Loss: 0.9313937145120957, \t D Loss: 1.2290831675716476\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "\tTrain\n",
      "\t\tG Loss: 1.216416833266406,\tD Loss: 0.5168766165283364\n",
      "\tValid\n",
      "\t\tG Loss: 1.6806229212704826, \t D Loss: 1.2674287931591857\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2421117131139192,\tD Loss: 0.5236451428540996\n",
      "\tValid\n",
      "\t\tG Loss: 1.2886494281245213, \t D Loss: 1.2002151059169395\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2621042342253135,\tD Loss: 0.5159757620012256\n",
      "\tValid\n",
      "\t\tG Loss: 1.4367892414915795, \t D Loss: 1.3275585910853218\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2249307556891105,\tD Loss: 0.5317687283099537\n",
      "\tValid\n",
      "\t\tG Loss: 1.623276668436387, \t D Loss: 1.3867438096626132\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2202571076406559,\tD Loss: 0.5315185634183212\n",
      "\tValid\n",
      "\t\tG Loss: 1.3957976453444536, \t D Loss: 1.404359238989213\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "\tTrain\n",
      "\t\tG Loss: 1.303039420658434,\tD Loss: 0.5185271467961056\n",
      "\tValid\n",
      "\t\tG Loss: 1.2113116523798775, \t D Loss: 1.4369441995433732\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2313208084710887,\tD Loss: 0.5393135639983164\n",
      "\tValid\n",
      "\t\tG Loss: 0.7761577671649409, \t D Loss: 1.3611362249243493\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2552711056991361,\tD Loss: 0.5195153456338695\n",
      "\tValid\n",
      "\t\tG Loss: 1.4445587782298817, \t D Loss: 1.4601610758725334\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2899352555543604,\tD Loss: 0.522174230343859\n",
      "\tValid\n",
      "\t\tG Loss: 1.1945859708038031, \t D Loss: 1.2527073317883062\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2329647364750715,\tD Loss: 0.5406923827151178\n",
      "\tValid\n",
      "\t\tG Loss: 0.9916235231885723, \t D Loss: 1.473383246683607\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2246434407334932,\tD Loss: 0.5486996236821295\n",
      "\tValid\n",
      "\t\tG Loss: 1.3330588270636166, \t D Loss: 1.4616186922671748\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "\tTrain\n",
      "\t\tG Loss: 1.244642112456577,\tD Loss: 0.5121171411494134\n",
      "\tValid\n",
      "\t\tG Loss: 1.281122460084803, \t D Loss: 1.4276967188891243\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "\tTrain\n",
      "\t\tG Loss: 1.3146432344342622,\tD Loss: 0.5131559871451955\n",
      "\tValid\n",
      "\t\tG Loss: 1.933020325268016, \t D Loss: 1.6787213858436136\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2924198096906636,\tD Loss: 0.533094541287758\n",
      "\tValid\n",
      "\t\tG Loss: 0.9785954508126951, \t D Loss: 1.4100068059622073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "\tTrain\n",
      "\t\tG Loss: 1.3472364108327408,\tD Loss: 0.5243444132133269\n",
      "\tValid\n",
      "\t\tG Loss: 1.8076510382633584, \t D Loss: 1.4692118004256605\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "\tTrain\n",
      "\t\tG Loss: 1.2680306220558328,\tD Loss: 0.5220586976534883\n",
      "\tValid\n",
      "\t\tG Loss: 1.3013350087053634, \t D Loss: 1.3936301668485005\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "\tTrain\n",
      "\t\tG Loss: 1.3120463910237166,\tD Loss: 0.5198176964907579\n",
      "\tValid\n",
      "\t\tG Loss: 1.2732686786090626, \t D Loss: 1.6240281731474633\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "\tTrain\n",
      "\t\tG Loss: 1.4753299766862895,\tD Loss: 0.4799095858150805\n",
      "\tValid\n",
      "\t\tG Loss: 1.0550936296874402, \t D Loss: 2.0758671643687228\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "\tTrain\n",
      "\t\tG Loss: 1.455747776468035,\tD Loss: 0.4998071244065191\n",
      "\tValid\n",
      "\t\tG Loss: 1.4773312386344462, \t D Loss: 2.022667420845406\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "\tTrain\n",
      "\t\tG Loss: 1.6139868430688347,\tD Loss: 0.43114226133051053\n",
      "\tValid\n",
      "\t\tG Loss: 2.5077760196199606, \t D Loss: 2.0986152209487616\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "\tTrain\n",
      "\t\tG Loss: 1.7915506858221242,\tD Loss: 0.37585619511738627\n",
      "\tValid\n",
      "\t\tG Loss: 1.1880798351530935, \t D Loss: 2.167758539611218\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "\tTrain\n",
      "\t\tG Loss: 1.6807949408678942,\tD Loss: 0.4817788474996325\n",
      "\tValid\n",
      "\t\tG Loss: 0.9990758218017279, \t D Loss: 2.2011344689948884\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "\tTrain\n",
      "\t\tG Loss: 1.580107355621499,\tD Loss: 0.4555970421979125\n",
      "\tValid\n",
      "\t\tG Loss: 1.5463734608070523, \t D Loss: 1.9527360107384475\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "\tTrain\n",
      "\t\tG Loss: 1.4743898502537902,\tD Loss: 0.49350652392481414\n",
      "\tValid\n",
      "\t\tG Loss: 2.181666932853998, \t D Loss: 1.7616230109158684\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "\tTrain\n",
      "\t\tG Loss: 1.6004430660059754,\tD Loss: 0.4461980629974688\n",
      "\tValid\n",
      "\t\tG Loss: 1.427911307297501, \t D Loss: 1.986409213028702\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "\tTrain\n",
      "\t\tG Loss: 1.6897400819079977,\tD Loss: 0.4520377004650277\n",
      "\tValid\n",
      "\t\tG Loss: 1.4508505989523495, \t D Loss: 2.040437237889159\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "\tTrain\n",
      "\t\tG Loss: 1.386875785572428,\tD Loss: 0.502933811973518\n",
      "\tValid\n",
      "\t\tG Loss: 0.6286490033654606, \t D Loss: 1.9456813966526705\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "\tTrain\n",
      "\t\tG Loss: 1.639353674902043,\tD Loss: 0.4727759470402355\n",
      "\tValid\n",
      "\t\tG Loss: 2.002234842263016, \t D Loss: 1.5715889135996501\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "\tTrain\n",
      "\t\tG Loss: 1.6350128197334182,\tD Loss: 0.43594517653257076\n",
      "\tValid\n",
      "\t\tG Loss: 1.6912812017926984, \t D Loss: 1.9362113405676449\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "\tTrain\n",
      "\t\tG Loss: 1.8658296633774125,\tD Loss: 0.43506195658529306\n",
      "\tValid\n",
      "\t\tG Loss: 1.3043927386695264, \t D Loss: 1.9030858184777053\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "\tTrain\n",
      "\t\tG Loss: 1.7414645158069235,\tD Loss: 0.45776978554859965\n",
      "\tValid\n",
      "\t\tG Loss: 1.814686050602034, \t D Loss: 2.244298497835795\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "\tTrain\n",
      "\t\tG Loss: 2.007751161783514,\tD Loss: 0.432894315518124\n",
      "\tValid\n",
      "\t\tG Loss: 1.101970421332939, \t D Loss: 2.1386702574935614\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "\tTrain\n",
      "\t\tG Loss: 1.8873093992891445,\tD Loss: 0.416266530752182\n",
      "\tValid\n",
      "\t\tG Loss: 5.6525021440842576, \t D Loss: 1.917256607728846\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "\tTrain\n",
      "\t\tG Loss: 1.895226797587435,\tD Loss: 0.42980195560925444\n",
      "\tValid\n",
      "\t\tG Loss: 3.4215658131767723, \t D Loss: 2.347899088672563\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "\tTrain\n",
      "\t\tG Loss: 2.0896248464852993,\tD Loss: 0.3913883130315324\n",
      "\tValid\n",
      "\t\tG Loss: 2.432498681779001, \t D Loss: 2.514376256980148\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "\tTrain\n",
      "\t\tG Loss: 1.7961699677185274,\tD Loss: 0.44630387992086545\n",
      "\tValid\n",
      "\t\tG Loss: 1.3128347794214885, \t D Loss: 1.907112112232283\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 19\n",
      "\tTrain\n",
      "\t\tG Loss: 1.9595194391801323,\tD Loss: 0.4081296419173899\n",
      "\tValid\n",
      "\t\tG Loss: 1.6173659563064575, \t D Loss: 2.7668377722010895\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 20\n",
      "\tTrain\n",
      "\t\tG Loss: 2.175425480788862,\tD Loss: 0.3806765374373382\n",
      "\tValid\n",
      "\t\tG Loss: 0.5756361765020034, \t D Loss: 2.578443592669917\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 21\n",
      "\tTrain\n",
      "\t\tG Loss: 2.3850639202225374,\tD Loss: 0.3814994833419021\n",
      "\tValid\n",
      "\t\tG Loss: 0.7308187040628171, \t D Loss: 2.4658674071816837\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 22\n",
      "\tTrain\n",
      "\t\tG Loss: 2.2316863939795697,\tD Loss: 0.3967080290468646\n",
      "\tValid\n",
      "\t\tG Loss: 1.2949019763983933, \t D Loss: 2.8156374856537463\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 23\n",
      "\tTrain\n",
      "\t\tG Loss: 2.3222154714691805,\tD Loss: 0.3800000103426651\n",
      "\tValid\n",
      "\t\tG Loss: 1.7676728449615777, \t D Loss: 2.5364811864553714\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 24\n",
      "\tTrain\n",
      "\t\tG Loss: 2.2504919675034536,\tD Loss: 0.3787401478055497\n",
      "\tValid\n",
      "\t\tG Loss: 2.615489964391671, \t D Loss: 2.9733849086013495\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 25\n",
      "\tTrain\n",
      "\t\tG Loss: 2.6641832111586985,\tD Loss: 0.35781372474952483\n",
      "\tValid\n",
      "\t\tG Loss: 0.7127363570764953, \t D Loss: 3.1927959731980864\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 26\n",
      "\tTrain\n",
      "\t\tG Loss: 2.3922829031944275,\tD Loss: 0.353923799706177\n",
      "\tValid\n",
      "\t\tG Loss: 2.7166043870589314, \t D Loss: 2.233114018159754\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 27\n",
      "\tTrain\n",
      "\t\tG Loss: 2.37325158673273,\tD Loss: 0.3403227194933824\n",
      "\tValid\n",
      "\t\tG Loss: 2.0159614249771716, \t D Loss: 3.6027723059934726\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 28\n",
      "\tTrain\n",
      "\t\tG Loss: 2.8385517588803464,\tD Loss: 0.3296712736638499\n",
      "\tValid\n",
      "\t\tG Loss: 2.4050379711038925, \t D Loss: 2.896799886927885\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 29\n",
      "\tTrain\n",
      "\t\tG Loss: 2.7292155212079976,\tD Loss: 0.3291072639780985\n",
      "\tValid\n",
      "\t\tG Loss: 4.874010417975631, \t D Loss: 4.006441443574195\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "\tTrain\n",
      "\t\tG Loss: 2.5219576207684797,\tD Loss: 0.319376306949367\n",
      "\tValid\n",
      "\t\tG Loss: 2.330635260133182, \t D Loss: 3.66353448232015\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 1\n",
      "\tTrain\n",
      "\t\tG Loss: 2.812023224964948,\tD Loss: 0.2707663274986643\n",
      "\tValid\n",
      "\t\tG Loss: 3.235784049127616, \t D Loss: 4.242414292167215\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 2\n",
      "\tTrain\n",
      "\t\tG Loss: 3.147445083503992,\tD Loss: 0.25457332241283337\n",
      "\tValid\n",
      "\t\tG Loss: 0.5829929881820491, \t D Loss: 3.7992510421603334\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 3\n",
      "\tTrain\n",
      "\t\tG Loss: 3.319822286216306,\tD Loss: 0.17257205449359517\n",
      "\tValid\n",
      "\t\tG Loss: 8.574964457867193, \t D Loss: 4.462590395235548\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 4\n",
      "\tTrain\n",
      "\t\tG Loss: 3.6709203086268736,\tD Loss: 0.2191381971810905\n",
      "\tValid\n",
      "\t\tG Loss: 1.192331803779976, \t D Loss: 4.699164867401123\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 5\n",
      "\tTrain\n",
      "\t\tG Loss: 4.228958663806109,\tD Loss: 0.11781258217360772\n",
      "\tValid\n",
      "\t\tG Loss: 2.7276479216182934, \t D Loss: 4.43067395920847\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 6\n",
      "\tTrain\n",
      "\t\tG Loss: 4.076151777321185,\tD Loss: 0.13308153220150673\n",
      "\tValid\n",
      "\t\tG Loss: 3.4720081535040164, \t D Loss: 4.983406272588992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 7\n",
      "\tTrain\n",
      "\t\tG Loss: 4.105849743728906,\tD Loss: 0.2295346394915816\n",
      "\tValid\n",
      "\t\tG Loss: 3.848923641092637, \t D Loss: 4.924272770975151\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 8\n",
      "\tTrain\n",
      "\t\tG Loss: 4.108535128580013,\tD Loss: 0.16747193610374356\n",
      "\tValid\n",
      "\t\tG Loss: 1.3535062168158738, \t D Loss: 5.126358284669764\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 9\n",
      "\tTrain\n",
      "\t\tG Loss: 3.568218353138843,\tD Loss: 0.2573191687517183\n",
      "\tValid\n",
      "\t\tG Loss: 2.112817911540761, \t D Loss: 5.788374900817871\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 10\n",
      "\tTrain\n",
      "\t\tG Loss: 3.913300846663999,\tD Loss: 0.25530552570248993\n",
      "\tValid\n",
      "\t\tG Loss: 6.426501021665685, \t D Loss: 5.336662007313149\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 11\n",
      "\tTrain\n",
      "\t\tG Loss: 4.313501337884178,\tD Loss: 0.17583122560885592\n",
      "\tValid\n",
      "\t\tG Loss: 6.429671624127557, \t D Loss: 5.5357953380135925\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 12\n",
      "\tTrain\n",
      "\t\tG Loss: 3.726653799204759,\tD Loss: 0.20313920920163814\n",
      "\tValid\n",
      "\t\tG Loss: 4.360615856507245, \t D Loss: 4.364335256464341\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 13\n",
      "\tTrain\n",
      "\t\tG Loss: 3.748764111962117,\tD Loss: 0.22645843448773237\n",
      "\tValid\n",
      "\t\tG Loss: 2.694335460662842, \t D Loss: 4.479638352113612\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 14\n",
      "\tTrain\n",
      "\t\tG Loss: 4.111157821937346,\tD Loss: 0.26922636342720246\n",
      "\tValid\n",
      "\t\tG Loss: 1.806117988100239, \t D Loss: 3.3025728394003475\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 15\n",
      "\tTrain\n",
      "\t\tG Loss: 3.5083042282453727,\tD Loss: 0.17820531182305913\n",
      "\tValid\n",
      "\t\tG Loss: 2.3162984450658164, \t D Loss: 4.263247167362886\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 16\n",
      "\tTrain\n",
      "\t\tG Loss: 3.8655035143167202,\tD Loss: 0.18756320086163533\n",
      "\tValid\n",
      "\t\tG Loss: 5.691565738004797, \t D Loss: 4.524428746279548\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 17\n",
      "\tTrain\n",
      "\t\tG Loss: 4.39407114579644,\tD Loss: 0.13068348596948134\n",
      "\tValid\n",
      "\t\tG Loss: 4.74690803827024, \t D Loss: 5.0475593922184965\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 18\n",
      "\tTrain\n",
      "\t\tG Loss: 3.56728583154544,\tD Loss: 0.2856273273347129\n",
      "\tValid\n",
      "\t\tG Loss: 2.3378009702645097, \t D Loss: 4.47106624584572\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch: 19\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "dataset_path = [f\"HighResolution/torch/{i}\" for i in resolution_list]\n",
    "model_state_dict_path = [f\"model_state_dict/{i}\" for i in resolution_list]\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self,\n",
    "                steps: int,\n",
    "                batch_size: int,\n",
    "                device: torch.device,\n",
    "                test_size: int\n",
    "            ):\n",
    "\n",
    "        self.steps = steps\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.test_size = test_size\n",
    "\n",
    "        directory_path = dataset_path[self.steps]\n",
    "\n",
    "        self.trainloader = DataLoader(torch.cat((torch.load(f\"{directory_path}/train_0.pt\"), torch.load(f\"{directory_path}/train_1.pt\")), dim=0).type(torch.float32), batch_size=self.batch_size, shuffle=True)\n",
    "        self.validloader = DataLoader(torch.cat((torch.load(f\"{directory_path}/valid_0.pt\"), torch.load(f\"{directory_path}/valid_1.pt\")), dim=0).type(torch.float32), batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.generator = Generator(steps=self.steps).to(self.device)\n",
    "        self.discriminator = Discriminator(steps=self.steps).to(self.device)\n",
    "\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.generator_optim = Adam(self.generator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "        self.discriminator_optim = Adam(self.discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "\n",
    "        # It will be used for testing.\n",
    "        self.test_z = torch.randn((self.test_size, 256, 1, 1)).to(self.device)\n",
    "\n",
    "        self.load_model()\n",
    "\n",
    "\n",
    "    # def save_model(self):\n",
    "    #     # ------------------------------------------------------------------ generator model ---------------------------------------------------------------------------\n",
    "    #     for i in range(self.steps+1):\n",
    "    #         torch.save(self.generator.prog_blocks[i].state_dict(), f\"{model_state_dict_path[self.steps]}/generator_model/prog_blocks_{i}.pt\")\n",
    "    #         torch.save(self.generator.torgb_layers[i].state_dict(), f\"{model_state_dict_path[self.steps]}/generator_model/torgb_layers_{i}.pt\")\n",
    "\n",
    "    #     # ---------------------------------------------------------------- discriminator model -------------------------------------------------------------------------\n",
    "    #     for i in range(self.steps+1):\n",
    "    #         torch.save(self.discriminator.prog_blocks[i].state_dict(), f\"{model_state_dict_path[self.steps]}/discriminator_model/prog_blocks_{i}.pt\")\n",
    "    #         torch.save(self.discriminator.fromrgb_layers[i].state_dict(), f\"{model_state_dict_path[self.steps]}/discriminator_model/fromrgb_layers_{i}.pt\")\n",
    "    \n",
    "    def save_model(self):\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        # 모델 상태를 저장할 기본 경로\n",
    "        base_path = \"model_state_dict\"\n",
    "\n",
    "        for i in range(self.steps + 1):\n",
    "            # 생성자와 판별자의 상태 저장 경로 설정\n",
    "            gen_path = f\"{base_path}/{resolution_list[self.steps]}/generator_model\"\n",
    "            disc_path = f\"{base_path}/{resolution_list[self.steps]}/discriminator_model\"\n",
    "\n",
    "            # 디렉토리가 없으면 생성\n",
    "            os.makedirs(gen_path, exist_ok=True)\n",
    "            os.makedirs(disc_path, exist_ok=True)\n",
    "\n",
    "            # 생성자 모델 상태 저장\n",
    "            torch.save(self.generator.prog_blocks[i].state_dict(), f\"{gen_path}/prog_blocks_{i}.pt\")\n",
    "            torch.save(self.generator.torgb_layers[i].state_dict(), f\"{gen_path}/torgb_layers_{i}.pt\")\n",
    "\n",
    "            # 판별자 모델 상태 저장\n",
    "            torch.save(self.discriminator.prog_blocks[i].state_dict(), f\"{disc_path}/prog_blocks_{i}.pt\")\n",
    "            torch.save(self.discriminator.fromrgb_layers[i].state_dict(), f\"{disc_path}/fromrgb_layers_{i}.pt\")\n",
    "\n",
    "\n",
    "    def load_model(self):\n",
    "        if self.steps == 0:\n",
    "            return\n",
    "\n",
    "        # ------------------------------------------------------------------ generator model ---------------------------------------------------------------------------\n",
    "        for i in range(self.steps):\n",
    "            self.generator.prog_blocks[i].load_state_dict(torch.load(f\"{model_state_dict_path[self.steps-1]}/generator_model/prog_blocks_{i}.pt\"))\n",
    "            self.generator.torgb_layers[i].load_state_dict(torch.load(f\"{model_state_dict_path[self.steps-1]}/generator_model/torgb_layers_{i}.pt\"))\n",
    "\n",
    "        # ---------------------------------------------------------------- discriminator model -------------------------------------------------------------------------\n",
    "        for i in range(1, self.steps+1):\n",
    "            self.discriminator.prog_blocks[i].load_state_dict(torch.load(f\"{model_state_dict_path[self.steps-1]}/discriminator_model/prog_blocks_{i-1}.pt\"))\n",
    "            self.discriminator.fromrgb_layers[i].load_state_dict(torch.load(f\"{model_state_dict_path[self.steps-1]}/discriminator_model/fromrgb_layers_{i-1}.pt\"))\n",
    "    \n",
    "\n",
    "    def clear_cuda_memory(self):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "    def test(self, epoch):\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        pred = self.generator(self.test_z, alpha=self.alpha)\n",
    "        pred = pred.detach().cpu()\n",
    "\n",
    "        # 이미지를 저장할 경로를 생성합니다.\n",
    "        save_path = f\"./train_log/{resolution_list[self.steps]}\"\n",
    "        os.makedirs(save_path, exist_ok=True)  # 해당 경로에 폴더가 없으면 생성합니다.\n",
    "\n",
    "        test_image = merge_test_pred(pred)\n",
    "        test_image.save(fp=f\"{save_path}/epoch-{epoch}.jpg\")\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        generator_avg_loss = 0\n",
    "        discriminator_avg_loss = 0\n",
    "\n",
    "        for _ in range(len(self.trainloader)):\n",
    "            self.alpha += self.alpha_gap\n",
    "\n",
    "            real_image = next(iter(self.trainloader)).to(self.device)\n",
    "\n",
    "            real_label = torch.full((real_image.size(0), 1), 1).type(torch.float).to(self.device)\n",
    "            fake_label = torch.full((real_image.size(0), 1), 0).type(torch.float).to(self.device)\n",
    "\n",
    "            # ---------------------------------------------------------- discriminator train ------------------------------------------------------------\n",
    "            z = torch.randn(real_image.size(0), 256, 1, 1).to(self.device)\n",
    "\n",
    "            fake_image = self.generator(z, alpha=self.alpha)\n",
    "            \n",
    "            d_fake_pred = self.discriminator(fake_image, alpha=self.alpha)\n",
    "            d_fake_loss = self.criterion(d_fake_pred, fake_label)\n",
    "\n",
    "            d_real_pred = self.discriminator(real_image, alpha=self.alpha)\n",
    "            d_real_loss = self.criterion(d_real_pred, real_label)\n",
    "\n",
    "            d_loss = d_fake_loss + d_real_loss\n",
    "\n",
    "            self.discriminator_optim.zero_grad()\n",
    "            d_loss.backward()\n",
    "            self.discriminator_optim.step()\n",
    "\n",
    "            discriminator_avg_loss += (d_loss.item() / 2)\n",
    "\n",
    "            # ---------------------------------------------------------- generator train -----------------------------------------------------------------\n",
    "            z = torch.randn(real_image.size(0), 256, 1, 1).to(self.device)\n",
    "\n",
    "            fake_image = self.generator(z, alpha=self.alpha)\n",
    "\n",
    "            d_fake_pred = self.discriminator(fake_image, alpha=self.alpha)\n",
    "            g_loss = self.criterion(d_fake_pred, real_label)\n",
    "\n",
    "            self.generator_optim.zero_grad()\n",
    "            g_loss.backward()\n",
    "            self.generator_optim.step()\n",
    "\n",
    "            generator_avg_loss += g_loss.item()\n",
    "\n",
    "\n",
    "            self.clear_cuda_memory()\n",
    "\n",
    "        generator_avg_loss /= len(self.trainloader)\n",
    "        discriminator_avg_loss /= len(self.trainloader)\n",
    "\n",
    "        return generator_avg_loss, discriminator_avg_loss\n",
    "\n",
    "    \n",
    "    def valid(self):\n",
    "        self.generator.eval()\n",
    "        self.discriminator.eval()\n",
    "\n",
    "        generator_avg_loss = 0\n",
    "        discriminator_avg_loss = 0\n",
    "\n",
    "        for _ in range(len(self.validloader)):\n",
    "            real_image = next(iter(self.validloader)).to(self.device)\n",
    "\n",
    "            real_label = torch.full((real_image.size(0), 1), 1).type(torch.float).to(self.device)\n",
    "            fake_label = torch.full((real_image.size(0), 1), 0).type(torch.float).to(self.device)\n",
    "\n",
    "            # ----------------------------------------------------- discriminator valid ----------------------------------------------------------------\n",
    "\n",
    "            z = torch.randn((real_image.size(0), 256, 1, 1)).to(self.device)\n",
    "            fake_image = self.generator(z, alpha=self.alpha)\n",
    "\n",
    "            d_fake_pred = self.discriminator(fake_image.detach(), alpha=self.alpha)\n",
    "            d_fake_loss = self.criterion(d_fake_pred, fake_label)\n",
    "\n",
    "            d_real_pred = self.discriminator(real_image, alpha=self.alpha)\n",
    "            d_real_loss = self.criterion(d_real_pred, real_label)\n",
    "\n",
    "            discriminator_avg_loss += ((d_fake_loss + d_real_loss).item() / 2)\n",
    "\n",
    "            # ------------------------------------------------------ generator valid --------------------------------------------------------------------\n",
    "\n",
    "            z = torch.randn((real_image.size(0), 256, 1, 1)).to(self.device)\n",
    "            fake_image = self.generator(z, alpha=self.alpha)\n",
    "\n",
    "            d_fake_pred = self.discriminator(fake_image.detach(), alpha=self.alpha)\n",
    "            g_loss = self.criterion(d_fake_pred, real_label)\n",
    "\n",
    "            generator_avg_loss += g_loss.item()\n",
    "\n",
    "            self.clear_cuda_memory()\n",
    "\n",
    "        generator_avg_loss /= len(self.validloader)\n",
    "        discriminator_avg_loss /= len(self.validloader)\n",
    "\n",
    "        return generator_avg_loss, discriminator_avg_loss\n",
    "\n",
    "\n",
    "    def run(self, epochs):\n",
    "        train_history = []\n",
    "        valid_history = []\n",
    "\n",
    "        self.alpha = 0\n",
    "        self.alpha_gap = 1 / (len(self.trainloader) * (epochs[1] - epochs[0]))\n",
    "\n",
    "        for epoch in range(*epochs):\n",
    "            print(\"-\"*100 + \"\\n\" + f\"Epoch: {epoch}\")\n",
    "\n",
    "            train_history.append(self.train())\n",
    "            print(f\"\\tTrain\\n\\t\\tG Loss: {train_history[-1][0]},\\tD Loss: {train_history[-1][1]}\")\n",
    "\n",
    "            valid_history.append(self.valid())\n",
    "            print(f\"\\tValid\\n\\t\\tG Loss: {valid_history[-1][0]}, \\t D Loss: {valid_history[-1][1]}\")\n",
    "\n",
    "            self.test(epoch)\n",
    "    \n",
    "        return train_history, valid_history\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for steps in range(8):\n",
    "        trainer = Trainer(steps=steps, batch_size=16, device=device, test_size=16)\n",
    "        train_history, valid_history = trainer.run((0, 30))\n",
    "        trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
