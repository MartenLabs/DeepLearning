
부제목: 저해상도 열화상 이미지의 중첩 객체 검출을 위한 복합 손실 함수 활용

초록: 본 논문은 리소스가 제한된 ARM Cortex-M 시리즈 마이크로컨트롤러(MCU)를 대상으로 저해상도, 단일 채널 열화상에서 실시간 객체 검출을 수행하기 위한 혁신적인 경량 딥러닝 아키텍처를 제안한다. 제안된 모델은 고해상도의 3채널 시각 이미지에 비해 저해상도의 단일 채널 열화상이 제공하는 제한된 정보에도 불구하고, 저전력 임베디드 디바이스에서 실시간 추론 능력을 유지하면서 놀라운 객체 검출 성능을 달성한다. 이 아키텍처는 depthwise separable convolution과 channel-wise attention 메커니즘과 같은 효율적인 합성곱 신경망(CNN) 설계 원칙을 활용하여 연산 복잡도와 메모리 사용량을 최소화한다. MLX90640 열화상 센서로 수집한 사용자 정의 데이터셋에 대한 실험 결과는 ARM Cortex-M7 MCU에서 실시간으로 실행되는 동안 모델이 관심 객체를 정확하게 감지할 수 있음을 입증한다. 본 연구는 경량 딥러닝 기술이 에지 디바이스에서 지능적인 인식 능력을 가능하게 하여 저전력, 저비용 임베디드 비전 애플리케이션을 위한 새로운 가능성을 제시한다는 점을 강조한다.

1. 서론 열화상 기술은 가시광선 조건과 무관하게 물체의 열 특성을 포착할 수 있어 객체 검출을 포함한 다양한 컴퓨터 비전 작업에서 강력한 도구로 주목받고 있다. 그러나 기존의 고해상도 열화상 카메라는 높은 비용과 전력 소모로 인해 임베디드 시스템에서의 광범위한 활용이 제한되어 왔다. 최근 MLX90640과 같은 저해상도 열화상 센서의 등장으로 상당히 저렴한 비용과 전력으로 열화상을 획득할 수 있게 되었다. 하지만 이러한 센서의 공간 해상도 감소와 단일 채널 특성은 전통적인 객체 검출 알고리즘에 새로운 도전 과제를 제기한다.

본 논문은 ARM Cortex-M 시리즈 마이크로컨트롤러의 제약 조건에 초점을 맞추어 저해상도, 단일 채널 열화상에서의 실시간 객체 검출 문제를 다룬다. 이러한 영상에서 사용할 수 있는 제한된 정보만으로는 정확한 객체 검출이 어려워 보일 수 있지만, 우리는 세심하게 설계된 경량 딥러닝 아키텍처가 리소스가 제한된 MCU의 엄격한 연산 및 메모리 제약 조건 내에서 작동하면서도 뛰어난 성능을 발휘할 수 있음을 보여준다.

본 연구의 주요 기여는 다음과 같다:

1. 저해상도, 단일 채널 열화상에서의 실시간 객체 검출에 최적화된 새로운 경량 CNN 아키텍처를 제안한다.
2. 열화상 도메인에서 사용 가능한 제한된 정보에도 불구하고 제안된 모델이 관심 객체를 정확하게 감지할 수 있음을 입증한다.
3. ARM Cortex-M7 MCU에서 모델의 실시간 성능을 검증하여 저전력 임베디드 비전 애플리케이션에 적합함을 보여준다.
4. 관련 연구 열화상 객체 검출에 관한 선행 연구들은 주로 고해상도 열화상을 대상으로 이루어져 왔다. (관련 연구 1)은 전통적인 hand-crafted 특징과 AdaBoost 분류기를 사용하여 열화상에서의 보행자 검출을 수행하였다. (관련 연구 2)는 딥러닝 기반의 객체 검출 모델인 YOLO를 열화상에 적용하여 차량 검출 성능을 향상시켰다. 그러나 이러한 연구들은 대부분 고성능 GPU에서 수행되었으며, 저해상도 열화상이나 임베디드 시스템에서의 실시간 동작 가능성은 고려하지 않았다.

경량 CNN 아키텍처에 관한 연구로는 MobileNet과 ShuffleNet 등이 있다. (관련 연구 3)은 depthwise separable convolution을 사용하여 모델 크기와 연산량을 대폭 줄인 MobileNet을 제안하였다. (관련 연구 4)는 채널 셔플 연산을 통해 정보 흐름을 개선한 ShuffleNet을 제안하였다. 그러나 이러한 모델들은 주로 고해상도 RGB 이미지를 대상으로 설계되었으며, 열화상의 특수성을 고려하지 않았다.

임베디드 딥러닝 분야에서는 모델 압축, 양자화, 경량 추론 엔진 등의 연구가 활발히 진행되고 있다. (관련 연구 5)는 가중치 가지치기와 양자화를 통해 모델 크기를 줄이는 방법을 제안하였다. (관련 연구 6)은 ARM Cortex-M 시리즈에 최적화된 경량 추론 엔진을 개발하였다. 그러나 이러한 연구들은 주로 분류 문제에 초점을 맞추고 있으며, 객체 검출과 같은 복잡한 태스크에 대한 고려는 부족한 실정이다.

본 연구는 저해상도 열화상, 경량 CNN 아키텍처, 임베디드 딥러닝의 요소들을 결합하여, ARM Cortex-M 시리즈 MCU에서 실시간 객체 검출을 수행하는 혁신적인 접근 방식을 제안한다. 열화상의 고유한 특성을 고려한 모델 설계와 다양한 최적화 기법을 통해, 제한된 자원 환경에서도 우수한 검출 성능을 달성할 수 있음을 입증한다.

3. 방법론 3.1 데이터셋 본 연구에서는 MLX90640 열화상 센서를 사용하여 사용자 정의 데이터셋을 구축하였다. 데이터 수집을 위해 (데이터 수집 환경 설명) 환경에서 (데이터 수집 프로토콜 설명) 프로토콜에 따라 열화상을 촬영하였다. 수집된 열화상은 (어노테이션 도구)를 사용하여 객체의 bounding box와 클래스 레이블을 어노테이션하였다. 최종적으로 (데이터셋 규모)의 데이터셋이 구축되었으며, 이를 (데이터셋 분할 비율)의 비율로 학습, 검증, 테스트 세트로 분할하였다.

3.2 경량 CNN 아키텍처 제안하는 경량 CNN 아키텍처는 저해상도 열화상에서의 객체 검출에 최적화되었다. 모델은 (백본 네트워크 설명)을 백본 네트워크로 사용하며, 이를 통해 추출된 특징 맵은 (neck 구조 설명)의 neck 구조를 거쳐 (head 구조 설명)의 head 구조에 전달된다. 백본 네트워크에서는 depthwise separable convolution을 사용하여 파라미터 수를 줄이고, channel-wise attention 메커니즘을 통해 중요한 채널에 가중치를 부여하였다. Neck 구조에서는 (특징 융합 방법 설명)을 통해 다양한 스케일의 특징을 효과적으로 결합하였다. Head 구조는 (anchor 설계 방법 설명)의 anchor를 사용하여 객체의 위치와 클래스를 예측한다. 전체 모델 구조는 (모델 경량화 기법 설명)의 경량화 기법을 적용하여 ARM Cortex-M 시리즈에서의 실시간 동작이 가능하도록 설계되었다.

3.3 훈련 및 최적화 제안된 모델은 (손실 함수 설명)의 손실 함수를 사용하여 end-to-end 방식으로 학습되었다. 객체 검출 성능을 높이기 위해 (데이터 증강 기법 설명)의 데이터 증강 기법을 적용하였으며, (하이퍼파라미터 설정)의 하이퍼파라미터 설정을 사용하였다. 모델 최적화를 위해 (옵티마이저 선택)의 옵티마이저와 (학습률 스케줄링 방법)의 학습률 스케줄링을 적용하였다. 또한 모델 경량화를 위해 (양자화 방법 설명)의 양자화 기법을 사용하였으며, 이를 통해 (경량화 성능 지표)의 모델 크기와 연산량 감소를 달성하였다.

4. 실험 및 결과 4.1 실험 설정 제안된 모델의 성능 평가를 위해 (하드웨어 플랫폼 설명) 환경에서 실험을 수행하였다. ARM Cortex-M7 MCU로는 (MCU 모델명)을 사용하였으며, MLX90640 열화상 센서로부터 (프레임 레이트)의 속도로 열화상을 입력받았다. 모델 학습에는 (학습 환경 설명)의 환경을 사용하였으며, 추론 단계에서는 (추론 엔진 설명)의 경량 추론 엔진을 사용하여 MCU에 배포하였다.

4.2 객체 검출 성능 제안된 모델의 객체 검출 성능은 (평가 지표 설명)의 평가 지표를 사용하여 측정되었다. 사용자 정의 데이터셋에 대한 실험 결과, 본 모델은 (mAP 성능)의 mAP와 (IoU 임계값)의 IoU 임계값에서 (정밀도)의 정밀도와 (재현율)의 재현율을 달성하였다. 이는 기존의 (비교 모델명) 모델 대비 (성능 향상 폭)의 성능 향상을 나타낸다. 또한 클래스별 검출 성능을 분석한 결과, (어려운 클래스)의 검출이 상대적으로 어려운 것으로 나타났는데, 이는 (원인 분석)의 원인에 기인한 것으로 파악된다. 저해상도 열화상의 특성이 검출 성능에 미치는 영향을 분석한 결과, (열화상 특성과 성능 간 관계 분석 결과)의 경향성을 확인할 수 있었다.

4.3 ARM Cortex-M7에서의 실시간 성능 제안된 모델의 실시간 성능을 평가하기 위해 ARM Cortex-M7 MCU에서의 추론 속도와 메모리 사용량을 측정하였다. 그 결과, 본 모델은 (추론 속도)의 추론 속도와 (메모리 사용량)의 메모리 사용량을 나타내었다. 이는 (비교 모델명) 모델 대비 (추론 속도 향상 폭)의 추론 속도 향상과 (메모리 사용량 감소 폭)의 메모리 사용량 감소에 해당한다. 또한 (에너지 효율 분석)을 통해 모델의 에너지 효율성을 검증하였다. 본 모델은 ARM Cortex-M7 MCU에서 (실시간성 여부) 실시간 객체 검출이 가능한 것으로 확인되었으며, 이



## **1. 서론**

최근 사물인터넷(IoT), 지능형 감시, 웨어러블 디바이스 등의 분야에서 저전력, 저비용, 소형 센서 기반 기기의 활용이 증가하고 있다. 이러한 기기들은 제한된 컴퓨팅 자원을 가지고 있기 때문에 고사양 프로세서나 GPU 기반 모델을 사용하기 어렵다. 따라서 STM32, ARM Cortex-M 등과 같은 초저사양 MCU(Micro-Controller Unit)에서 동작할 수 있는 효율적인 딥러닝 모델이 필요하다.

특히, 열화상 카메라는 물체의 열 방출 특성을 감지하여 이미지를 생성하는 센서로, 가시광선 카메라와 달리 조명 조건에 영향을 받지 않고 야간에도 작동할 수 있다는 장점이 있다. 하지만 열화상 이미지는 해상도가 낮고 물체의 경계가 명확하지 않은 특징이 있어, 기존의 딥러닝 모델을 그대로 적용하기 어렵다. 더욱이 물체가 겹쳐져 있는 경우에는 개별 물체를 정확히 분류하는 것이 매우 어려운 과제가 된다.

이러한 열화상 이미지로부터 사람을 분리하고 감지하는 기술은 다음과 같은 다양한 분야에 활용될 수 있다:

1. **지능형 감시 시스템**: 열화상 카메라를 통해 사람의 움직임을 감지하고 추적할 수 있어, 보안 모니터링, 출입 통제, 군사 감시 등의 분야에 활용 가능하다.

2. **재난 구조 및 탐색**: 열화상 카메라는 연기나 먼지 등의 환경에서도 사람을 쉽게 감지할 수 있어, 화재나 지진 등의 재난 상황에서 생존자 탐색에 유용하다.

3. **의료 및 건강 관리**: 열화상 이미지는 인체의 온도 분포를 확인할 수 있어, 열 패턴 분석을 통해 질병 진단, 스트레스 모니터링, 비접촉식 체온 측정 등에 활용 가능하다.

4. **빌딩 에너지 효율 최적화**: 열화상 카메라로 건물의 열 손실 지점을 파악할 수 있어, 에너지 효율 개선 및 비용 절감에 도움이 된다.

5. **산업 및 제조 공정 모니터링**: 열화상 카메라를 통해 기계 장비의 과열 징후를 조기에 감지하여 고장을 예방할 수 있다.

이처럼 열화상 이미지로부터 사람을 감지하고 분리하는 기술은 다양한 분야에서 광범위하게 활용될 수 있다. 그러나 기존의 고사양 딥러닝 모델은 제한된 자원을 가진 초저사양 MCU에서 실행하기 어렵다. 따라서 본 연구에서는 STM32와 같은 초저사양 MCU 환경에서도 동작 가능한 효율적인 열화상 이미지 기반 사람 분리 딥러닝 모델을 제안한다.



## CutMix 

객체 탐지(Object Detection) 문제는 이미지 내에 존재하는 물체의 위치와 클래스를 동시에 예측하는 작업이다. 이때 학습 데이터셋 내에서 물체가 존재하는 경우(Positive 샘플)와 물체가 존재하지 않는 경우(Negative 샘플)가 모두 포함되어 있다. 그런데 실제 데이터셋에서는 Positive 샘플의 비율이 상대적으로 낮은 경우가 많이 발생한다. 이는 데이터 수집 과정에서 비어있는 배경 이미지가 많이 포함되거나, 작은 물체들이 있는 이미지가 다수 포함되기 때문이다.

Positive 샘플의 비율이 낮으면 객체 탐지 모델이 Positive 샘플을 충분히 학습하지 못하게 되어 성능 저하가 발생할 수 있다. 모델은 Positive 샘플을 통해 물체의 특징을 제대로 학습해야 하는데, 이러한 샘플이 부족하면 모델이 일반화 능력을 잘 갖추지 못하게 된다. 결과적으로 테스트 데이터에 대해 낮은 정확도를 보이게 되는 것이다.

이러한 문제를 해결하기 위해 CutMix 알고리즘을 적용하여 Positive 샘플의 비율을 증가시켰다. CutMix는 데이터 증강(Data Augmentation) 기법 중 하나로, 기존 이미지에서 물체 영역을 잘라내어 다른 이미지에 붙여넣는 방식이다. 이를 통해 기존 이미지에 새로운 Positive 샘플을 추가할 수 있게 된다.

구체적으로는 데이터셋 내 이미지들 중 Positive 샘플이 있는 이미지를 선택하여, 그 이미지에서 물체 영역을 잘라낸다. 그리고 다른 이미지에 그 영역을 붙여넣는다. 이때 기존 이미지의 물체 영역과 겹치지 않도록 IoU(Intersection over Union) 임계값을 설정하여 제약을 둔다. 이렇게 하면 기존 이미지에 새로운 Positive 샘플이 추가되면서도, 기존 물체 정보는 유지할 수 있다.

이 과정을 반복하여 원하는 수준으로 Positive 샘플의 비율을 높일 수 있다. 결과적으로 학습 데이터셋 내 Positive 샘플의 수가 증가하게 되어, 객체 탐지 모델이 Positive 샘플을 더 많이 학습할 수 있게 된다. 이를 통해 모델의 일반화 능력이 향상되고, 테스트 데이터에 대한 정확도 또한 높아질 것으로 기대할 수 있다.


CutMix 알고리즘의 과정은 다음과 같다:

**Algorithm 1** CutMix for Object Detection
**Input:** Dataset $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N$, where $x_i$ is an image and $y_i = \{(b_j, c_j)\}_{j=1}^{M_i}$ is a set of bounding boxes $b_j$ and class labels $c_j$ for $M_i$ objects in $x_i$. Hyperparameters: maximum number of objects $M$, IoU threshold $\tau$.

**Output:** Augmented dataset $\mathcal{D}'$

1: $\mathcal{D}' \gets \emptyset$ 
2: **for** $(x, y)$ in $\mathcal{D}$ **do**
3:     $x' \gets x$ 
4:     $y' \gets y$
5:     $M' \gets |y'|$ 
6:     **while** $M' < M$ **do**
7:         Sample a donor image $(x_d, y_d)$ from $\mathcal{D}$ such that $|y_d| > 0$
8:         Sample an object $(b_d, c_d)$ from $y_d$ 
9:         $\mathcal{B} \gets \{b \in y' \mid \text{IoU}(b, b_d) < \tau\}$ 
10:        **if** $\mathcal{B} \neq \emptyset$ **then**
11:            $x'[\text{region}(b_d)] \gets x_d[\text{region}(b_d)]$ 
12:            $y' \gets y' \cup \{(b_d, c_d)\}$ 
13:            $M' \gets M' + 1$
14:        **end if**
15:    **end while**
16:    $\mathcal{D}' \gets \mathcal{D}' \cup \{(x', y')\}$
17: **end for**
18: **return** $\mathcal{D}'$


1. 원본 데이터셋 $\mathcal{D}$와 하이퍼파라미터(최대 물체 수 $M$, IoU 임계값 $\tau$)를 입력.
2. 증강된 데이터셋 $\mathcal{D}'$을 초기화 (line 1).
3. 데이터셋 $\mathcal{D}$의 각 이미지-주석 쌍 $(x, y)$에 대해 (line 2-17):
    - 이미지 $x'$와 주석 $y'$를 복사 (line 3-4).
    - 현재 물체 수 $M'$를 계산 (line 5).
    - $M' < M$인 동안 (line 6-15):
        - 물체가 있는 이미지를 $\mathcal{D}$에서 샘플링 (line 7).
        - 해당 이미지에서 물체 $(b_d, c_d)$를 샘플링 (line 8).
        - $y'$의 기존 바운딩 박스들 중 $b_d$와 IoU가 $\tau$ 미만인 바운딩 박스들의 집합 $\mathcal{B}$를 계산 (line 9).
        - $\mathcal{B}$가 비어있지 않다면 (line 10-14):
            - $x_d$의 영역 $b_d$를 $x'$의 해당 영역에 배치 (line 11).
            - $(b_d, c_d)$를 $y'$에 추가 (line 12).
            - $M'$를 1 증가 (line 13).
    - 증강된 이미지-주석 쌍 $(x', y')$을 $\mathcal{D}'$에 추가 (line 16).
4. 증강된 데이터셋 $\mathcal{D}'$를 출력 (line 18).

이렇게 CutMix 알고리즘을 적용하면, 원본 이미지에 새로운 Positive 샘플을 추가하여 Positive 샘플의 비율을 높일 수 있다. 이를 통해 Object Detection 모델이 Positive 샘플을 더 많이 학습할 수 있게 되어 성능 향상을 기대할 수 있다.




## 1. 서론

열화상 카메라는 물체의 열 방출 특성을 감지하여 이미지를 생성하는 센서이다. 열화상 이미지는 가시광선 이미지와 달리 해상도가 낮고 물체의 경계가 명확하지 않은 특징이 있다. 특히 물체가 겹쳐져 있는 경우, 개별 물체를 정확히 분류하는 것이 어려운 과제가 된다. 본 논문에서는 이러한 문제를 해결하기 위해 박스 좌표 예측, 클래스 분류, F1 점수를 결합한 복합 손실 함수를 제안하고, 그 효과를 실험적으로 입증한다.



## 2. 제안 손실 함수

우리는 객체 탐지 문제에 대해 복합적인 손실 함수를 제안한다. 이 손실 함수는 박스 좌표 예측(Box Regression), 클래스 분류(Classification), 그리고 F1 점수(F1 Score)를 모두 고려하며, Positive와 Hard Negative 샘플을 구분하여 다룬다. 

박스 손실(Box Loss) $L_{\text{box}}$는 예측된 박스 $y_{\text{pred}}$와 실제 박스 $y_{\text{true}}$ 간의 차이를 기반으로 계산된다.

$$
L_{\text{box}} = \sum_{i}\begin{cases}
0.5 \times (y_{\text{true},i} - y_{\text{pred},i})^2 & \text{if } |y_{\text{true},i} - y_{\text{pred},i}| \leq \delta\\
|y_{\text{true},i} - y_{\text{pred},i}| - 0.5 \times \delta & \text{otherwise}
\end{cases}
$$

여기서 $\delta$는 하이퍼파라미터이다. 이 손실 함수는 작은 오차에 대해서는 제곱 오차를, 큰 오차에 대해서는 절대 오차를 사용하여 박스 좌표 예측 성능을 향상시킨다.

F1 점수 손실 $L_{\text{f1}}$은 예측된 클래스 확률 $y_{\text{pred}}$와 실제 클래스 레이블 $y_{\text{true}}$로부터 계산된 F1 점수를 기반으로 한다.

$$
L_{\text{f1}} = 1 - \text{F1}
$$

$$
\text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall} + \epsilon}
$$

$\epsilon$은 0으로 나누는 것을 방지하기 위한 작은 상수이다. F1 점수는 정밀도(Precision)와 재현율(Recall)의 조화 평균으로, 두 지표를 균형있게 개선할 수 있다. 특히 물체 탐지 문제에서 정밀도와 재현율은 매우 중요한 평가 지표이므로, F1 점수를 최대화하는 것이 모델 성능 향상에 도움이 된다.

F1 점수 손실 $L_{\text{f1}}$은 0과 1 사이의 값을 가지며, 이를 최소화하면 F1 점수가 최대화된다. 이렇게 F1 점수를 직접 최적화함으로써 정밀도와 재현율의 균형을 잡을 수 있다. 기존의 손실 함수들은 이 두 지표를 명시적으로 최적화하지 않아 한쪽으로 치우치는 경향이 있었다.  

분류 손실 $L_{\text{cls}}$는 시그모이드 교차 엔트로피 손실과 Focal Loss의 아이디어를 결합한 형태이다.

$$
L_{\text{cls}} = -\alpha_t \times (1 - p_t)^\gamma \times \log(p_t)
$$


여기서 $\alpha_t$와 $p_t$는 다음과 같이 정의된다.
$$
\alpha_t = \begin{cases}
\alpha & \text{if } y_{\text{true}} = 1\\
1 - \alpha & \text{otherwise}
\end{cases}
$$

$$
p_t = \begin{cases}
y_{\text{pred}} & \text{if } y_{\text{true}} = 1\\
1 - y_{\text{pred}} & \text{otherwise}
\end{cases}
$$


이 손실 함수에서 $\alpha$는 클래스 불균형 문제를 완화하기 위해 사용되는 가중치이다. 양성 클래스의 샘플이 적을수록 $\alpha$를 높게 설정하여 양성 샘플에 대한 손실 기여도를 높일 수 있다. $\gamma$는 쉽게 예측할 수 있는 샘플의 손실 기여도를 낮추는 역할을 한다. 즉, $\gamma$가 클수록 어려운 샘플에 더 집중하게 된다.

이러한 방식으로 분류 손실 $L_{\text{cls}}$는 클래스 불균형 문제와 쉬운 샘플에 대한 과적합 문제를 동시에 완화할 수 있다. 특히 열화상 이미지에서 겹친 물체는 분류하기 어려운 샘플이므로, 어려운 샘플에 더 집중하는 $L_{\text{cls}}$가 이 문제를 해결하는 데 도움이 될 것이다.  


최종 손실 함수 $L_{\text{final}}$은 Positive와 Hard Negative 샘플에 대해 각각 정규화된 손실을 계산하고, 이를 결합하여 구한다.

$$
\begin{align*}
L_{\text{positive}} &= \frac{L_{\text{cls,pos}} + L_{\text{f1,pos}} + L_{\text{box,pos}}}{N_{\text{pos}}}\\
L_{\text{hard\_neg}} &= \frac{L_{\text{cls,hard\_neg}} + L_{\text{f1,hard\_neg}}}{N_{\text{hard\_neg}}}\\
L_{\text{cls}} &= \sqrt{L_{\text{cls,pos}} \times L_{\text{cls,hard\_neg}}}\\
L_{\text{f1}} &= \sqrt{L_{\text{f1,pos}} \times L_{\text{f1,hard\_neg}}}\\
L_{\text{combined}} &= \sqrt{L_{\text{cls}} \times L_{\text{f1}}}\\
L_{\text{final}} &= w_{\text{cls}} \times L_{\text{combined}} + w_{\text{box}} \times L_{\text{box,pos}}
\end{align*}
$$

여기서 $N_{\text{pos}}$와 $N_{\text{hard\_neg}}$는 각각 Positive와 Hard Negative 샘플의 수이며, $w_{\text{cls}}$와 $w_{\text{box}}$는 분류 손실과 박스 손실에 대한 가중치이다.

이 손실 함수의 주요 특징은 다음과 같다:

1) 박스 좌표 예측, 클래스 분류, F1 점수를 모두 고려하여 물체 탐지와 분류 성능을 종합적으로 향상시킨다.

2) Positive와 Hard Negative 샘플을 구분하여 다루고, 각각에 대해 정규화된 손실을 계산함으로써 모델이 어려운 샘플에 잘 적응할 수 있도록 한다.

3) 정규화와 가중치 기법을 도입하여 개별 손실 요소 간의 균형을 맞출 수 있다.

4) 기하 평균을 취함으로써 각 손실 요소의 상대적 중요도를 조절할 수 있다.

이러한 특징들로 인해 제안한 손실 함수는 저해상도 열화상 이미지에서 겹쳐진 물체를 효과적으로 분류할 수 있을 것으로 기대된다.





## 하드 네거티브 마이닝 (Hard Negative Mining)

하드 네거티브 마이닝은 객체 탐지 모델의 성능을 개선하기 위한 기법 중 하나이다. 이 기법은 모델이 잘못 예측한 어려운 네거티브 샘플(Hard Negative Sample)에 더 집중하도록 함으로써 모델의 일반화 능력을 향상시킨다.

**이론적 배경**

객체 탐지 문제에서 네거티브 샘플(Negative Sample)은 이미지 내에 물체가 없는 경우를 의미한다. 전통적인 학습 방식에서는 모든 네거티브 샘플에 대해 동일한 가중치를 부여하여 학습을 진행한다. 그러나 이렇게 되면 쉬운 네거티브 샘플에 비해 어려운 네거티브 샘플에 대한 학습이 부족해질 수 있다.

하드 네거티브 마이닝은 이러한 문제를 해결하기 위해 고안되었다. 이 기법은 모델이 잘못 예측한 어려운 네거티브 샘플에 더 많은 가중치를 부여하여 학습함으로써, 모델이 이러한 샘플에 더 잘 적응하도록 한다.


**알고리즘**

하드 네거티브 마이닝 알고리즘은 다음과 같이 동작한다:

**Algorithm 2** Hard Negative Mining
**Input:** Training set $\mathcal{T} = \{(x_i, y_i)\}_{i=1}^N$, where $x_i$ is an image and $y_i = \{(b_j, c_j)\}_{j=1}^{M_i}$ is a set of bounding boxes $b_j$ and class labels $c_j$ for $M_i$ objects in $x_i$. Hyperparameters: negative-positive ratio $r$, maximum number of hard negatives $k$.

1: Train the model on $\mathcal{T}$
2: Compute classification loss $L_{cls}$ and F1 score loss $L_{f1}$ on $\mathcal{T}$
3: Compute negative classification loss $L_{cls, neg}$ on negative samples
4: $N_{pos} \gets \sum_{i=1}^N \mathbb{1}[M_i > 0]$ // Number of positive samples
5: $k \gets \lfloor r \times N_{pos} \rfloor$ // Maximum number of hard negatives
6: $L_{hard\_neg} \gets \emptyset$ // Hard negative losses
7: $L_{cls, neg} \gets \text{sort\_descending}(L_{cls, neg})$ // Sort negative losses in descending order
8: **for** $i=1$ to $k$ **do**
9:     $L_{hard\_neg} \gets L_{hard\_neg} \cup \{(L_{cls, neg}[i], L_{f1, neg}[i])\}$
10: **end for**
11: $L_{pos} \gets \frac{1}{N_{pos}} \sum_{(x, y) \in \mathcal{T}, M > 0} (L_{cls, pos} + L_{f1, pos} + L_{box, pos})$
12: $L_{hard\_neg} \gets \frac{1}{k} \sum_{(l_c, l_f) \in L_{hard\_neg}} (l_c + l_f)$
13: $L_{cls} \gets \sqrt{\max(L_{pos, cls} \times L_{hard\_neg, cls}, \epsilon)}$
14: $L_{f1} \gets \sqrt{\max(L_{pos, f1} \times L_{hard\_neg, f1}, \epsilon)}$
15: $L_{combined} \gets \sqrt{\max(L_{cls} \times L_{f1}, \epsilon)}$
16: $L_{final} \gets w_{cls} \times L_{combined} + w_{box} \times L_{pos, box}$
17: Update the model using $L_{final}$


1. 모델을 학습 데이터셋으로 미리 학습 (line 1).
2. 학습 데이터셋에 대해 분류 손실과 F1 점수 손실을 계산 (line 2-3).
3. 네거티브 샘플에 대한 분류 손실을 계산하고, 이를 내림차순으로 정렬 (line 3, 7).
4. 하이퍼파라미터 $r$과 포지티브 샘플 수 $N_{pos}$를 이용하여 최대 하드 네거티브 샘플 수 $k$를 결정 (line 4-5).
5. 상위 $k$개의 네거티브 샘플을 하드 네거티브 샘플로 선택하고, 해당 샘플의 분류 손실과 F1 점수 손실을 저장 (line 8-10).
6. 포지티브 샘플과 하드 네거티브 샘플에 대한 손실을 계산하고, 이를 결합하여 최종 손실 함수를 구성(line 11-16).
7. 최종 손실 함수를 사용하여 모델 업데이트(line 17).


**장점**

하드 네거티브 마이닝의 주요 장점은 다음과 같다:

1. **일반화 능력 향상**: 모델이 어려운 네거티브 샘플에 더 잘 적응하게 되어 테스트 데이터에 대한 일반화 능력이 향상된다.
2. **오버피팅 방지**: 쉬운 네거티브 샘플에 과적합되는 것을 막아주어 모델의 오버피팅 문제를 완화할 수 있다.
3. **네거티브 샘플 불균형 해결**: 데이터셋 내 네거티브 샘플의 비율이 높은 경우, 하드 네거티브 마이닝을 통해 어려운 샘플에 더 집중함으로써 이 문제를 해결할 수 있다.

**제안 손실 함수에서의 적용**

본 논문에서 제안한 손실 함수에서는 하드 네거티브 마이닝 기법을 적용하였다. 구체적인 과정은 다음과 같다:

1. 모델을 통해 분류 손실($L_{cls}$)과 F1 점수 손실($L_{f1}$)을 계산한다.
2. 네거티브 샘플에 대한 분류 손실($L_{cls, neg}$)을 계산한다.
3. $L_{cls, neg}$가 높은 상위 k개의 샘플을 하드 네거티브 샘플로 선택한다. 여기서 k는 $N_{pos} \times r$로 결정되며, $N_{pos}$는 포지티브 샘플의 수, $r$은 하이퍼파라미터(네거티브-포지티브 비율)이다.
4. 하드 네거티브 샘플에 대한 $L_{cls, hard\_neg}$와 $L_{f1, hard\_neg}$를 계산하고, 이를 포지티브 샘플의 손실과 결합하여 최종 손실 함수를 구성한다.

이렇게 함으로써 모델은 어려운 네거티브 샘플에 더 집중하게 되어 일반화 능력이 향상된다. 특히 저해상도 열화상 이미지에서 겹친 물체 분류 문제의 경우, 배경과 물체를 구분하기 어려운 상황이 많기 때문에 하드 네거티브 마이닝 기법이 효과적일 것으로 기대된다.



## 3. 손실 함수 증명

우선 박스 손실 $L_{\text{box}}$는 회전 불변성(rotation invariance)과 이동 불변성(translation invariance)을 만족한다. 이는 아래와 같이 증명할 수 있다.

회전 불변성: $$ \begin{align*} L_{\text{box}}(R\mathbf{y}_{\text{true}}, R\mathbf{y}_{\text{pred}}) &= \sum_{i}\begin{cases} 0.5 \times \|R\mathbf{y}_{\text{true},i} - R\mathbf{y}_{\text{pred},i}\|^2 & \text{if } \|R\mathbf{y}_{\text{true},i} - R\mathbf{y}_{\text{pred},i}\| \leq \delta\\ \|R\mathbf{y}_{\text{true},i} - R\mathbf{y}_{\text{pred},i}\| - 0.5 \times \delta & \text{otherwise} \end{cases}\\ &= \sum_{i}\begin{cases} 0.5 \times \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\|^2 & \text{if } \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\| \leq \delta\\ \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\| - 0.5 \times \delta & \text{otherwise} \end{cases}\\ &= L_{\text{box}}(\mathbf{y}_{\text{true}}, \mathbf{y}_{\text{pred}}) \end{align*} $$

여기서 $R$은 회전 변환 행렬이다. 회전 변환 후에도 박스 손실의 값이 변하지 않음을 확인할 수 있다. 이는 회전에 대한 불변성을 의미한다. 즉, 박스의 회전 상태와 무관하게 손실 값이 동일하게 계산되므로, 회전 불변성을 만족한다.

이동 불변성: $$ \begin{align*} L_{\text{box}}(\mathbf{y}_{\text{true}} + \mathbf{t}, \mathbf{y}_{\text{pred}} + \mathbf{t}) &= \sum_{i}\begin{cases} 0.5 \times \|(\mathbf{y}_{\text{true},i} + \mathbf{t}) - (\mathbf{y}_{\text{pred},i} + \mathbf{t})\|^2 & \text{if } \|(\mathbf{y}_{\text{true},i} + \mathbf{t}) - (\mathbf{y}_{\text{pred},i} + \mathbf{t})\| \leq \delta\\ \|(\mathbf{y}_{\text{true},i} + \mathbf{t}) - (\mathbf{y}_{\text{pred},i} + \mathbf{t})\| - 0.5 \times \delta & \text{otherwise} \end{cases}\\ &= \sum_{i}\begin{cases} 0.5 \times \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\|^2 & \text{if } \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\| \leq \delta\\ \|\mathbf{y}_{\text{true},i} - \mathbf{y}_{\text{pred},i}\| - 0.5 \times \delta & \text{otherwise} \end{cases}\\ &= L_{\text{box}}(\mathbf{y}_{\text{true}}, \mathbf{y}_{\text{pred}}) \end{align*} $$

여기서 $\mathbf{t}$는 이동 벡터이다. 박스를 이동시켜도 손실 값이 변하지 않음을 확인할 수 있다. 이는 이동에 대한 불변성을 의미한다. 즉, 박스의 위치와 무관하게 손실 값이 동일하게 계산되므로, 이동 불변성을 만족한다.

이러한 회전 불변성과 이동 불변성은 박스 좌표 예측 문제에서 중요한 특성이다. 왜냐하면 물체의 위치와 방향에 영향을 받지 않고 일관된 손실 값을 산출할 수 있기 때문이다. 이를 통해 모델이 물체의 위치와 방향에 좀 더 강건해질 수 있다.

다음으로 F1 점수 손실 $L_{\text{f1}}$의 타당성을 살펴보자. 정밀도와 재현율은 모두 0과 1 사이의 값을 가지므로, 이들의 조화 평균인 F1 점수 역시 0과 1 사이에 있게 된다. 따라서 $L_{\text{f1}} = 1 - \text{F1}$은 항상 0과 1 사이의 값을 가지게 되어 유효한 손실 함수가 된다.

F1 점수는 정밀도와 재현율의 조화 평균으로, 두 지표를 균형있게 최적화할 수 있다. 이는 기존 손실 함수들이 정밀도와 재현율 중 한쪽으로 치우치는 경향이 있었던 것과 대조된다. 정밀도와 재현율은 물체 탐지 문제에서 매우 중요한 평가 지표이므로, F1 점수 손실 함수를 통해 두 지표를 균형있게 개선할 수 있다는 점에서 의미가 있다.

마지막으로 분류 손실 $L_{\text{cls}}$는 시그모이드 교차 엔트로피와 Focal Loss의 장점을 결합한 형태이다. 시그모이드 교차 엔트로피는 이진 분류 문제에서 널리 사용되는 손실 함수로, 안정적이고 신뢰할 수 있는 성능을 보인다. 한편, Focal Loss는 쉬운 샘플에 대한 손실 기여도를 줄이고 어려운 샘플에 집중할 수 있도록 해준다.

$$ L_{\text{cls}} = -\alpha_t \times (1 - p_t)^\gamma \times \log(p_t) $$

여기서 $\alpha_t$는 클래스 불균형 문제를 완화하기 위한 가중치이며, $\gamma$는 어려운 샘플에 더 집중하도록 하는 하이퍼파라미터이다. 만약 $\gamma$가 0이라면 기존 교차 엔트로피 손실이 되고, $\gamma$가 커질수록 쉬운 샘플의 손실 기여도가 작아진다.

이렇게 시그모이드 교차 엔트로피와 Focal Loss의 아이디어를 결합함으로써, 분류 손실 함수는 클래스 불균형 문제와 쉬운 샘플 과적합 문제를 동시에 완화할 수 있게 된다. 특히 열화상 이미지에서 겹친 물체는 분류하기 어려운 샘플이므로, 어려운 샘플에 더 집중하는 분류 손실이 이 문제를 해결하는 데 도움이 될 것으로 기대된다.

종합적으로, 제안한 손실 함수의 개별 요소들은 모두 이론적으로 타당성을 가지며, 각 요소의 장점을 결합함으로써 시너지 효과를 얻을 수 있다. 박스 손실은 회전과 이동 불변성을 만족하고, F1 점수 손실은 정밀도와 재현율의 균형을 잡아주며, 분류 손실은 클래스 불균형과 어려운 샘플 문제를 해결한다. 이를 통해 저해상도 열화상 이미지에서 겹친 물체 분류 성능을 향상시킬 수 있을 것으로 기대된다.


제안한 손실 함수에서 주목할 만한 또 다른 부분은 cls_loss와 f1_loss의 기하평균을 취하는 것이다.

$$L_{combined} = \sqrt{\max(L_{cls} \times L_{f1}, \; \epsilon)}$$

여기서 $L_{cls}$는 분류 손실(Classification Loss), $L_{f1}$는 F1 점수 손실(F1 Score Loss)을 나타내며, $\epsilon$는 0으로 나누는 것을 방지하기 위한 작은 상수($1 \times 10^{-6}$ 등)이다. $\max(\cdot)$는 최대값 함수를 의미한다.

기하평균을 취하는 이유는 두 가지 손실 요소 $L_{cls}$와 $L_{f1}$ 간의 균형을 맞추기 위함이다. 단순히 두 손실을 더하거나 평균을 취하는 경우, 한 손실의 값이 너무 크거나 작으면 다른 손실의 영향력이 감소할 수 있다. 하지만 기하평균을 취하면 이러한 문제를 완화할 수 있다. 

예를 들어, $L_{cls}$가 매우 큰 값을 가지고 $L_{f1}$가 작은 값을 가진다고 하자. 이 경우 단순 합이나 평균을 취하면 $L_{cls}$의 영향력이 지배적이 된다. 반대로 $L_{f1}$가 매우 큰 값을 가지면 $L_{f1}$의 영향력이 지나치게 크게 된다.

그러나 기하평균을 취하면 두 손실의 균형을 맞출 수 있다. 기하평균은 곱의 제곱근이므로, 큰 값과 작은 값의 곱에 제곱근을 취하면 중간 값을 가지게 된다. 이를 통해 한 손실의 영향력이 지나치게 크거나 작아지는 것을 방지할 수 있다.

또한, 기하평균은 두 손실 요소의 상대적 중요도를 조절할 수 있게 해준다. 예를 들어, $L_{f1}$의 가중치를 높이고 싶다면 $L_{cls} \times (L_{f1})^2$와 같이 지수를 조정할 수 있다. 이렇게 하면 $L_{f1}$의 영향력이 더 커지게 된다.

결과적으로, $L_{cls}$와 $L_{f1}$의 기하평균을 취함으로써 다음과 같은 이점을 얻을 수 있다:

1. 두 손실 요소 간의 균형을 맞출 수 있다.
2. 한 손실의 영향력이 지나치게 커지거나 작아지는 것을 방지할 수 있다.
3. 각 손실 요소의 상대적 중요도를 조절할 수 있다.

이러한 이유로 제안한 손실 함수에서는 $L_{cls}$와 $L_{f1}$의 기하평균을 취하는 방식을 채택하였다. 실제 실험 결과에서도 이 방식이 모델의 성능 향상에 기여한 것으로 확인되었다.



