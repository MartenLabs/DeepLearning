
![](../../Data/Models/obj_dct_1.png)


``` python
# Hyper parameter 설정 
num_classes = 80
batch_size = 2

learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]
learning_rate_boundaries = [125, 250, 500, 240000, 360000]

learning_rate_fn = tf.optimizers.schedules.PieceWiseConstantDecay(
	boundaries = learning_rate_boundaries, values = learning_rates
)

"""
tf.optimizers.schedules.PieceWiseConstantDecay는 텐서플로우에서 사용되는 학습률 스케줄링 함수로 학습 과정 중에 특정 단계에서 학습률(learning rate)을 조정하는데 사용

- boundaries: 이 리스트는 학습률이 변결될 훈련 스텝 또는(에폭)의 경계를 설정. 예를들어 learning_rate_boundaries = [125, 250, 500, 2400000, 360000] 는 학습 과정에서 스텝 125, 250, 500, 240000, 360000 에서 학습률이 변경되어야 함을 의미 

- values: 이 리스트는 각 경계 지점에서 사용될 새로운 학습률의 값을 제공. 이 리스트의 길이는 boundaries보다 하나 더 길어야 한다. 첫번째 값은 시작 학습률을 나타내고, 이후의 값들은 각 경계 지점 이후에 사용될 학습률이다.

스케줄링 방식을 사용하면 모델의 학습이 특정 단계에서 더 잘 수렴하도록 학습률을 조정할 수 있다. 
초기에는 높은 학습률로 시작하여 빠른 학습을 추구하고, 학습이 진행됨에 따라 학습률을 점차 낮추어 보다 세밀한 최적화를 진행할 수 있다. 이런 접근 방식은 과적합을 방지하고, 모델의 일반화 성능을 향상시키는데 도움이 될 수 있다.
"""
```

``` python
(train_dataset, val_dataset), dataset_info = tfds.load(
	"coco/2017", split=["train", "validation"], with_info = True, data_dir = './'
)

"""
with_info : 데이터셋에 대한 추가 정보 ex) 클래스 레이블, 데이터셋 크기 등 을 함께 로드

tfds.core.DatasetInfo( 
	name='coco', 
	full_name='coco/2017/1.1.0', 
	description= '''

	homepage='(http://cocodataset.org/#home)', 
	data_path='/data/coco/2017/1.1.0', 
	file_format=tfrecord, 
	download_size=25.20 GiB, 
	dataset_size=24.98 GiB, 
	features=FeaturesDict({ 
		'image': Image(shape=(None, None, 3), dtype=uint8), 
		'image/filename': Text(shape=(), dtype=string), 
		'image/id': int64, 
		'objects': Sequence({ 
			'area': int64, 
			'bbox': BBoxFeature(shape=(4,), 
			dtype=float32), 
			'id': int64, 
			'is_crowd': bool, 
			'label': ClassLabel(shape=(), dtype=int64, num_classes=80), 
		}), 
	}), 
	supervised_keys=None, 
	disable_shuffling=False, 
	splits={ 
		'test': <SplitInfo num_examples=40670, num_shards=64>, 
		'train': <SplitInfo num_examples=118287, num_shards=256>, 
		'validation': <SplitInfo num_examples=5000, num_shards=8>,
	})
"""
```

### Data 확인
``` python
for data in train_dataset.take(1):
	image = np.array(data['image'], dtype = np.uint8)
	plt.figure(figsize = (8, 8))
	plt.axis('off')
	plt.imshow(image)
	ax = plt.gca()

	boxes = data['objects']['bbox']
	image_h = image.shape[0]
	image_w = image.shape[1]

	boxes = tf.stack(
		[
		 boxes[:, 0] * image_h,
		 boxes[:, 1] * image_w,
		 boxes[:, 2] * image_h,
		 boxes[:, 3] * image_w
		], axis = -1
	)

	for box in boxes:
		ymin, xmin = box[:2]
		h, w = box[2:] - box[:2]
		patch = plt.Rectangle(
			[xmin, ymin], w, h, fill = False, 
										edgecolor = [1, 0, 0], linewidth = 2
		)
		ax.add_patch(patch)
	plt.show()

"""
plt.axis('off') : 보이는 모든 x, y, 레이블, 눈금 등을 숨김

ax = plt.gca() : 현재 활성돠된 축을 가져온다.

boxes = tf.stack([...], axis = -1) : 각 경계 상자의 좌표를 이미지의 크기에 맞게 조정 
이는 경계상자가 상태적인 값으로 저장되어 있기 때문에 필요

edgecolor = [1, 0, 0] : 빨간색 테두리 사용
linewidth = 2 : 두께 지정 
"""
```


### Data Augmentation
``` python
"""
행렬과 같은 tensor의 경우 행->열 순으로 되어 있기 때문에 (y좌표, x좌표) 순서로 저장되어 있다.
(x좌표, y좌표) 순서가 더 직관적으로 이해하기 쉬우므로 저장된 x, y좌표의 순서를 바꾸는 작업

함수의 입력은 (N, 4) shape의 bounding box 정보이며, bounding box좌표 정보는 양쪽 모서리의 
x, y 좌표값으로 되어있다고 가정

[0] [1] [2] [3]
 y   x   y   x

[1] [0] [3] [2]
 x   y   x   y
"""
def swap_xy(boxes):
	return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], 
																	axis = -1)
```

``` python
"""
bounding box의 위치 정보에 대한 format을 변경하는 함수 
(xmin, ymin, xmax, ymax) 형태의 bounding box format을 (x, y, w, h)로 바꿔서 반환

이 때 x, y는 bounding box의 center 좌표를 의미 
함수의 입력은 (N, 4)와 같이 2차원 이상의 tensor
"""

def convert_to_xywh(boxes):
	return tf.concat(
		[(boxes[..., :2] + boxes[..., 2:])/2.0, boxes[..., 2:] - boxes[..., :2]],
		  axis = -1
	)
"""
(xmin, ymin + xmax, ymax) / 2 = 중심점(x, y)

xmax, ymax - xmin, ymin = w, h 길이
"""
```

``` python
"""
bounding box의 위치 정보에 대한 format을 변경하는 함수 
(x, y, w, h) 형태의 bounding box format을 (xmin, ymin, xmax, ymax)로 바꿔서 변환

이 때 x, y는 bounding box의 center 좌표를 의미 
함수의 입력은 (N, 4)와 같이 2차원 이상의 tensor
"""
def convert_to_corners(boxes):
	return tf.concat(
		[boxes[..., :2] - boxes[..., 2:] / 2.0, 
						 boxes[..., :2] + boxes[..., 2:] / 2.0], axis = -1)

"""
boxes[N, 0] = x_center
boxes[N, 1] = y_center
boxes[N, 2] = width
boxes[N, 3] = height

x - w/2 = xmin
y - h/2 = ymin

x + w/2 = xmax
y + w/2 = ymax
"""
```

``` python
"""
Image resizing 함수 

짧은 변을 min_side와 같게 resize 
만약 긴 변의 길이가 max_side보다 클 경우에는 긴 변이 max_side와 같아지도록 다시 resize 

image size(가로, 세로 모두)가 stride의 배수가 아닐 경우 stride의 배수가 되도록 오른쪽과 아래쪽에
0을 채움(zero padding)

함수의 입력값 
- image : 3차원 tensor로 이루어진 image의 pixel 값(h, w, c)
- min_side : resize에 사용할 짧은 변의 길이 
- max_side : resize에 사용할 긴 변의 길이
- stride : 1번 입력인 image의 1 pixel이 실제 원본 image에서 몇 pixel에 해당되는지


함수의 반환값
- resize 및 padding된 image의 pixel값 
- padding 하기 전의 image size
- padding 하기 전 image와 원본 image의 확대/축소 비율(resize 후/resize 전)
"""

'''ex) 1200x1600 pixel image'''
def resize_and_pad_image(image, min_side=800.0, max_side=1333.0, stride=128.0):

	# 입력 이미지의 높이와 너비를 구하고, 이를 부동 소수점 타입으로 변환
	'''image_shape: [1200.0, 1600.0]'''
	image_shape = tf.cast(tf.shape(image)[:2], dtype = tf.float32)
	
	# 이미지의 가장 작은 차원을 min_side에 맟추기 위한 비율을 계산
	'''ratio: 800.0 / 1200.0 = 0.6667'''
	ratio = min_side / tf.redice_min(image_shape)

	# resize된 이미지의 가장 큰 차원이 max_side를 초과하는지 확인 
	# 만약 초과한다면 비율을 재조정 해 가장 큰 차원이 max_side가 되도록 설정
	'''ratio * 1600.0 = 0.6667 * 1600.0 = 1066.72 < 1333.0 ratio 는 변경되지 않음'''
	if ratio * tf.reduce_max(image_shape) > max_side:
		ratio = max_side / tf.reduce_max(image_shape)

	# resize된 이미지 크기 계산
	''' image_shape : 0.6667 * [1200.0, 1600.0] = [800.004, 1066.72]'''
	image_shape = ratio * image_shape

	# 이미지를 새로운 크기로 리사이즈 
	# tf.cast(image_shape, dtype = tf.int32) 는 resize될 크기를 정수형으로 변환
	# 이미지의 크기는 정수값 이여야 하기 떄문
	''' [800, 1067] '''
	image = tf.image.resize(image, tf.cast(image_shape, dtype = tf.int32))

	# 이미지의 각 차원을 stride로 나눈 후, 그 결과를 올림하여 각 차원이 stride의 배수가 되도록 설정
	''' 
	stride: 128.0
	tf.math.ceil(image_shape / stride) : [800.004, 128.0, 1066.72 / 128.0] 
	= [7, 9]

	padded_image_shape = [7 * 128, 9 * 128] = [896, 1152]
	'''
	padded_image_shape = tf.cast(
		tf.math.ceil(image_shape / stride) * stride, dtype = tf.int32	
	)

	# tf.image.pad_to_bounding_box는 이미지에 패딩 추가
	# 이 함수는 이미지의 위쪽과 왼쪽에 지정된 픽셀만큼 패딩을 추가하고, 이미지를 지정된 대상 크기 
	# (padded_image_shape)로 조정
	''' 최종 이미지 크기 : [896, 1152] (여기서 이미지는 위쪽과 왼쪽에 패딩이 추가됨)'''
	image = tf.image.pad_to_bounding_box(
		image, 0, 0, padded_image_shape[0], padded_image_shape[1]
	)
	'''
	tf.image.pad_to_bounding_box(
		image, offset_height, offset_width, target_height, target_width
	)

	- offset_height : 이미지의 위쪽에서부터 얼마나 떨어진 지점부터 패딩을 시작할지를 지정
					  이 값이 0이면 이미지의 맨 위부터 패딩을 시작
	
	- offset_width : 이미지의 왼쪽에서부터 얼마나 떨어진 지점부터 패딩을 시자할지 지정
					 이 값이 0이면, 이미지의 맨 왼쪽부터 패딩 시작

	- target_height : 패딩된 이미지의 최종 높이
	
	- target_width : 패딩된 이미지의 최종 너비
	'''

	return image, image_shape, ratio
	'''
	반환값: 패딩된 이미지[896, 1152], [800.004, 1066.72], 0.6667
	'''
```

``` python
"""
Horizontal flip 함수
- 50%의 확률로 이미지를 좌우 반전 
- 이 때 bounding box의 좌표도 좌우반전에 맞게 변경 
- 입력 이미지는 3차원 텐서
- bounding box의 좌표는 (xmin, ymin, xmax, ymax)로 구성되어 있고, 각각의 좌표는 0 ~ 1사이 값
- 함수의 반환값은 image의 pixel 값, bounding box의 좌표
"""

def random_flip_horizontal(image, boxes):
	if tf.random.uniform(()) > 0.5:
		image = tf.image.flip_left_right(image)
		boxes = tf.stack(
			[1 - boxes[:, 2], boxes[:, 1]. 1 - boxes[:, 0], boxes[:, 3], 
																	axis = 1])
"""
[0] [1] [2] [3]
 x   y   x   y
 
boxes[:, 1] (ymin), boxes[:, 3] (ymax) // 수평방향으로 뒤집기 때문에 건들필요 없음 

boxes[:, 2] (xmax) 
boxes[:, 0] (xmin)

new xmin = 1 - xmax (1 - boxes[:, 2])
new xmax = 1 - xmin (1 - boxes[:, 0])

ex) [0.1, 0.2, 0.4, 0.6] -> [0.6, 0.2, 0.9, 0.6]

new xmin = 1 - 0.4 = 0.6
new xmax = 1 - 0.1 = 0.9

ymin = 0.2
ymax = 0.6


random_flip_horizontal 함수는 이미지와 해당 이미지 내의 객체들의 bounding boxes를 무작위로 
수평 방향으로 뒤집는 역할을 한다. 이 과정에서 중요한 부분은 이미지를 뒤집은 후에 bboxes의 좌표도 
적절히 조정해야 한다는 것이다.

이미지를 수평으로 뒤집을 때, 상자의 수직 위치(y좌표)는 변하지 않지만, 수평 위치(x좌표)는 반대 방향으로 
이동하므로 xmin과, xmax의 값을 적절히 조정
"""

```

``` python
"""
Augmentation 함수 만들기 
- tf.data(dataset)에 map으로 적용할 수 있도록 함수를 작성 
- dataset의 itemp을 입력으로 받음
- 위에서 작성한 random_flip_horizontal 함수를 먼저 적용하고, 다음으로 resize_and_pad_image 
함수를 적용 
- 0 ~ 1 사이 값으로 normalized된 bounding box좌표를 실제 image size에 맞도록 조정
- bounding box 좌표를 (xmin, ymin, xmax, ymax) -> (x, y, w, h) 형태로 변경
- 함수의 반환 값은 image의 pixel값, bounding box의 좌표, class id
"""

def preprocess_data(sample):
	image = sample["image"]
	bbox = swap_xy(sample["objects"]["bbox"])
	class_id = tf.cast(sample["objects"]["label"], dtype = tf.int32)

	image, bbox = random_flip_horizontal(image, bbox)
	image, image_shape, _ = resize_and_pad_image(image)

	bbox = tf.stack([
		bbox[:, 0] * image_shape[1],
		bbox[:, 1] * image_shape[0],
		bbox[:, 2] * image_shape[1],
		bbox[:, 3] * image_shape[0]],
		axis = -1
	)
	bbox = convert_to_xywh(bbox)
	return image, bbox, class_id
```

### Anchor Box 정보 만들기 
``` python
_compute_dims : 각 level 별로 anchor box의 (w, h)를 계산해 반환
_get_anchors : 각 level 별로 anchor box의 (x, y, w, h)를 계산해 반환
			   이때 return shape은 (height * width * 9, 4)
get_anchors : _get_anchors의 level별 anchor box정보를 모두 합쳐서 최종 결과를 반환



- AnchorBox class를 만들고, get_anchors method를 call 하면 모든 anchor box의 
(x, y, w, h) 좌표를 반환 

- P3 ~ P7까지의 모든 level의 anchor box의 (x, y, w, h) 좌표가 반환되어야 함
- 계산의 편의성을 위해 먼저 각 level의 anchor box를 (height, width, 9, 4)의 shape을 갖는 
tensor로 만든다. 여기서 height, width는 각 level의 feature mpa size를 의미하며, 9는 각 
level의 anchor box 갯수이며 4는 (x, y, w, h)를 의미한다. 

- 최종적으로 반환되는 값은 (5 * height * width * 9, 4)의 형태가 되며 맨 앞의 5는 level의 갯수(P3, P4, P5, P6, P7)을 의미한다.


# class 내부의 method 

__init__method 
* anchor box정보 계산을 위한 기본 값 setting


_compute_dims method 
* _compute_dims 는 모든 level(P3 ~ P7)에 대해 각 level 별로 anchor box의 (w, h)를 계산하여 반환하는 역할 수행 
* anchor_dims_all list에 해당 정보가 저장되며 list의 원소는 각각 (1,1,9,2)의 shape을 갖는다.


_get_anchors method
* _get_anchors method는 각 level별로 anchor box의 (x, y, w, h)를 계산해 반환
* 반환값의 shape은 (height * width * 9, 4)


get_anchors method 
* get_anchors method는 _get_anchors를 통해 level별 anchor box의 정보를 받아 이를 모두 합쳐
  최종 결과를 반환
* 반환값의 shape은 (5 * height * widht * 9, 4)
```

