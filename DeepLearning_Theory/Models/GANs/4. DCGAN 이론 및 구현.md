


![[1. DCGAN_Model.png]]


### 요약 

DCGAN은 GAN의 개선 모델로 GAN과 다른 점은 다음과 같다

- D(Discriminator)
	- Strided Convolution을 사용
	- Batch Normalization을 사용. 입력 레이어 (첫번째)에는 사용하지 않는다
	- activation function으로 Leaky ReLU를 사용

- G(Generator) 
	- Fractional Strided Convolution(Transposed Convolution)을 사용
	- Batch Normalization을 사용. 출력 레이어(마지막)에는 사용하지 않는다.
	- activation function으로 ReLU를 사용하고 마지막 레이어는 tanh를 사용

$\star$논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미. 이 연산은 convolution의 역연산이 아님



### GAN Review

![[../../Data/논문_DCGAN/GAN_Model.png]]

![[Data/논문_DCGAN/이미지 분포.png]]

![[../../Data/논문_DCGAN/GAN_이론공식.png]]



### 기존 GAN의 한계

1. GAN의 결과가 불안정하다
	- 기존 GAN만 으로는 성능이 잘 나오지 않았다

2. Black-box method
	- Neural Network 자체의 한계라고 볼 수 있는데, 결정 변수나 주요 변수를 알 수 있는 다수의 머신러닝 기법들과 달리 Neural Network는 처음부터 끝까지 어떤 형태로 그러한 결과가 나오게 되었는지 그 과정을 알 수 없다.

3. Generative Model 평가
	- GAN은 결과물 자체가 새롭게 만들어진 Sample이다. 이를 기존 sample과 비교하여 얼마나 비슷한지 확인할 수 있는 정략적 척도가 없고, 사람이 판단하더라도 이는 주관적인 기준이기 때문에 얼마나 정확한지, 혹은 뛰어난지 판단하기 힘들다





### DCGAN의 목표

1. Generator가 단순 기억으로 generate하지 않는다는 것을 보여줘야 한다. 
2.  z(sampling 된 noise vector) 의 미세한 변동에 따른 generator 결과가 연속적으로 부드럽게 이어져야 한다. (이를 walking in the latent space라고 한다.)



### Architecture Guidelines

GAN과 DCGAN의 전체적인 구조는 거의 유사. 
다만 각각의 Discriminator와 Generator의 세부적인 구조가 달라진다.

논문발췌

``` txt
GAN에 CNN을 써서 이미지 품질을 높이려는 시도는 지금까지 성공적이지 못했다.

우리는 많은 시도 끝에 다양한 데이터셋에서 안정적인 그리고 더 높은 해성도의 이미지를 생성하는 모델 구조를 찾아내었다. 핵심은 다음 3가지를 CNN구조에 적용시키는 것이다.

1. max-pooling 과 같은 미분불가능한 레이어를 strided convolution으로 바꿔 
	spatial downsampling이 가능하게 한 것이다. 이는 G에 사용된 것이고, D에는 
	unsampling 이 가능하게 바꿨다

2. 요즘 트랜드는 FC(Fully Connected) Layer를 없애고 convolution layer로 바꾸는 것.

3. Batch Normalization을 사용하여 학습을 안정화시킨다
	(*2019년 현재 BN은 거의 필수처럼 되어 있다.) 
	이는 weight 초기화가 나쁘게 된 경우와 깊은 모델에서 gradient flow를 도우며,
	이는 학습 초기에 잘못된 방향으로 학습이 진행되어 망해가는 경우를 막아준다.

	그러나 sample이 요동치는 것을 막기 위해 G의 출력 레어이어와 D의 input layer에 
	는 넣지 않았다.(수많은 시도 끝에 알아냄)


G에서는 activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다. Bounded activation(tanh)은 더 빠르게 수렴하고 학습샘플의 분포를 따라갔다. 
D에는 Leaky ReLU를 사용하여 높은 해상도를 만들 수 있게 하였다. 

이는 GAN과 다른 부분이다. 
```







### 기존 GAN Architecture

![[../../gan-architecture.png]]




### CNN Architecture

![[../../cnn-architecture.png]]




### DCGAN Architecture

DCGAN은 결국, 기존 GAN에 존재했던 fully-connected 구조의 대부분을 CNN구조로 대체한것.

![[Architecture guidelines.png]]

- Discriminator에서는 모든 pooling layers를 strided convolutions로 바꾸고, Generator에서는 pooling layers를 fractional-strided convolution으로 바꾼다.

- Generator와 Discriminator에 batch-normalization을 사용한다. 논문에서는 이를 통해deep generators의 초기 실패를 막는다고 하였다. 그러나 모든 layer에 다 적용하면 sample oscillation과 model instability의 문제가 발생하여 Generator output layer와 Discriminator input layer에는 적용하지 않았다고 한다.

- Fully-connected hidden layers를 삭제한다.

- Generator에서 모든 활성화 함수는 ReLU를 쓰되, 마지막 출력단에서만 Tanh를 사용한다.

- Discriminator에서는 모든 활성화 함수를 LeakyReLU를 사용한다.







#### Strided Convolution이란?
![[../../padding_strides.gif]]


#### Fractionally-Strided Convolution이란?
![[../../padding_strides_transposed.gif]]

둘의 차이는 

기존 convolutions는 필터를 거치며 크기가 작아진 반면에 fractionally-strided convolution은 input에 padding을 하고 convolution을 수행하며 오히려 필터가 더 커지는 특징이 차이점 이다.

쉽게 transposed convolution이라고 불린다 논문에서는 Deconvolution이라고 불리는데 이는 잘못된 단어라고 한다.





##### Batch-normalization이란?

Batch Normalization은 최근 거의 모든 인경신경망에 쓰이고 있는 기법으로 기본적으로 Gradient Vanishing / Gradient Exploding이 일어나지 않도록 하는 아이디어 중의 하나이며, 지금까지는 이 문제를 Activation함수의 변화(ReLU 등), Careful Initialization, small learning rate 등으로 해결했지만, 이 논문에서는 이러한 간접적인 방법보다 training하는 과정 자체를 전체적으로 안정화하여 학습 속도를 가속시킬 수 있는 근본적인 방법을 제안하였다.


##### **Gradient Vanishing / Exploding 문제**

신경망에서 학습시 Gradient 기반의 방법들은 파라미터 값의 작은 변화가 신경망 출력에 얼마나 영향을 미칠 것인가를 기반으로 파라미터 값을 학습시키게 된다. 

만약 파라미터 값의 변화가 신경망 결과의 매우 작은 변화를 미치게 될 경우 파라미터를 효과적으로 학습 시킬 수 없게 된다.

**Gradient 라는 것이 결국 미분값 즉 변화량을 의미하는데 이 변화량이 매우 작아지거나(Vanishing) 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, Error rate 가 낮아지지 않고 수렴해버리는 문제가 발생** 하게 된다. 

그래서 이러한 문제를 해결하기 위해서 Sigmoid 나 tanh 등의 활성화 함수들은 매우 비선형적인 방식으로 입력 값을 매우 작은 출력 값의 범위로 squash 해버리는데, 가령 sigmoid는 실수 범위의 수를 [0, 1]로 맵핑해버린다. 

이렇게 출력의 범위를 설정할 경우, 매우 넓은 입력 값의 범위가 극도로 작은 범위의 결과 값으로 매핑된다. 

이러한 현상은 비선형성 레이어들이 여러개 있을 때 더욱 더 효과를 발휘하여(?) 학습이 악화된다. 

**첫 레이어의 입력 값에 대해 매우 큰 변화량이 있더라도 결과 값의 변화량은 극소가 되어버리는 것이다.** 

그래서 이러한 문제점을 해결하기 위해 활성화 함수로 자주 쓰이는 것이 **ReLU(Rectified Linear Unit)** 이다. 또한 아래와 같은 방법들도 존재한다. 

-   **Change activation function** : 활성화 함수 중 Sigmoid 에서 이 문제가 발생하기 때문에 ReLU 를 사용
-   **Careful initialization** : 가중치 초기화를 잘 하는 것을 의미
-   **Small learning rate** : Gradient Exploding 문제를 해결하기 위해 learning rate 값을 작게 설정함





### Generator Model 

![[1. DCGAN_Model.png]]

100 dimensional uniform distribution(Z) 이 들어오면 이들이 4개의 fractionally-strided convolution layer를 거치며 크기를 키워서 더 높은 차원의 64 x 64 pixel 이미지가 된다.




### Visualization 

**Generated bedrooms**
![[3. Figure_3.png]]

**Walking in the latent space**
![[4. Figure_4.png]]

앞서 DCGAN의 목표들 중 하나인 walking in the latent space를 직접 구현한 그림.

생성된 2개의 이미지에 사용된 noise인 $z$ 를 선형 보간하며 그 보간된 $z$ 로 이미지를 생성시켜본  결과 한 이미지에서 다른 이미지로 서서히 변해가는 결과를 얻었다. 
이미지를 보면 창문 없는 방이 거대한 창문이 있는 방으로 변해가거나, TV가 창문으로 변해가는 과정을 볼 수 있다.




**Visualize filters (no longer black-box)**
![[5. Figure_5.png]]
네트워크 내부의 각 필터는 이해할 수 없는 형식이 아닌 특정 object나 특징을 추출하였음을 알 수 있다.




**Applying arithmetic in the input space**
![[8. Glasses.png]]
![[7. Smilling.png]]
벡터 산술 연산을 통해 
vec(웃는 여자) - vec(무표정 여자) + vec(무표정 남자) = vec(웃는남자)
같은 결과를 얻을 수 있다.





---
# DCGAN

### Import 
``` python
from _future_ import print_function

import random
import torch
import torch.nn as nn
import torch.nn,parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils 
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML

manualSeed = 999
random.seed(manualSeed)
torch.manual_seed(manualSeed)
```


### Inputs 

- **dataroot** - 데이터셋 폴더의 root경로
- **workers** - DataLoader를 사용해 데이터를 로드하는데 사용하는 쓰레드 수
- **batch_size** - 훈련에 사용되는 배치 크기. DCGAN 논문에서는 배치 크기를 128로 사용
- **image_size** - 훈련에 사용되는 이미지 공간 크기. 이 구현은 기본적으로 $64 \times 64$로 설정
			    다른 크기를 원하는 경우 D 및 G의 구조를 변경해야 함
- **nc** - 입력 이미지의 색상 채널 수. color 이미지의 경우 3
- **nz** - latent vector 길이
- **ngf** - Generator를 통해 전달되는 feature map의 깊이와 관련
- **ndf** - Discriminator를 통해 전달되는 feature map의 깊이 설정
- **num_epochs** - 실행할 훈련 epoch 수. 더 긴 훈련은 보다 나은 결과를 얻을 수 있지만, 오랜 시간 소요
- **lr** - learning rate. DCGAN논문에서는 0.0002로 설정
- **beta1** - Adam 옵티마이저의 beta1 하이퍼파라미터. 논문에서는 0.5로 설정
- **ngpu** - 사용 가능한 GPU 수. 이 값이 0이면 코드가 CPU모드에서 실행됨. 이 숫자가 0보다 크면 해당 수의 GPU에서 실행

``` python
# 데이터셋 폴더의 root경로
dataroot = 'data/celeba'

# DataLoader를 사용해 데이터를 로드하는데 사용하는 쓰레드 수
workers = 8

# 훈련에 사용되는 배치 크기. DCGAN 논문에서는 배치 크기를 128로 사용
batch_size = 128

# 훈련에 사용되는 이미지 공간 크기. 이 구현은 기본적으로 $64 \times 64$로 설정 다른 크기를 원하는 경우 D 및 G의 구조를 변경해야 함
image_size = 64

# 입력 이미지의 색상 채널 수. color 이미지의 경우 3
nc = 3

# latent vector 길이
nz = 100

# Generator를 통해 전달되는 feature map의 깊이와 관련
ngf = 64

# Discriminator를 통해 전달되는 feature map의 깊이 설정
ndf = 64

# 실행할 훈련 epoch 수. 더 긴 훈련은 보다 나은 결과를 얻을 수 있지만, 오랜 시간 소요
num_epochs = 10

# learning rate. DCGAN논문에서는 0.0002로 설정
lr = 0.0002

# Adam 옵티마이저의 beta1 하이퍼파라미터. 논문에서는 0.5로 설정
beta1 = 0.5

# 사용 가능한 GPU 수. 이 값이 0이면 코드가 CPU모드에서 실행됨. 이 숫자가 0보다 크면 해당 수의 GPU에서 실행
ngpu = 1
```


### Data
``` python
# !pip install -U --no-cache-dir gdown --pre
# !gdown --id 1O8LE-FpN79Diu6aCvppH5HwlcR5I--PX
# !mkdir data
# !unzip img_align_celeba.zip -d data/
```


### Data Load

`transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))`가 이미지 데이터의 범위를 [-1, 1]로 변경하는 이유는, 이 변환 과정이 각 채널의 픽셀 값에 대해 정규화를 수행하기 때문. 

정규화는 다음 공식에 따라 수행
$\text{normalized\_pixel} = \frac{\text{pixel} - \text{mean}}{\text{std}}$

여기서,
- `pixel`은 원본 픽셀 값
- `mean`은 정규화할 때 사용되는 평균 값
- `std`는 정규화할 때 사용되는 표준편차 값

`transforms.ToTensor()`를 통해 이미지는 [0, 1] 범위의 픽셀 값을 가진 텐서로 변환. 
이때 (0.5, 0.5, 0.5)를 평균으로 하고, (0.5, 0.5, 0.5)를 표준편차로 사용하여 정규화하면, 결과적으로 픽셀 값의 범위가 [-1, 1]로 조정. 
이는 각 채널에서 0.5를 빼고 (평균을 0으로 만들고), 그 결과를 0.5로 나누어 (표준편차를 1로 만들어) 정규화하기 때문

예를 들어, [0, 1] 범위의 픽셀 값에 대해 정규화 과정을 적용
- 픽셀 값이 0.0인 경우: \((0.0 - 0.5) / 0.5 = -1.0\)
- 픽셀 값이 1.0인 경우: \((1.0 - 0.5) / 0.5 = 1.0\)

따라서, 이 정규화 과정을 통해 픽셀 값의 범위가 [-1, 1]로 조정. 
``` python
# 이미지 데이터셋을 로딩하기 위해 ImageFolder 클래스를 사용
dataset = dset.ImageFolder(root = dataroot,
						   # transform은 데이터에 적용할 전처리 목록을 정의
						   transform = transforms.Compose([
								transforms.Resize(image_size),
								transforms.CenterCrop(image_size),
								transforms.ToTensor(),
								# transforms.Normalize(mean, std)
									           #각 채널(RGB)의 평균(mean) # 각 채널의 표준편차(standard deviation)
								transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
						   ]))

dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,
										shuffle = True, num_workers = workers)

device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# 데이터 로더에서 첫 번째 배치를 가져옴. 
# dataloader는 데이터셋에서 미니배치를 순차적으로 로드 
# iter(dataloader)는 dataloader의 iterator를 생성하고, next() 함수는 iterator에서 다음 아이템(여기서는 첫번째 배치)을 가져옴
real_batch = next(iter(dataloader))
plg.figure(figsize = (8, 8))
plt.axis("off")
plt.title("Training Images")


# 실제 이미지 배치를 시각화
# vutils.make_grid() 함수는 여러 이미지를 그리드 형태로 배열하여 하나의 이미지로 만듦
# real_batch[0] 은 데이터 로더로부터 가져온 첫 번째 배치의 이미지 텐서
# [:64] 첫 64개의 이미지만 사용
# padding=2 는 이미지 간의 패딩을 2픽셀로 설정 
# normalize=True 는 이미지 픽셀 값을 [0, 1]범위로 정규화
# np.transpose(..., (1, 2, 0)) 는 텐서의 차원을 변경. PyTorch는 이미지를 (C, H, W) 형식으로 저장하지만, 
# matplotlib은 (H, W, C) 형식을 기대하므로 채널 차원을 맨 뒤로 이동
# 즉 첫번째 배치를 가져와서 거기 있는 64개의 이미지를 그리드로 그리는 코드
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], 
										 padding = 2, normalize=True).cpu(),(1, 2, 0))
```



### Weight Initialization (가중치 초기화)

DCGAN논문에서 저자들은 모든 모델 가중치가 평균 = 0, 표준편차 = 0.02 인 정규 분포에서 무작위로 초기화되어야 한다고 명시
weights_init 함수는 초기화된 모델을 입력으로 받고 모든 Conv2d, Conv2dTranspose 및 BatchNormalization Layer를 이 기준을 충족시키도록 다시 
초기화 한다. 이 함수는 모델이 초기화된 직후에 적용

``` python
# 가중치 초기화 함수
# 생성자(netG)와 판별자(netD)에 적용
def weights_init(m):
	# 모듈의 클래스 이름 반환
	classname = m.__class__.__name__
	if classname.find('Conv') != -1:
		# nn.init.normal_ 함수는 주어진 텐서를 in-place로 정규 분포를 사용해 초기화
		# 여기서 m.weight.data는 해당 층의 가중치 텐서를 의미하며, 평균 0.0, 표준펀차 0.02의 분포를 사용
		nn.init.normal_(m.weight.data, 0.0, 0.02)
	elif classname.find('BatchNorm') != -1:
		nn.init.normal_(m.weight.data, 1.0, 0.02)
		nn.init.constant_(m.bias.data, 0)
```



### Generator

Generator $G$ 는 잠재 공간 벡터 ($z$) 를 데이터 공간으로 매핑하는 것이 목표.
$z$ 를 데이터 공간으로 변환하면 최종적으로 훈련 이미지와 동일한 크기의 RGB 이미지를 만드는것 (즉 $3\times64\times64$)
실제로는 일련의 스트라이드된 2차원 Conv2dTranspose layer와 각각의 2차원 BatchNormalization layer와 ReLU Activation 함수와 함께 이를 수행,
Generator의 출력은 tanh 함수를 통해 다시 입력 데이터 범위인 $[-1, 1]$ 로 변환.
DCGAN 논문에서 BatchNormalization 함수의 존재를 언급하는 것이 중요하다. 이러한 레이어들은 훈련 중에 경사하강법(gradient-descent)의 흐름을 돕는 중요한 역할을 수행
![](../../Data/Models/GANs/4.DCGAN/1.png)

입력 섹션에서 설정한 입력(nz, ngf, nc)이 코드에서 Generator 아키텍쳐에 영향을 미치는 방식에 주목하면 nz는 z의 입력 벡터의 길이이고,
ngf는 생성기를 통해 전달되는 feature map의 크기와 관련이 있으며, nc는 출력 이미지의 채널 수(RGB 이미지의 경우 3으로 설정)



``` python
"""
# 입력 이미지의 색상 채널 수. color 이미지의 경우 3
nc = 3

# latent vector 길이
nz = 100

# Generator를 통해 전달되는 feature map의 깊이와 관련
ngf = 64

# Discriminator를 통해 전달되는 feature map의 깊이 설정
ndf = 64
"""
class Generator(nn.Module):
	def __init__(self, ngpu):
		super(Generator, self).__init__()
		self.ngpu = gpu
		self.main = nn.Sequential(
			# nz는 입력 벡터(z)의 차원, ngf는 생성자의 피처 맵 수
			# 이 층은 nz 차원의 입력을 받아 ngf*8 채널의 피처 맵을 출력
			nn.ConvTranspose2d(in_channels = nz, out_channels = ngf * 8,
							   kernel_size = 4, stride = 1,
							   padding = 0, bias = False),
			nn.BatchNorm2d(ngf * 8),
			nn.ReLU(inplace = True),
			# 출력 크기:  (ngf*8) x 4 x 4
			
			nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
			nn.BatchNorm2d(ngf * 4),
			nn.ReLU(True),
			# 출력 크기: (ngf*4) x 8 x 8
			
			nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
			nn.BatchNorm2d(ngf * 2),
			nn.ReLU(True),
			# 출력 크기: (ngf*2) x 16 x 16
			
			nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
			nn.BatchNorm2d(ngf),
			nn.ReLU(True),
			# 출력 크기: (ngf) x 32 x 32
			
			# 마지막 층: 최종 이미지를 생성
			# 출력 채널 수(nc)는 생성할 이미지의 채널 수
			nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
			nn.Tanh()
			# 출력 크기는 (nc) x 64 x 64가 됩니다. 
			# 활성화 함수로 Tanh를 사용하여 출력 값을 [-1, 1] 범위로 조정합니다.
			
		)

	def forward(self, input):
		return self.main(input)		
```

`nn.ConvTranspose2d`는 전치 합성곱(transposed convolution) 또는 분수 스트라이드 합성곱(fractionally-strided convolution)을 수행하여 입력 데이터의 공간 차원을 확장 
이 과정에서 입력 텐서의 크기를 `(nz, 1, 1)`에서 시작하여 더 큰 공간 차원으로 변환 가능  
`nz`가 100이라고 할 때, `in_channels=nz`는 입력 채널의 수를 의미 
여기서 주목해야 할 점은 전치 합성곱이 입력의 공간적 차원을 어떻게 확장하는지이다.

전치 합성곱 층의 출력 크기는 다음과 같은 공식에 의해 결정된다.
$$\text{H}_{\text{out}} = (\text{H}_{\text{in}} - 1) \times \text{stride} - 2 \times \text{padding} + \text{kernel\_size}$$

여기서,
- $( \text{H}_{\text{out}})$은 출력 높이,
- $( \text{H}_{\text{in}} )$은 입력 높이 (이 경우 1),
- `stride`는 스트라이드 값 (이 경우 1),
- `padding`은 패딩 값 (이 경우 0),
- `kernel_size`는 커널 크기 (이 경우 4)

이 공식을 사용하면 첫 번째 `nn.ConvTranspose2d` 층의 출력 높이와 너비가 어떻게 결정되는지 계산 가능하다.

$$\text{H}_{\text{out}} = (1 - 1) \times 1 - 2 \times 0 + 4 = 4$$
따라서, 첫 번째 `nn.ConvTranspose2d` 층의 출력은 `(ngf*8, 4, 4)`의 차원을 가지게 된다.
여기서 `ngf*8`은 이 층의 출력 채널 수. 
`ngf`는 생성자의 기본 필터 수를 의미하는 하이퍼파라미터이며, 이를 통해 모델의 용량을 조절할 수 있다.

요약하자면, 이 코드는 `nz` 차원의 잠재 벡터를 입력으로 받아, 내부적으로 공간 차원을 확장하는 전치 합성곱 연산을 수행하여 최종적으로 `(ngf*8, 4, 4)` 크기의 텐서를 출력한다. 이 과정은 초기 잠재 벡터에서 시작하여 점차적으로 이미지와 같은 고차원 데이터를 생성하는 과정을 구현한다.


### Why $z$ = 100?

z가 100이여도 1이여도 `nn.ConvTranspose2d` 층의 출력 크기는 동일하다. 하지만 `z`의 차원 수, 즉 잠재 벡터(`z`)의 크기를 1이 아닌 100과 같이 더 크게 설정하는 이유는, 모델이 학습할 수 있는 표현력과 다양성에 있다. 잠재 벡터의 크기가 커질수록, 생성자는 더 다양하고 복잡한 패턴과 특성을 학습하여 생성할 수 있는 가능성이 높아진다. 

### 1. 표현력(Expressiveness)
- 잠재 공간이 더 크면, 모델이 학습할 수 있는 데이터의 특성이 더 많아진다. 즉, 더 다양한 이미지를 생성할 수 있는 가능성이 커진다. `z`가 단일 차원이면, 이론적으로는 매우 제한적인 변화만 표현할 수 있다.

### 2. 다양성(Diversity)
- 더 큰 차원의 잠재 벡터는 생성된 이미지 간에 더 큰 다양성을 가능하게 한다. 잠재 공간의 각 차원은 생성 과정에서 다른 종류의 변화를 조절할 수 있으므로, 더 많은 차원을 가지면 더 세밀하고 다양한 이미지를 생성할 수 있다.

### 3. 학습의 용이성(Learnability)
- 잠재 벡터의 차원이 너무 작으면, 생성자가 학습 데이터의 복잡성을 충분히 모델링하기 어려울 수 있다. 적절한 크기의 잠재 공간은 학습 과정에서 모델이 데이터 분포를 더 잘 학습하게 만들 수 있다.

### 4. 실제 적용에서의 고려 사항
- `z`의 차원을 결정할 때는, 생성하고자 하는 데이터의 복잡성, 모델의 구조, 그리고 학습 과정에서의 계산 비용 등을 고려해야 한다. 너무 큰 차원은 모델의 학습을 어렵게 만들고, 계산 비용을 증가시킬 수 있다.

결론적으로, 잠재 벡터 `z`의 차원 수는 생성자가 생성할 수 있는 이미지의 품질과 다양성에 중요한 영향을 미친다. 따라서 `z`의 차원을 1로 설정하는 것과 100으로 설정하는 것 사이에는 생성된 이미지의 품질과 다양성 측면에서 큰 차이가 있을 수 있다. 적절한 차원 수는 실험을 통해 결정되며, 대상 데이터와 특정 응용 프로그램의 요구 사항에 따라 달라질 수 있다.



### Generator 가중치 초기화

이제 Generator를 인스턴스화 하고 `weights_init` 함수를 적용할 수 있다.
``` python
netG = Generator(ngpu).to(device)

if (device.type == 'cuda') and (ngpu > 1):
	netG = nn.DataParallel(netG, list(range(ngpu)))

# Generator 가중치 초기화
netG.apply(weights_init)

print(netG)

"""
Generator(
  (main): Sequential(
    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU(inplace=True)
    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): ReLU(inplace=True)
    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
    (13): Tanh()
  )
)
"""
```



### 멀티 GPU 사용

멀티 GPU 설정이 작동하는 방식을 이해하려면, PyTorch의 `nn.DataParallel` 모듈의 역할을 살펴볼 필요가 있다. 
`Generator` 클래스에 `ngpu` 인자를 넣는 것 자체로는 멀티 GPU에서 동작하도록 만들지 않는다. 
실제로 멀티 GPU 설정을 가능하게 하는 것은 `nn.DataParallel`을 사용하는 부분이다.

#### `nn.DataParallel`의 역할

- **모델 복제**: `nn.DataParallel`은 모델을 자동으로 여러 GPU에 복제한다. 즉, 각 GPU에 모델의 복사본이 생성되어 동시에 작동할 수 있게 된다.
- **데이터 분할**: 입력 데이터 배치가 `nn.DataParallel`에 의해 자동으로 여러 부분으로 나뉘며, 각각의 GPU에 분배된다. 이렇게 하여 각 GPU는 데이터의 한 부분을 처리하게 된다.
- **병렬 처리**: 각 GPU에서는 모델의 복사본을 사용하여 할당받은 데이터 부분을 독립적으로 처리한다. 이 과정은 병렬적으로 수행된다.
- **결과 수집**: 각 GPU에서 처리된 결과는 자동으로 한곳에 모아진다. 그리고 필요한 경우 결과들이 합쳐져 최종 출력이 생성된다.

### 코드 설명

```python
netG = Generator(ngpu).to(device)
```
- 여기서 `Generator` 인스턴스는 단일 GPU 또는 CPU로 이동된다. `ngpu`는 생성자에 전달되지만, `Generator` 내부에서는 별도로 멀티 GPU 설정에 사용되지 않는다.

```python
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))
```
- 이 조건문은 CUDA 환경이고 사용 가능한 GPU의 수(`ngpu`)가 1보다 클 때만 실행된다. `nn.DataParallel`을 사용하여 `netG` 모델을 감싸는 것으로 멀티 GPU 설정이 활성화된다.
- `list(range(ngpu))`는 사용할 GPU의 인덱스 리스트를 생성. 예를 들어, `ngpu`가 2라면 `[0, 1]`이 되어 첫 번째와 두 번째 GPU를 사용하게 된다.

결론적으로, `Generator` 클래스에 `ngpu`를 전달하는 것은 모델이 몇 개의 GPU를 기대하는지 알려주는 용도로만 사용된다. 실제 멀티 GPU 활성화와 데이터의 병렬 처리는 `nn.DataParallel`에 의해 이루어진다. `nn.DataParallel`은 모델을 여러 GPU에 분산시켜 병렬 처리를 가능하게 하는 핵심 메커니즘이다.




### Discriminator

$D$ 는 이미지를 입력으로 받고 해당 입력 이미지가 실제(가짜가 아닌)임을 나타내는 스칼라 확률을 출력하는 이진 분류 네트워크이다. 
여기서 $D$는 $3\times64\times64$ 입력 이미지를 받아 Conv2d, BatchNorm2d 및 LeakyReLU 레이어를 통해 처리하고 Sigmoid 활성화 함수를 통해 최종 확률을 출력한다. 이 아키텍쳐는 문제에 따라 더 많은 레이어로 확장될 수 있지만 strided convolution, BatchNorm 및 LeakyReLU의 사용에는 의미가 있다.
DCGAN 논문에서는 네트워크가 자체 Pooling 함수를 학습할 수 있도록 strided convolution을 사용하는 것이 좋은 실천 방법이라고 언급한다. 
또한 배치 정규화 및 LeakyReLU 함수는 $G$와 $D$의 학습 과정에 대한 건전한 기울기 흐름을 촉진하는데 중요하다.

$$\text{output\_size} = \left\lfloor \frac{\text{input\_size} + 2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} \right\rfloor + 1$$
``` python
class Discriminator(nn.Module):
	def __init__(self, ngpu):
		super(Discriminator, self).__init__()
		self.ngpu = ngpu
		self.main = nn.Sequential(
			# input is (nc) x 64 x 64
			
		)
```



























































