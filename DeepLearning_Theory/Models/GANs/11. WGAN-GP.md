


# WGAN-GP 논문

Wasserstein GAN (WGAN)은 GAN의 문제점 중 하나인 mode collapse를 해결하고 안정적인 학습을 가능하게 하는 방법으로, Wasserstein 거리를 사용하는 방식을 도입한 모델입니다. 이전의 GAN에서는 JS-divergence와 KL-divergence를 사용하여 생성자와 실제 데이터 분포 사이의 차이를 계산했지만, WGAN에서는 Wasserstein 거리를 사용하므로써 분포 간의 차이를 더 정확하게 계산할 수 있습니다.

WGAN에서는 Wasserstein 거리를 최소화하는 방향으로 생성자를 학습시킵니다. 이때, 판별자는 임의의 함수가 아니라 Lipschitz 연속 함수여야 합니다. 하지만, 이 조건을 강제하면서 모델을 학습시키는 것은 어렵기 때문에, 이 논문에서는 가중치 클리핑(Weight Clipping)을 도입하였습니다. 이 방법은 판별자의 가중치 값을 일정한 범위 내에서 고정시켜, Lipschitz 연속 함수의 조건을 만족시키는 것입니다.

하지만 가중치 클리핑은 학습 과정에서 불안정성을 유발시키는 원인 중 하나입니다. 이러한 문제를 해결하기 위해, 이 논문에서는 gradient penalty를 도입하여 안정적인 학습을 가능하게 했습니다. Gradient penalty는 판별자의 gradient를 일정한 범위 내로 제한하여 Lipschitz 연속 함수의 조건을 만족시키는 것입니다.

이 논문에서는 WGAN-GP(Wasserstein GAN with Gradient Penalty)라는 모델을 제안하였습니다. 이 모델은 가중치 클리핑과 gradient penalty를 모두 사용하여 안정적인 학습을 가능하게 합니다. 또한, 이 모델은 기존의 WGAN에 비해 더욱 안정적이고 효과적인 학습을 할 수 있게 되었습니다.

WGAN-GP의 학습 방법은 다음과 같습니다. 우선, 생성자는 무작위 노이즈 벡터를 입력으로 받아 가짜 이미지를 생성합니다. 이 가짜 이미지와 실제 이미지를 판별자에게 입력으로 주고, 판별자는 이 두 이미지가 얼마나 실제와 가까운지를 계산하여 출력합니다. 이때, 판별자의 출력값을 최대화하는 방향으로 실제 이미지의 판별 결과를 학습시키고, 가짜 이미지의 판별 결과를 최소화하는 방향으로 생성자를 학습시킵니다.

이때, 가중치 클리핑과 gradient penalty를 적용하는 방법은 다음과 같습니다. 먼저, 가중치 클리핑은 판별자의 가중치 값을 일정한 범위 내에서 고정시키는 것입니다. 이를 통해 판별자가 Lipschitz 연속 함수의 조건을 만족시킬 수 있게 됩니다. 그러나 가중치 클리핑은 학습 과정에서 불안정성을 유발시키는 원인 중 하나입니다. 이러한 문제를 해결하기 위해, gradient penalty를 도입합니다. Gradient penalty는 판별자의 gradient를 일정한 범위 내로 제한하여 Lipschitz 연속 함수의 조건을 만족시키는 것입니다.

WGAN-GP에서는 생성자와 판별자의 아키텍처를 일반적인 CNN에서 벗어나서, fully connected layer와 batch normalization을 사용하지 않고, convolutional layer와 instance normalization을 사용하였습니다. 이를 통해 생성된 이미지의 퀄리티를 높이는 데에 성공하였습니다.

WGAN-GP의 손실 함수는 다음과 같이 정의됩니다.

$L_{WGAN-GP}(D,G) = E_{x \sim p_{data}}[D(x)] - E_{z \sim p_{z}}[D(G(z))] + \lambda E_{\tilde{x} \sim p_{\tilde{x}}}[(||\nabla_{\tilde{x}}D(\tilde{x})||_2 - 1)^2]$

여기서 첫 번째 항은 실제 이미지의 판별 결과를 최대화하는 항이며, 두 번째 항은 가짜 이미지의 판별 결과를 최소화하는 항입니다. 세 번째 항은 gradient penalty를 나타내며, $\tilde{x}$는 실제 이미지와 가짜 이미지의 비율을 조절하는 매개변수입니다. $\lambda$는 gradient penalty의 강도를 조절하는 하이퍼파라미터입니다.

WGAN-GP는 mode collapse 문제를 해결하고 안정적인 학습을 가능하게 하여, 다양한 이미지를 생성하는 데에 성공하였습니다. 이 모델은 현재까지도 GAN 모델의 대표적인 방법 중 하나로 평가되고 있습니다.



### Mini batch
배치는 컴퓨터의 데이터 처리 형태의 하나로, 처리해야 할 데이터를 일정 기간 동안 일정량 정리하여 처리하는 것을 의미합니다. 컴퓨터 시스템에서 처리의 대상이 되는 데이터를 일 단위나 월 단위마다 모아두고 그것을 하나로 종합하여 처리하는 것을 배치 처리, 또는 일괄처리라고 합니다. 인공지능이 학습을 할 때 거대한 양의 데이터를 한꺼번에 학습하지 않고 단위 별로 쪼개서 하는 것을 미니 배치라고 합니다. 미니 배치로 학습하는 이유는 데이터가 많아질 때 길어지는 시간이나 데이터의 손실을 줄이기 위해서입니다.



### Instance normalization
Instance normalization은 주로 이미지 생성 분야에서 사용되는 정규화 방법 중 하나로, 각 샘플의 feature map에서 평균과 분산을 구하여 정규화하는 방법입니다.

기존의 Batch Normalization은 하나의 미니배치 단위로 평균과 분산을 구해 정규화하는 방법이었습니다. 하지만 생성자에서는 미니배치가 없기 때문에, Batch Normalization을 사용하기 어려웠습니다. 이를 해결하기 위해 각 샘플에 대해 평균과 분산을 구하여 정규화하는 Instance Normalization이 제안되었습니다.

Instance normalization은 각 샘플의 평균과 분산을 구하는 것으로, 채널 간의 상관 관계를 고려하지 않습니다. 이를 통해 채널 간의 상관 관계를 유지하면서, 이미지의 일관된 특성을 유지할 수 있습니다. 이는 이미지 생성 분야에서 매우 유용한 방법 중 하나로, 최근에는 GAN 모델을 학습시키는 데에 널리 사용되고 있습니다.


### Lipschitz 
Lipschitz 연속성(Lipschitz continuity)은 수학에서 함수의 안정성(stability)과 연관된 개념 중 하나입니다. 함수의 안정성이란 입력값이 조금만 바뀌어도 출력값이 크게 변하지 않는 것을 의미합니다. 예를 들어, 함수 f(x) = x^2는 x가 조금만 변해도 출력값이 크게 변하므로, 안정적이지 않습니다. 반면 함수 f(x) = 2x는 x가 변하더라도 출력값이 일정하게 변하기 때문에, 안정적입니다.

Lipschitz 연속성은 함수의 기울기를 제한하는 것으로, 함수 f(x)가 k-Lipschitz 연속 함수이다는 것은 모든 x, y에 대해 |f(x) - f(y)| ≤ k|x - y|를 만족하는 k가 존재한다는 것을 의미합니다. 이를 간단히 말하면, 함수의 기울기가 얼마 이상 커지지 않는다는 것입니다.

GAN에서는 판별자와 생성자가 각각 함수로 구현되어 있으며, 이 함수들이 Lipschitz 연속성을 만족하지 않으면 안정적인 학습이 어렵습니다. 따라서 WGAN과 같은 몇몇 GAN 모델에서는 Lipschitz 연속성을 강제하기 위해 판별자와 생성자의 가중치를 일정한 범위로 제한하거나, 그래디언트 패널티(gradient penalty)를 사용합니다. 이를 통해 안정적인 학습을 가능하게 하고, 좀 더 안정적이고 다양한 이미지를 생성할 수 있게 됩니다.



### Weight Clipping
Weight Clipping은 GAN 모델에서 판별자의 가중치 값을 일정한 범위로 제한하는 방법입니다. WGAN과 WGAN-GP에서 Lipschitz 제약 조건을 강제하기 위해 사용되었습니다.

GAN 모델에서 판별자의 출력값은 0에서 1 사이의 값을 갖게 되며, 이를 위해 시그모이드 함수를 사용합니다. 하지만 이 때문에 판별자의 가중치 값이 커지게 되면, 시그모이드 함수의 미분 값이 0에 가까워져, 학습이 어려워지거나 불안정해질 수 있습니다.

이를 방지하기 위해 Weight Clipping은 판별자의 가중치 값을 일정한 범위 내에서 고정시키는 것입니다. 예를 들어, 가중치를 -0.01에서 0.01 사이로 제한하는 방법이 있습니다. 이를 통해 판별자가 Lipschitz 연속성을 만족하도록 하며, 안정적인 학습을 가능하게 합니다.

그러나 Weight Clipping은 판별자의 학습을 제한하는 원인이 될 수 있으며, 이를 보완하기 위해 gradient penalty를 사용하는 WGAN-GP가 제안되었습니다. Gradient penalty는 가중치 제한 없이 Lipschitz 제약 조건을 강제하는 방법으로, 안정적인 학습을 가능하게 하며, Weight Clipping으로 인한 불안정성을 해결할 수 있습니다.



### 본편

# Abstract

GAN은 파워풀한 생성 모델이지만, 학습의 불안정성을 겪는다. 최근에 제안된 Wasserstein GAN (WGAN)은 GAN의 안정적인 학습으로 진전했지만, 가끔 아직도 안좋은 샘플들을 생성하거나 수렴에 실패하기도 한다. 우리는 이러한 문제를 바람직하지 않은 behavior로 이끌 수 있는 critic에 Lipschitz constraint를 부과하기 위해 WGAN에서 weight clipping을 사용하기 때문이라고 발견했다. 우리는 가중치를 clipping 하는 것의 대안을 제안한다: critic의 입력에 대해서 gradient의 norm에 패널티를 부여한다. 우리의 방법은 보통의 WGAN보다 좋은 성능을 보이고, 101개의 ResNet과 연속적인 generator의 언어 모델을 포함하여 하이퍼라마티어 튜닝 없이 넓고 다양한 GAN 아키텍쳐의 학습을 안정화 하는 것을 가능하게 한다. 우리는 또한 CIFAR10과 LSUN 데이터셋에서 좋은 퀄리티를 얻었다.


# 1. Introduction
Generative Adversarial Networks (GAN)은 생성 모델링을 두개의 네트워크의 게임으로 캐스팅하는 파워풀한 생성 모델의 한 분야이다: generator 네트워크는 몇몇의 노이즈 소스가 주어졌을 때 합성 데이터를 생성하고 discriminator 네트워크는 generator의 출력과 실제 데이터 사이를 구분한다. GAN은 시각적으로 매우 매력적인 샘플들을 생성하지만, 종종 학습하기 어렵고, 주제에서 몇몇의 연구는 학습을 안정화 시키도록 하는 방법을 찾는데 전념했다. 그럼에도 불구하고, 지속적으로 GAN의 학습을 안정화 시키는 것은 아직도 열린 문제로 남아있다.

특히, [1]은 GAN에 의해 최적화되는 value function의 수렴 특성의 분석을 제공한다. Wasserstein GAN (WGAN)이라 부르는 그들의 대안은 원래의 것보다 더 이론적인 특성을 가지고 있는 value function을 생성하도록 Wasserstein distance를 사용한다. WGAN은 discriminator가 작가들은 weight clipping을 통해 부여한, 반드시 1-Lipschitz function의 공간에 있음을 요구한다.

우리의 기여는 다음과 같다:

1.  toy dataset에서, 우리는 critic weight clipping이 바람직하지 않은 behavior로 이끌 수 있음을 증명한다.
2.  우리는 같은 문제를 겪지 않는 gradient penalty (WGAN-GP)를 제안한다.
3.  우리는 다양한 GAN 아키텍쳐에서 안정적인 학습과, weight clipping을 넘는 성능 증가, 높은 퀄리티의 이미지 생성, discrete sampling 없이 character-level GAN 언어 모델을 증명한다.


# 2. Background

## 2.1 Generative adversarial networks

GAN의 학습 전략은 두개의 경쟁적인 네트워크 사이의 게임으로 정의된다. generator 네트워크는 노이즈의 소스를 입력 공간으로 맵핑한다. discriminator 네트워크는 생성된 샘플 또는 실제 데이터를 받고 반드시 두개 사이를 구분해야 한다. generator는 안좋은 discriminator를 학습하도록 한다.

공식적으로, generator G와 discriminator D 사이의 게임은 minmax objective이다.
![](../../Data/논문_WGAN-GP/GP_1.png)
$P_r$ 은 데이터 분포이고  Pg는 암묵적으로 ~x=G(z), z∼p(z)에 의해 정의된 모델의 분포이다.

만약 discriminator가 각각의 generator 파라미터 업데이트 전에 최적성으로 학습이 된다면, value function을 최소화하는 것은 $P_r$ 와 $P_g$ 사이의 Jensen-Shannon divergence를 최소화 하는 것과 같지만, 그렇게 하면 판별자가 포화될 때 그래디언트가 사라지는 경우자 종종 있다. 특히, 이 어려움을 우회하는 방법인, $\mathbb{E}_{\tilde{\boldsymbol{x}} \sim \mathbb{P}_{g}}[\log (D(\tilde{\boldsymbol{x}}))]$ 를 최대화 하는 것을 대신 되어야 한다고 주장한다. 하지만, 심지어 변형된 loss function은 좋은 discriminator 존재에서 잘못 행동되어질 수 있다.

## 2.2 Wasserstein GANs

[2]는 GAN이 전형적으로 최소화 하는 것이 generator의 파라미터에 대해서 잠재적으로 연속적이지 않은 divergence는 학습의 어려움을 이끈다고 주장한다. 그들은 대신에 Earth-Mover (또한 Wasserstein-1이라 불리는 distance W(q,p)를 사용했고, 이것은 분포 q를 분포 p로 변형하기 위한 transporting mass의 최소 비용으로 정의되었다. 가벼운 가정하에, W(q,p)는 어느곳에서나 연속적이고 거의 모든곳에서 미분가능하다.

WGAN의 value function은 Kantorovich-Rubinstein duality를 사용하여 구성되었다.
![](../../Data/논문_WGAN-GP/GP_2.png)

D는 1-Lipschitz function의 집합이고 Pg

는 ~x=G(z), z∼p(z) 에 의해 정의된 모델의 분포이다. 이 경우에, 최적의 discriminator 하에, generator 파라미터에 관련된 value function을 최소화 하는 것은$W\left(\mathbb{P}_{r}, \mathbb{P}_{g}\right)$ 를 최소화한다.

WGAN의 value function은 입력이 GAN의 대응보다 더 잘 작동하는 gradient를 가지는 critic function의 결과를 얻고 generator의 최적화를 더 쉽게 만든다. 실험적으로, WGAN의 value function은 GAN의 case에 해당되지 않는 샘플 퀄리티와 관련된 것을 보임을 관찰했다.

critic에 Lipschitz constraint를 부과하기 위해서, [2]는 compact space [-c, c]안에 critic의 가중치가 놓여지도록 clip하는 것을 제안한다. 이 constraint를 만족하는 함수의 집합은 c와 critic 아키텍쳐에 의존하는 k를 위한 k-LIpschitz function의 부분집합이다. 다음 secion에서는, 우리는 이러한 접근법의 몇가지 이슈를 증명하고 대안을 제안한다.


## 2.3 Properties of the optimal WGAN critic

WGAN의 critic에서 왜 weight clipping이 문제가 있었는지 이해하고 우리의 접근법을 동기부여 하기 위해서, 우리는 WGAN 프레임워크에서 최적의 critic의 몇가지 특성을 하이라이트 한다.

# 3. Difficulties with weight contraints

우리는 WGAN에서 weight clipping이 최적화 어려움을 이끈다는 것을 발견했고, 심지어 최적화의 성공이 critic이 pathological value surface를 갖게 하는 결과를 이끈다. 우리는 이러한 문제를 아래에 설명했고 이것들의 효과를 증명한다; 하지만 우리는 각각의 것이 실제로 항상 발생한다는 것을 주장하지 않고 이것들은 오직 메커니즘이다.

우리의 실험은 [2]로부터의 weight constraint 특정한 형식을 사용하지만, 우리는 또한 다른 weight constraint도 시도했고 이것들이 비슷한 문제를 보임을 발견했다.

이러한 문제는 어느정도 [2]에서 그들의 모든 실험에 사용된 critic에서 batch normalization과 함께 완화될 수 있다. 하지만 심지어 batch normalization에서도, 우리는 매우 깊은 WGAN critic이 종종 수렴에 실패한다는 것을 관찰했다.
![](../../Data/논문_WGAN-GP/GP_3.png)




## 3.1 Capacity underuse

weight clipping을 통해서 k-Lipschitz constraint를 부과하는 것은 critic을 더 간단한 함수로 편향시킨다. 이전에 Corolalry 1에서 말한데로, 최적의 WGAN critic은 Pr

과 Pg 아래에 거의 모든 곳에서 unit gradient norm을 가진다; weight-clipping constraint 하에서, 우리는 gradient norm k를 최대화하도록 얻도록 시도하는 우리의 뉴럴 아키텍쳐들이 굉장히 쉬운 함수의 학습으로 마친다는 것을 발견했다.

이것을 증명하기 위해서, 우리는 weight clipping과 함께한 WGAN critic을 몇몇의 toy 분포에 대한 최적성으로 학습했고, generator 분포 Pg는 실제 분포 더하기 unit-variance Gaussin noise에서 고정되었다. 우리는 critics의 value surface를 Figure 1a에 그렸다. 우리는 critic에서 batch normalization은 생략했다. 각각의 경우에서, weight clipping과 함께 학습된 critic은 데이터 분포의 더 높은 순간을 무시하고 대신에 모델은 최적화 함수로 매우 간단한 근사를 한다. 반대로, 우리의 방법은 이러한 behavior로부터 겪지 않는다.


## 3.2 Exploding and vanishing gradients

우리는 clipping threshold c의 조심스러운 튜닝 없이 gradient가 vanishing 또는 exploding 하는 결과를 일으키는 weight constraint와 cost function 사이의 상호작용 때문에 WGAN의 최적화 과정은 어렵다고 관찰했다.

이것을 증명하기 위해서, 우리는 clipping threshold c를 다르게 하면서 Swiss Roll toy 데이터셋에서 WGAN을 학습했고, 성공적인 activation의 layer에 대해서 critic loss의 gradient의 norm을 표로 그렸다. generator와 critic 둘 다 batch normalization 없이 12 layer ReLU MLP이다. Figure 1b는 이러한 value들을 보여주고, gradient는 네트워크 안에서 움직일 때 마다 지수적으로 자라거나 decay 된다. 우리는 우리의 방법이 더 복잡한 네트워크의 학습을 허락하면서 사라지거나 폭발하지 않는 더 안정적인 gradient의 결과를 가짐을 찾았다.
![](../../Data/논문_WGAN-GP/GP_4.png)


# 4. Gradient penalty

우리는 이제 Lipschitz constraint을 부과하는 대안의 방법을 제안한다. 미분가능한 함수는 1-Lipschitz 함수이고 norm과 함께한 gradient가 어디에서나 1이 되고, 그래서 우리는 입력에 대해서 critic의 출력의 gradient norm을 직접적으로 구속하는 것을 고려한다. 다루기 쉬운 문제를 피하기 위해, 우리는 랜덤 샘플 ^x∼P^x를 위해 gradient norm에 penalty가 있는 contraint의 부드러운 버전을 부과한다.
![](../../Data/논문_WGAN-GP/GP_5.png)



### Sampling distribution

우리는 P^x 샘플링을 데이터 분포 Pr 과 generator 분포 Pg 로 부터 샘플된 점 사이의 직선을 따라 uniform하게 정의한다. 이것은 최적의 critic이 $\mathbb{P}_{r}과\; \mathbb{P}_{g}$ 로부터의 점 사이를 연결하는 gradient norm 1과 함께 직선을 포함한다는 사실로부터 동기부여 됬다. unit gradient norm constraint을 모든곳에 부과하기는 어려운 일이므로, 단지 이러한 직선을 따라 부과하는 것은 충분에 보이고 실험적으로 좋은 성능을 보이는 것 같다.

### Penalty coefficient
본 논문에서 모든 실험은 lambda=10을 사용했고, 우리는 toy task에서 큰 ImageNet CNN 까지 다양한 아키텍쳐와 데이터셋에서 잘 작동하는 것을 발견했다.


### No critic batch normalization

대부분의 이전의 GAN implementation에서는 학습을 안정화시키기 위해서 generator와 discriminator 둘 다에 batch normalization을 사용하지만, batch normalization은 discriminator의 문제의 형태를 단일 출입력을 단일 출력으로 맵핑하는 것에서 입력의 모든 배치로부터 출력의 배치를 맵핑하는 것으로 변화시킨다. 우리의 패널티가 부과된 학습 목점함수는 우리가 전체의 배치가 아니라 각각의 입력에 독립적으로에 대해서 critic의 gradient의 norm에 패널티를 부과하기 때문에 더이상 이러한 셋팅이 유효하지 않다. 이러한 문제를 해결하기 위해서, 우리는 우리의 모델의 critic에서 batch normalization을 간단하게 생략하고, 이것이 없이 잘 작동하는 것을 찾았다. 우리의 방법은 예시들 사이의 correlation을 도입하지 않는 normalization 방법과 함께 작동한다. 특히, 우리는 batch normalization을 위한 대체로써 layer normalization을 추천한다.

### Two-sided penalty

우리는 gradient의 norm을 1 아래에 두는 대신에 1로 가도록 격려한다. 실험적으로 이것은 최적의 WGAN critic은 분포 아래에 어디서나 1의 norm을 가진 gradient를 가지고 subsection 2.3 사이의 지역의 큰 부분에 있기 때문에 critic을 너무 구속하지 않는 것처럼 보인다. 우리의 초기의 관찰에서 우리는 이것이 조금 더 좋게 수행한다는 것을 발견했지만, 우리는 이것을 완전히 조사하지는 않는다.


# 5. Experiments

![](../../Data/논문_WGAN-GP/GP_6.png)

![](../../Data/논문_WGAN-GP/GP_7.png)

![](../../Data/논문_WGAN-GP/GP_8.png)


# 6. Conclusion

본 연구에서, 우리는 WGAN에서 weight clipping의 문제를 증명하고 같은 문제를 겪지 않는 critic loss에서 penalty term의 형식으로 대체하는 것을 소개했다. 우리의 방법을 사용하여, 우리는 다양한 아키텍쳐에 걸쳐 더 강한 모델링 성능과 안정성을 증명했다. 우리가 GAN을 학습시키기 위해 더 안정적인 알고리즘을 가지고 있으므로, 우리는 우리의 연구가 큰 이미지 데이터셋과 언어에서 더 강한 모델링 성능의 길을 여는 것을 희망한다. 또 다른 흥미로운 방향은 보통의 GAN의 목적 함수에 우리의 penalty term을 적용하는 것이고, 이것은 discriminator가 더 부드러운 결정 경계를 학습하도록 격려되어 학습을 안정화시킬 수 있다.




