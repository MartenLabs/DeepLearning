

### 1. Evaluation of generative models 

- 생성모델을 평가하는 것은 매우 까다로울 수 있다.
- Key question: 어떤 작업이 중요한가?
	- 샘플링 / 생성
	- 밀도 추정
	- 압축
	- 잠재적 표현 학습

생성 모델을 평가하는 것은 매우 어려울 수 있으며, 성공적인 평가를 위해서는 어떤 작업이 중요한지를 명확히 이해해야 한다. 
주요 작업은 다양할 수 있으며, 주로 샘플링 또는 생성된 데이터의 품질, 데이터 분포의 밀도 추정, 데이터의 압축률, 잠재적 표현의 품질 등을 평가할 수 있다. 
또한 여러 작업을 동시에 수행해야 할 수도 있으며, 이러한 작업들은 다양한 사용자 정의 하향 작업에 사용될 수 있다. 



### 2. Sample Quality

- ground truth 를 알 수 없을때
	- IS, FID, KID, Precision / Recall
- ground truth 를 알 수 있을 때
	- MSE, PSNR, SSIM, LPIPS
- human evaluation 
	- Ranking vs Contrast
	- Tools : AMT

생성된 이미지의 품질은 Ground Truth를 알 수 없을 때 또는 Ground Truth를 알 수 있을 때에 따라 다르게 측정 될 수 있다. 
Ground Truth를 알 수 없을 때에 대한 평가에서는 다양한 메트릭을 사용할 수 있으며, IS(Inception Score), FID(Fréchet Inception Distance), 
KID(Kernel Inception Distance), Precision / Recall 등이 포함될 수 있다. 
반면 Ground Truth를 알 수 있을때에 대한 평가에서는 MSE, PSNR(Peak Signal-to-Noise Ratio), SSIM(Structural Similarity Index), 
LPIPS(Learned Perceptual Image Patch Similarity) 등의 메트릭을 사용할 수 있다. 또한 인간 평가를 통해 샘플의 품질을 평가할 수 있으며, 이때는 Ranking 또는 Contrast 를 통해 샘플을 비교하고 평가할 수 있다. 이러한 평가를 위해 Amazon Mechanical Turk와 같은 도구를 사용할 수 도 있다.



### 2-1. Unknown Ground Truth

- 생성된 이미지의 Ground Truth를 알 수 없음 
	- 데이터가 unpaired 상태 
	- 생성된 이미지를 직접적으로 실제 값 이미지와 비교하는것은 불가능 
	- 비대응 데이터는 매우 흔함 
	- Metrics: IS, FID, KID, Precision, Recall
![](../../Data/Models/GANs/7.EvaluationOfGans/1.png)

생성된 이미지의 실제 값이 알려지지 않은 경우 생성된 이미지와 실제 값 이미지를 직접적으로 비교하는 것은 불가능 하다. 
이러한 상황은 데이터가 비대응 상태인 경우에 흔히 발생한다. 
이러한 경우, 생성된 이미지의 품질을 평가하기 위해 IS, FID, KID, Precision, Recall 등과 같은 메트릭을 사용할 수 있다.



### 2-1-1. Inception Scores (IS)

- 가정 1: 레이블이 지정된 데이터셋에서 훈련된 생성 모델의 샘플 품질을 평가
- 가정 2: 임의의 점 x에 대해 레이블 y를 예측하기 위한 좋은 확률적 분류기 c(y|x) 가 있다고 가정
- 좋은 생성 모델에서 나오는 샘플이 두가지 기준을 충족시켜야 한다 : sharpness와 다양성

##### Sharpness (S)
![](../../Data/Models/GANs/7.EvaluationOfGans/2.png)

- High sharpness는 classifier가 생성된 이미지에 대해 확신을 가지고 예측하는 것을 의미 
- 즉 classifier의 예측 분포 c(y|x)가 낮은 엔트로피를 가지고 있다.

##### Diversity(D)
![](../../Data/Models/GANs/7.EvaluationOfGans/3.png)

- 여기서 $c(y) = E_{x\backsim p} [c(y|x)]$ 는 calssifier의 주변 예측 분포 
- 높은 다양성은 c(y)가 높은 엔트로피를 가지고 있다는 것을 의미 


##### Inception scores (IS)
- IS 는 sharpness와 다양성 두가지 기준을 메트릭으로 결합한 것
$$IS = D \times S$$
- 높은 IS는 더 나은 품질을 나타낸다 
- classifier가 없는 경우 대규모 데이터셋(예: ImageNet 데이터셋에서 학습된 Inception Net)으로 학습된 classifier를 사용할 수 있다.
![](../../Data/Models/GANs/7.EvaluationOfGans/4.png)



### 2-1-2. Fréchet Inception Distance (프레셰 인셉션 거리)

- 인셉션 점수(IS)는 $p_\theta$ 에서 샘플만 필요로 하며 원하는 데이터 분포 $p_{data}$ 를 직접 고려하지 않는다. (classifier를 통해서 암묵적으로만 고려)
- FID는 $p_\theta$ 에서 샘플링된 데이터 포인트와 테스트 데이터셋 간(예: 사전 훈련 된 분류기에 의해 학습된)특성 표현에서의 유사성을 측정한다. 
![](../../Data/Models/GANs/7.EvaluationOfGans/5.png)

- FID 계산 
	1. 먼저, 생성된 이미지와 실제 이미지를 특징 추출을 위해 미리 훈련된 인셉션 네트워크를 사용하여 각 이미지의 특성을 추출
	2. 각 이미지의 특성을 사용하여 다변량 가우시안 분포를 추정합니다. 이때, 추출된 특성 벡터들을 모아서 해당 이미지의 다변량 가우시안 분포를 정의
	3. 생성된 이미지와 실제 이미지의 특성에 대해 추정된 다변량 가우시안 분포를 이용하여 각각의 평균(Mg, My)과 공분산(Σg, Σy)을 계산
	4. 계산된 평균과 공분산을 사용하여 두 다변량 가우시안 분포 간의 Fréchet distance를 계산합니다. Fréchet distance는 두 가우시안 분포의 평균 사이의 거리와 공분산 사이의 거리를 고려하여 계산
	5. Fréchet distance가 FID로 사용되며, 일반적으로 다음과 같은 공식을 사용하여 계산

$$\text{FID} = ||Mg - My||^2 + \text{Tr}(\Sigma_g + \Sigma_y - 2(\Sigma_g \Sigma_y)^{1/2})$$

여기서 ||⋅||은 벡터의 유클리드 노름을 나타내며, Tr은 행렬의 trace (대각 요소의 합)를 나타낸다.

FID가 작을수록 생성된 이미지와 실제 이미지 간의 유사성이 높다고 해석된다. 따라서 품질이 높은 생성 모델은 FID가 낮은 값을 갖게 된다.



### 2-1-3. Kernel Inception Distance

- MMD(Maximum Mean Discrepancy)란? 
	- MMD는 두 확률분포 pp와 qq에서 샘플을 비교하는 두 샘플 검정 통계량이다. 이는 p와 q 각각에서 샘플링한 데이터의 모멘트(평균, 분산 등) 차이를 계산함으로써 이루어진다. 직관적으로, MMD는 p 내의 샘플들과 q 내의 샘플들이 서로 얼마나 "유사한지", 그리고 그들이 p와 q의 혼합에서 나온 샘플들과 얼마나 유사한지를 비교합니다.
	- MMD를 이용하면 두 분포 사이의 차이를 정량화할 수 있으며, 이는 두 데이터 집합이 같은 분포에서 왔는지를 테스트하는 데 사용될 수 있다.

- KID(Kernel Inception Distance)란?
	- KID는 MMD를 분류기(예: 인셉션 네트워크)의 특성 공간에서 계산하는 방법이다. 즉, 원래 데이터 공간이 아닌, 분류기를 통해 변환된 특성 공간에서 두 분포의 유사도를 측정한다. 이 접근 방식은 이미지 생성 모델의 성능 평가에서 자주 사용되며, 특히 생성된 이미지와 실제 이미지 사이의 차이를 정량화하는 데 유용하다.

-  FID(Fréchet Inception Distance) 대비 KID
	- **편향성**: FID는 항상 양수 값을 가지는 경향이 있어 편향될 수 있다. 반면, KID는 무편향 추정치를 제공한다.
	- **계산 복잡도**: FID는 $O(n)$ 시간에 평가될 수 있는 반면, KID의 계산은 보통 더 복잡하다. KID는 더 정밀한 평가를 위해 추가 계산이 필요할 수 있으며, 이는 $O(n^2)$ 시간 복잡도를 가질 수 있다. (정확한 복잡도는 구현 방법에 따라 달라진다.)

$$\text{MMD}^2(p, q) = \mathbb{E}_{x, x' \sim p}[K(x, x')] + \mathbb{E}_{y, y' \sim q}[K(y, y')] - 2\mathbb{E}_{x \sim p, y \sim q}[K(x, y)]$$
위 MMD의 공식은 커널 함수를 사용하여 두 분포 $p$와 $q$ 사이의 거리를 측정하는 방식을 나타낸다. 여기서 $K(x, x')$는 커널 함수로, 두 샘플 $x$와 $x'$ 사이의 유사도를 측정한다.

여기서:
- $\mathbb{E}_{x, x' \sim p}[K(x, x')]$는 분포 $p$에서 뽑은 두 샘플 $x, x'$ 간의 커널 함수 값의 기대치
- $\mathbb{E}_{y, y' \sim q}[K(y, y')]$는 분포 $q$에서 뽑은 두 샘플 $y, y'$ 간의 커널 함수 값의 기대치
- $\mathbb{E}_{x \sim p, y \sim q}[K(x, y)]$는 분포 $p$에서 뽑은 샘플 $x$와 분포 $q$에서 뽑은 샘플 $y$ 간의 커널 함수 값의 기대치

이 공식은 두 분포 $p$와 $q$에서 샘플링한 데이터 포인트들 간의 유사도를 커널 함수를 통해 측정하고, 이를 바탕으로 두 분포 사이의 거리(또는 차이)를 계산한다. 
커널 함수 $K$는 보통 가우시안 커널(Gaussian kernel) 또는 다른 유사도 측정 함수를 사용할 수 있으며, 이 선택은 분석하고자 하는 데이터의 특성에 따라 달라질 수 있다.

이 방식을 사용하면 두 분포 사이의 차이를 더욱 세밀하게 측정할 수 있으며, 특히 비선형 관계를 포착하는 데 있어 유리하다. MMD는 기계학습, 특히 도메인 적응(domain adaptation)과 같은 분야에서 데이터 분포의 차이를 분석할 때 유용하게 사용된다.




### 2-1-4 : Precision and Recall

- 정밀도(Precision)
	- 신뢰도와 관련이 있다.
	- 실제 이미지와 생성된 이미지 간의 중첩을 살펴보고 Generator가 생성한 추가적인 부분(중첩 되지 않은 부분)에 대해서도 고려한다. 
	![](../../Data/Models/GANs/7.EvaluationOfGans/6.png)

정밀도는 생성된 이미지가 실제 이미지와 얼마나 중첩되는지를 나타낸다. 이는 생성된 이미지가 실제 이미지와 얼마나 유사한지를 측정하는 데 사용될 수 있다. 
정밀도가 높을수록 생성된 이미지가 실제 이미지와 더 유사하다고 볼 수 있다. 하지만 생성된 이미지가 충첩되지 않는 추가적인 부분을 생성하지 않는것도 중요하다. 
Generator가 중첩되지 않는 추가적인 부분을 생성하지 않고 실제 이미지와 유사한 이미지를 생성할 때 정밀도는 높아진다.


- Recall
	- 다양성과 관련이 있다. 
	- 실제 이미지와 생성된 이미지의 중첩을 살펴보고 Generator가 모델링하지 못하는 모든 실제 이미지에 대해 고려한다.
![](../../Data/Models/GANs/7.EvaluationOfGans/7.png)

재현율은 생성된 이미지가 실제 이미지와 얼마나 많은 부분을 포함하는지를 나타낸다. 이는 생성된 이미지가 다양성을 갖고 있는지를 평가하는 데 사용될 수 있다. 
재현율이 높을수록 생성된 이미지가 실제 이미지와 많은 부분을 포함하고 있음을 의미한다. 생성된 이미지와 실제 이미지 간의 교집합이 많아질수록 높아진다. 




### 2-1-4. Evaluating sample quality - Best practices  (샘플 품질 평가 - 모범 사례)

```
Are GANs Created Equal? A Large-Scale Study
GAN(Generative Adversarial Networks)은 생성 모델의 강력한 하위 클래스입니다. 많은 흥미로운 GAN 알고리즘을 이끌어낸 매우 풍부한 연구 활동에도 불구하고, 어떤 알고리즘이 다른 것보다 더 잘 수행되는지 평가하는 것은 여전히 매우 어렵습니다. 우리는 최신 모델 및 평가 지표에 대한 중립적이고 다면향적인 대규모 경험적 연구를 수행합니다. 대부분의 모델이 충분한 하이퍼파라미터 최적화와 무작위 재시작으로 유사한 점수를 얻을 수 있다는 사실을 발견했습니다. 이는 개선 사항이 근본적인 알고리즘 변경보다는 더 높은 계산 예산과 튜닝에서 나올 수 있다는 것을 시사합니다. 현재 지표의 일부 한계를 극복하기 위해 정밀도와 재현율을 계산할 수 있는 여러 데이터 세트를 제안합니다. 우리의 실험 결과는 미래의 GAN 연구가 보다 체계적이고 객관적인 평가 절차를 기반으로 이루어져야 한다는 것을 시사합니다.
```

- **기본 설정 조율에 시간을 할애하라.**
	- 아키텍쳐, 학습률, 최적화기 등의 기본 설정을 조정하는데 시간을 투자하면, 놀랍도록 좋은 성능을 발휘할 수 있다. 처음에 예상했던 것 보다 훨씬 좋은 결과를 얻을 수 있으므로, 성능이 기대에 못미친다고 해서 실망하기 보다는, 기본 설정을 잘 조율하면 얼마나 잘 작동하는지 놀랄것이다. 

- **재현성을 위한 랜덤 시드 사용.**
	- 험의 재현성을 확보하기 위해서는 랜덤 시드를 사용하는 것이 중요하다. 랜덤 시드를 고정하면 동일한 실험을 반복할 때마다 동일한 결과를 얻을 수 있어, 연구 결과의 신뢰성을 높일 수 있다.

- **다양한 랜덤 시드에 대한 결과 평균과 신뢰 구간 보고**
	- 실험 결과는 랜덤 시드에 따라 달라질 수 있으므로, 여러 개의 랜덤 시드를 사용하여 실험을 반복하고, 그 결과를 평균내어 보고하는 것이 좋다. 또한, 결과의 변동성을 나타내기 위해 신뢰 구간을 함께 제공하는 것이 유용하다다. 이렇게 하면 연구 결과의 일반성과 신뢰도를 더욱 강화할 수 있다.




### 2-2. Known Ground Truth 

생성된 이미지의 기준 진리(Ground Truth)를 알고 있는 경우, 데이터는 짝을 이루며, 생성된 이미지를 기준 진리 이미지와 직접 비교할 수 있다. 
이러한 상황에서 사용할 수 있는 메트릭은 MSE(평균 제곱 오차), PSNR(피크 신호 대 잡음비), SSIM(구조적 유사도) 등이다. 
예를 들어, SRGAN(초해상도 생성적 적대 신경망)과 같은 모델에서 이러한 방식이 사용된다.

- **MSE (Mean Squared Error, 평균 제곱 오차)**: 이 메트릭은 예측된 값과 실제 값 사이의 차이를 제곱한 후 평균을 낸 것이다. 낮은 MSE 값은 예측된 이미지가 기준 진리 이미지와 매우 유사함을 의미한다.
  
- **PSNR (Peak Signal-to-Noise Ratio, 피크 신호 대 잡음비)**: PSNR은 신호가 가질 수 있는 최대 파워 대비 잡음의 파워 비율을 로그 스케일로 표현한 것이다. 이미지 처리에서 PSNR이 높을수록 원본 이미지와 생성된 이미지 사이의 차이가 작음을 의미한다.
  
- **SSIM (Structural Similarity Index, 구조적 유사도 지수)**: SSIM은 두 이미지의 구조적 유사성을 측정하는 지표이다. 이는 밝기, 대비, 구조 등 세 가지 측면에서 두 이미지를 비교한다. SSIM 값이 1에 가까울수록 두 이미지가 유사하다는 것을 의미한다.

이러한 메트릭들은 생성된 이미지가 얼마나 잘 기준 진리 이미지를 재현하는지를 정량적으로 평가할 때 사용된다. 알려진 기준 진리를 가진 경우, 이러한 직접 비교를 통해 모델의 성능을 객관적으로 평가할 수 있다.



- **SRGAN (Super-Resolution Generative Adversarial Network, 초해상도 생성적 적대 신경망)**: 사진처럼 사실적인 단일 이미지 초해상도를 생성적 적대 신경망을 사용하여 얻는 기술이다.
- 주어진 저해상도 입력 이미지로부터 고해상도 대응 이미지를 얻기 위함
- 생성적 적대 신경망(Generative Adversarial Networks, GANs)이 이를 실현할 수 있다.
- 해당 고해상도 대응 이미지를 생성한다.

SRGAN은 저해상도 이미지를 입력으로 받아, 이를 고해상도로 변환하는 모델로 이 과정에서 생성적 적대 신경망을 활용하여, 저해상도 이미지에 없는 디테일을 추론하고 추가함으로써, 최종적으로는 사진처럼 사실적인 고해상도 이미지를 생성한다. 이러한 기술은 이미지 복원, 의료 이미징, 위성 이미지 향상 등 다양한 분야에서 응용될 수 있다.

![](../../Data/Models/GANs/7.EvaluationOfGans/8.png)

![](../../Data/Models/GANs/7.EvaluationOfGans/9.png)

![](../../Data/Models/GANs/7.EvaluationOfGans/10.png)




### 2-2-1. Mean Squared Error(MSE)

MSE는 다음과 같이 정의된다.
$$\text{MSE} = \frac{1}{m} \sum_{i=1}^{m} (x_i - y_i)^2$$
여기서 $x_i$ ,  $y_i$는 이미지 쌍의 픽셀 값입니다.

- MSE는 이미지 쌍의 유사성을 평가할 수 있다.
- 범위는 $[0, \infty)$
- 숫자가 작을수록 두 이미지는 더 유사하며, 따라서 복원이 더 잘 된 것이다.
- 그러나 픽셀별 오차 측정에는 한계가 있다(논의 필요).
- 숫자가 작다 하더라도 인지적으로 좋지 않을 수 있다.



### 2-2-2. Peak Signal to Noise Ratio(PSNR)
				피크 신호 대 잡음비 (PSNR)

PSNR은 다음과 같이 정의된다.
$$\text{PSNR} = 10 \log_{10} \left( \frac{\text{데이터의 최대 가능 파워}}{\text{잡음의 파워}} \right)$$
$$\text{PSNR} = 10 \log_{10} \left( \frac{R^2}{\text{MSE}(x, y)} \right)$$
- 데이터의 최대 가능 파워 대 잡음의 파워를 의미한다.
- uint8 데이터의 경우, 최대 가능 파워는 255이다.
- 부동 소수점(float) 데이터의 경우, 최대 가능 파워는 1이다.
- 숫자가 클수록 이미지의 품질이 더 좋다는 것을 의미한다.



### 2-2-3. Structure Similarity Index Measure (SSIM) 
			구조적 유사도 지수 측정 

$$\text{SSIM} (x, y) = \left[ \text{Luminance} (x, y) \right]^\alpha \cdot \left[ \text{Contrast} (x, y) \right]^\beta \cdot \left[ \text{Structural} (x, y) \right]^\gamma$$
$\text{Luminance} (x, y) = \frac{2\mu_x\mu_y + C_1}{\mu_x^2 + \mu_y^2 + C_1}$

$\text{Contrast} (x, y) = \frac{2\sigma_x\sigma_y + C_2}{\sigma_x^2 + \sigma_y^2 + C_2}$

$\text{Structural} (x, y) = \frac{\sigma_{xy} + C_3}{\sigma_x\sigma_y + C_3}$


- 상대적 밝기, 대비, 구조의 곱
- 범위는 $[0, 1]$
- 숫자가 클수록 이미지의 품질이 더 좋다는 것을 의미




### 2-2-4. Learned Perceptual Image Patch Similarity(LPIPS)
			학습된 지각적 이미지 패치 유사도 (LPIPS)

- 딥 피처(deep features)는 이전의 모든 메트릭을 큰 차이로 능가
- 지각적 유사도는 깊은 시각적 표현들 간에 공유되는 등장하는 속성
- LPIPS가 높을수록 샘플 품질이 더 좋음을 의미
- 딥 네트워크의 지각적 메트릭으로서의 유효성을 반영

![](../../Data/Models/GANs/7.EvaluationOfGans/11.png)




### 2-3. Human evaluation

- SRGAN에서 언급된 바와 같이, 위에서 설명된 기계 평가에는 한계가 있다.
- 지각적 품질을 정확하게 평가하기 위해서는 인간 평가가 더 나은 선택일수 있다.
- **Ranking**: 이미지 그룹에 대한 순위를 매기도록 인간에게 평가 시킨다.
- **Contrast**: 두 이미지 쌍 중 더 나은 것을 선택하도록 인간에게 평가 시킨다.
- **Amazon Mechanical Turk**




### 2-4. Sampling and Truncation (샘플링과 절단)

- 가짜 이미지 샘플링
![](../../Data/Models/GANs/7.EvaluationOfGans/12.png)


- 절단 트릭
![](../../Data/Models/GANs/7.EvaluationOfGans/13.png)
![](../../Data/Models/GANs/7.EvaluationOfGans/14.png)
그림 2: (a) 절단을 증가시키는 효과. 왼쪽에서 오른쪽으로, 임계값이 2, 1, 0.5, 0.04로 설정된다. 
(b) 조건이 좋지 않은 모델에 절단을 적용했을 때 발생하는 포화 아티팩트.




### 3. Density estimation / Compression
			밀도 추정 / 압축 
- VAEs(변분 오토인코더)의 경우, 증거 하한(Evidence Lower Bounds, ELBO)을 로그 우도와 비교할 수 있다. 그렇다면 GANs(생성적 적대 신경망)는 어떨까? 샘플만 가지고 있을 때 모델의 우도를 어떻게 추정할 수 있을까?
- 일반적으로, 샘플로부터 밀도 함수의 무편향 추정은 불가능하다.
- 근사 방법이 필요한데 샘플만을 이용한 커널 밀도 추정을 사용할 수 있다.

![](../../Data/Models/GANs/7.EvaluationOfGans/15.png)





### 4. Evaluation latent representations
			잠재 표현 평가하기

- "좋은" 잠재 표현을 학습한다는 것은 무엇을 의미할까?
  - 하류 작업(downstream task)에 대해서는, 해당 성능 메트릭(예: 준지도 학습의 정확도, 노이즈 제거의 복원 품질 등)을 기반으로 표현을 평가할 수 있다.
  - 비지도 학습 과제의 경우, 모든 상황에 맞는 단일 해결책은 없다.
- 비지도 잠재 표현을 평가하기 위해 일반적으로 사용되는 세 가지 개념:
  - 클러스터링
  - 압축
  - 분리(Disentanglement)


### 4-1. Clustering

- 어떤 의미론적 속성을 기반으로 점들을 그룹화할 수 있는 표현은 잠재적으로 유용할 수 있다(예: 준지도 분류).
- 클러스터는 생성 모델의 잠재 공간에서 k-평균 또는 다른 알고리즘을 적용하여 얻을 수 있다.

![](../../Data/Models/GANs/7.EvaluationOfGans/16.png)
- MNIST 숫자에 대해 두 생성 모델이 학습한 2D 표현으로, 색상은 진짜 라벨을 나타낸다. 어느 것이 더 나을까? B or D?


### 4-2. Disentanglement (분리)

- 직관적으로, 우리는 관측된 데이터의 독립적이고 해석 가능한 속성을 분리할 수 있는 표현을 원한다.

![](../../Data/Models/GANs/7.EvaluationOfGans/17.png)
- 생성된 데이터의 속성에 대한 사용자 제어를 제공한다.
- $Z_1$이 고정되었을 때, 생성된 객체의 크기는 절대 변하지 않는다
- $Z_1$이 변경되었을 때, 변경은 생성된 객체의 크기에만 제한된다.



### 4-3. Disentanglement

- 많은 양적 평가 메트릭들이 있다.
	- Beta-VAE 메트릭 (Higgins et al., 2017): 고정된 변화 요인을 예측하는 선형 분류기의 정확도
	- 다른 많은 메트릭들 : Factor-VAE 메트릭, 상호 정보 간격(Mutual Information Gap), SAP 점수, DCI 분리, 모듈성(Modularity) 등.
	- 이러한 메트릭들의 구현체는 분리 라이브러리(Disentanglement lib)에서 확인할 수 있다.
- 추가적인 가정 없이 생성 요인을 이론적으로 분리하는 것은 불가능하다.



### 5. Summary

- 생성 모델의 양적 평가는 도전적인 작업이다.

- 하류 응용 프로그램의 경우, 응용 프로그램 특정 메트릭에 의존할 수 있다. 비지도 평가의 경우, 메트릭은 최종 목표에 따라 크게 달라질 수 있다: 밀도 추정, 샘플링, 잠재 표현





# 구현 

