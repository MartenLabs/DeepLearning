
![](../../Data/논문_SeeingTheWorldThroughYourEyes/SWTE_1.png)
Figure 1. 눈 반사를 사용한 광도 필드 재구성. 인간의 눈은 매우 반사적입니다. 우리는 움직이는 머리를 포착한 일련의 프레임으로부터 사람이 관찰하는 3D 장면을 반사된 눈만을 이용하여 재구성하고 렌더링할 수 있음을 보여줍니다.



### 초록 
인간의 눈의 반사적인 특성은 우리 주변의 세계가 어떻게 보이는지에 대한 정보로서 과소평가되고 있습니다. 움직이는 사람의 눈을 촬영함으로써, 우리는 눈의 반사를 통해 카메라의 직접 시야가 아닌 장면의 다양한 관점을 수집할 수 있습니다. 본 논문에서는 눈 반사가 포함된 초상 이미지를 사용하여 카메라 시야 밖의 3D 장면을 재구성합니다. 이 작업은 다음과 같은 어려움 때문에 도전적입니다: 1) 정확한 눈 자세 추정의 어려움과 2) 눈 동공과 장면 반사물의 얽힌 외관. 우리의 방법은 코네아 자세, 장면을 묘사하는 광도 필드, 관찰자의 눈 동공 질감을 동시에 개선하는 방식으로 작동합니다. 또한 재구성 품질을 향상시키기 위해 눈 동공 질감 패턴에 대한 간단한 정규화 사전을 제안합니다. 다양한 합성 및 실제 세계 촬영을 통해 눈 색상이 다양한 사람들을 대상으로 한 여러 실험을 통해, 눈 반사를 사용하여 3D 장면을 복원하는 우리의 접근 방식의 실현 가능성을 보여줍니다.



### 1. 서론 

"진정한 발견의 여행은 낯선 땅을 방문하는 것이 아니라, 다른 눈을 소유하고 다른 사람의 눈을 통해 우주를 바라보는 것이다." - 마르셀 프루스트, 1927

인간의 눈은 비전을 가능하게 하고 주변 세계에 대한 귀중한 정보를 담고 있는 놀라운 기관입니다. 우리는 보통 우리 자신의 눈을 두 개의 렌즈로 사용하여 망막을 구성하는 빛을 초점으로 맞추지만, 다른 사람의 눈을 바라볼 때는 코네아에서 반사된 빛도 포착할 수 있습니다. 다른 사람의 눈을 촬영하기 위해 카메라를 사용하면, 우리는 사실상 그들의 눈을 전체 이미징 시스템의 거울로 활용합니다. 관찰자의 눈에서 반사된 빛은 관찰자의 망막에 도달하는 빛과 동일한 원본을 공유하므로, 우리의 카메라는 관찰자가 본 세계에 대한 정보를 포함한 이미지를 형성해야 합니다.

이전 연구들은 두 눈의 이미지에서 관찰자가 보는 세계의 파노라마 이미지를 복원하는 것을 탐구해 왔습니다[30, 31]. 후속 연구들은 개인 식별[12, 28], 쥐 잡기 자세 감지[53], 초점 맞춤 개체 추정[42], 재조명[29] 등의 응용 분야를 더욱 탐구했습니다. 최근의 3D 비전과 그래픽의 발전을 고려할 때, 우리는 궁금해집니다: 우리는 단일한 파노라마 환경 맵을 재구성하거나 패턴을 인식하는 것 이상의 일을 할 수 있을까요? 관찰자가 본 세계를 완전한 3D로 복원할 수 있는 가능성은 있을까요?

본 논문에서는 눈 이미지의 연속에서 3D 장면을 재구성하여 이러한 질문에 답합니다. 우리는 자연스럽게 머리를 움직일 때 눈이 다중 관점 정보를 포착하고 반사한다는 통찰력에서 시작합니다. [30]에서 제안된 고전적인 이미징 공식을 영감으로 삼고, 최근의 신경 광도 필드 (NeRF) [26]를 주도한 3D 재구성의 최신 진보와 통합합니다. 일반적인 NeRF 촬영 설정은 다중 뷰 정보를 촬영하기 위해 움직이는 카메라를 필요로 하지만, 우리의 접근 방식은 정지한 카메라를 사용하고 머리 움직임 아래의 눈 이미지에서 다중 뷰 단서를 추출합니다.

개념적으로 간단하지만, 눈 이미지에서 3D NeRF를 재구성하는 것은 실제로는 매우 어려운 과제입니다. 첫 번째 도전은 원본 분리입니다. 인간의 눈의 복잡한 동공 질감에서 반사물을 분리해야 합니다. 이러한 복잡한 패턴은 3D 재구성 과정에 모호성을 추가합니다. 일반적인 캡처에서 가정되는 장면의 선명한 이미지와 달리, 얻은 눈 이미지는 동공 질감과 병합되어 있습니다. 이러한 조합은 픽셀 대응을 방해하고 재구성 과정을 복잡하게 만듭니다. 두 번째 도전은 코네아 자세 추정입니다. 눈은 작고 이미지 관측에서 정확하게 로컬라이즈하기 어렵습니다. 그러나 다중 뷰 재구성은 그들의 위치와 3D 방향의 정확도에 의존합니다.

이러한 도전을 해결하기 위해 본 연구에서는 두 가지 중요한 구성 요소를 도입하여 눈 이미지에 대한 NeRF 학습을 재조정합니다. 첫째, 전반적인 광도 필드에서 동공 질감을 분리하기 위해 단순한 방사형 사전을 활용하는 질감 분해입니다. 둘째, 눈의 작은 크기에 따른 도전을 극복하기 위해 눈 자세 정밀화 절차를 개발하여 자세 추정의 정확도를 향상시킵니다.

우리의 접근 방식의 성능과 효과를 평가하기 위해 우리는 실제적인 질감을 가진 합성된 코네아에서 반사를 포착하는 복잡한 실내 환경의 합성 데이터셋을 생성합니다. 또한 다양한 물체를 포함하는 실제 세계의 셋업으로 눈 이미지를 촬영합니다. 우리는 우리의 접근 방식에서 여러 설계 선택 사항을 검증하기 위해 합성 및 실제 세계에서 촬영한 눈 이미지에 대한 광범위한 실험을 수행합니다.

우리의 주요 기여는 다음과 같습니다: 
• 새로운 3D 재구성 문제. 우리는 이전의 기초적인 연구와 신경 렌더링의 최신 발전을 통합하여 눈 이미지에서 관찰자의 세계의 3D 장면을 재구성하기 위한 소설적인 방법을 제시합니다. 
• 동공을 위한 방사형 사전. 눈 이미지에서 동공 질감을 분해하기 위해 방사형 사전을 도입하여 재구성된 광도 필드의 품질을 크게 향상시킵니다. 
• 코네아 자세 개선. 인간의 눈에서 특징을 추출하는 과제에 대응하여, 눈의 자세 추정의 잡음에도 불구하고 코네아 자세 개선 절차를 개발하여 추정 정확도를 향상시킵니다.

이러한 진보는 눈 반사로부터 얻은 부분적으로 손상된 이미지 관측을 처리하는 신경 렌더링을 통한 3D 장면 재구성의 현재 기능을 확장하여, 사고적 이미징 [6, 20, 38, 45]의 넓은 영역에서 3D 장면을 밝혀내고 캡처하는 새로운 연구 및 개발 가능성을 엽니다.


![](../../Data/논문_SeeingTheWorldThroughYourEyes/SWTE_2.png)
Figure 2. 비시야 장면을 위한 NeRF. 일반적인 NeRF 촬영 설정은 재구성을 위해 여러 개의 자세 이미지(예: 움직이는 카메라로 촬영된 이미지)를 필요로 합니다. 우리의 설정에서는 움직이는 사람의 눈에서 반사된 빛을 통해 장면의 다중 뷰 정보를 수집합니다.




### 2. 관련 연구

카타디오프트릭 이미징. 
카타디오프트릭 이미징은 렌즈와 거울의 조합을 사용하여 이미지를 촬영하는 기술입니다. '카타디오프트릭'이라는 단어는 반사와 거울에 관련된 그리스어에서 파생되었으며, '디옵트릭'이라는 단어는 고대 그리스의 렌즈와 유사한 도구를 의미합니다. 본질적으로 카타디오프트릭 이미징은 추가적인 (보통 곡면인) 거울을 활용하여 렌즈 기반의 이미징 시스템의 시야를 확장하려는 것을 목표로 합니다. 초기의 카타디오프트릭 이미징 연구는 주로 거울 프로파일의 설계와 최종 이미지 품질에 대한 영향에 초점을 맞추었습니다. [2]는 카타디오프트릭 이미징 시스템의 세 가지 설계 기준을 연구했는데, 거울의 모양, 카메라의 해상도, 그리고 카메라의 초점 설정입니다. [41]은 단일 시점 카타디오프트릭 카메라로 취득한 이미지에서 왜곡을 양적으로 평가하고 최소화하는 방법을 제공했습니다. 또한, 인간의 눈을 외부 곡면 거울로 취급하여 우연한 카타디오프트릭 이미징 시스템을 실현하는 창의적인 방법이 있습니다[31]. [30]은 눈의 단일 이미지를 스테레오 시스템으로 사용하여 에피폴라 기하학과 픽셀 대응을 식별하여 성공적으로 관찰자가 무엇을 보고 있는지를 식별합니다. 눈을 이미징 시스템의 일부로 사용하는 또 다른 응용은 빛의 방향을 추정하기 위해 눈에서 빛을 이용하여 조명을 다시 설정하는 것입니다[29, 46]. 우리의 연구는 눈을 기반으로 한 카타디오프트릭 이미징 시스템에 대한 이전 연구에서 영감을 받았으며, 이 개념을 NeRF 기반 모델링을 통해 3D 장면 복원에까지 확장합니다. 특히, 본 논문에서는 학습 가능한 질감 분해 및 정교한 동공 추정과 같은 카타디오프트릭으로 촬영된 눈 이미지를 처리하기 위한 여러 새로운 기술을 소개합니다.

신경 광도 필드. 
신경 광도 필드(NeRF)는 새로운 시점에서의 합성을 위한 중요한 이정표입니다. NeRF는 3D 장면을 표현하기 위해 미분 가능한 부피 렌더링을 채택하고, 각 장면 점의 밀도와 색상을 학습하기 위해 신경망을 사용합니다. NeRF의 성공을 바탕으로 렌더링 품질 [3, 4], 장면 동적 처리 능력 [10, 17, 22, 34-36], 부정확한 카메라 포즈 [5, 18, 22, 25, 50], 렌더링 속도 [1, 27, 52] 등을 개선하기 위해 다양한 후속 연구가 소개되었습니다. 우리의 연구는 NeRF를 사용하여 눈 반사로부터 복구하려는 알려지지 않은 장면을 매개변수화합니다. 특히, nerfstudio [43]의 학습 프레임워크를 수정하여 NeRF 기반의 장면 복원을 구현합니다. 우리의 입력 이미지는 고정된 시점에서 촬영되었으며, 일반적인 NeRF 설정과는 다르게 추가적인 카메라 포즈 최적화 요구사항을 필요로 합니다.

반사물 제거. 
촬영된 이미지에서 반사물을 제거하는 것은 오랜 기간 동안의 계산 사진술 문제입니다. 이 주제에 대한 관련된 문헌은 주로 다음 두 가지 범주로 요약될 수 있습니다: 다중 프레임과 단일 이미지. 다중 프레임 반사물 제거 방법 [9, 23, 24, 40, 51]은 주로 배경과 반사층 사이의 움직임 패턴의 차이를 활용하고, 정규화를 위해 다양한 이미지 사전 지식을 적용합니다. 단일 이미지 반사물 제거 방법은 주로 깊이-초점 [16, 49], 깊이-편심도 [37] 또는 학습된 이미지 특징 [55]과 같이 단일 이미지에서 사용 가능한 시각적 단서를 활용합니다. 최근에는 NeRF가 다중 프레임 설정에서 반사물 제거를 위한 새로운 도구로 등장했습니다. 다양한 NeRF 기반 방법들은 빛나는 또는 금속적인 물체에서 반사물을 정확하게 모델링하고 추출하는 방법을 연구했습니다[7, 44, 48, 54]. Nerfren [11]은 두 개의 NeRF를 적합시켜 반사 및 확산 구성요소를 따로 모델링하여 거울과 같은 평면 표면에서의 반사물을 제거하고 별도의 3D 장면으로 다시 렌더링하는 것을 보여줍니다. 평면 반사의 단순성으로 인해 Nerfren은 단순히 알파-컴포짓팅에 의해 가중치가 부여된 두 개의 NeRF 모델 (반사 및 확산)의 예측을 모으는 방식으로 반사 및 확산 구성 요소의 공동 학습을 달성합니다. 이 작업에서는 평면 표면의 기하학에 중점을 둔 이전의 작업과는 달리, 우리의 대상인 인간의 눈은 본질적으로 더 복잡한 곡선 기하학을 가지고 있어 표준 NeRF 렌더링 워크플로에 여러 가지 수정 사항을 개발해야 합니다. 이에 대한 자세한 내용은 다음 섹션에서 설명하겠습니다.

![](../../Data/논문_SeeingTheWorldThroughYourEyes/SWTE_3.png)
  
Figure 3. 코네아 기하학. 코네아는 타원체로 모델링할 수 있습니다. 우리가 활용하는 핵심 사실은 성인들 사이에 코네아의 모양과 크기가 크게 일관되며, 비슷한 이심률과 곡률을 가진다는 것입니다.

비시야 이미징. 
비시야 (Non-line-of-sight, NLOS) 이미징은 카메라의 위치에서 직접 보이지 않거나 시야에 가려진 객체의 이미지를 복원하려는 기술입니다. NLOS 이미징의 원리는 시야 바깥의 객체에 대한 정보를 기록하기 위해 시야에 보이는 반사 표면에서 반사된 빛을 사용할 수 있다는 것입니다. NLOS 문헌은 크게 두 가지 범주로 나뉩니다: 액티브 (active)와 패시브 (passive). 액티브 NLOS 이미징 기술은 레이저와 같은 제어된 광원을 사용하며, 종종 비행 시간 측정을 기반으로 숨겨진 장면을 재구성합니다. [47]는 비행 중인 빛을 기록하는 초고속 이미징 시스템을 소개하여 비시야 객체를 재구성할 수 있도록 했습니다. [13, 19, 32]는 후에 액티브 NLOS 이미징 시스템의 해상도를 향상시키기 위한 다양한 방법을 제시했습니다. 최근에는 NeRF도 액티브 NLOS 이미징에 도입되어 더 정확한 재구성과 노이즈 처리를 개선하는 데 사용되었습니다 [8, 39]. 패시브 NLOS 이미징은 자연적이거나 주변 광을 활용하며 제어된 광원이 필요하지 않습니다. [45]는 우연한 핀홀과 핀스펙 카메라의 개념을 소개했는데, 이는 환경 내의 우발적이거나 의도하지 않은 이미징 요소를 사용하여 독특한 관점을 캡처하거나 숨겨진 장면을 해결하는 것을 의미합니다. [6, 38]은 그림자 패턴을 분석하고 이러한 패턴이 숨겨진 장면의 형상을 재구성하는 데 충분한 정보를 포함하고 있음을 보였습니다. [20]은 열 카메라로 촬영된 반사를 사용하여 비시야 인간의 3D 신체 자세를 재구성합니다. 최근에는 [44]에서 Orca가 소개되었는데, 이는 다중 뷰 이미지에서 관찰된 광택이 있는 객체의 반사를 사용하여 주변 환경을 위한 3D NeRF를 훈련시킵니다. 이 문맥에서 우리의 논문은 패시브 NLOS 장면 재구성의 특수한 사례로 볼 수 있습니다. 우리는 특정한 중계 표면인 인간의 눈에 초점을 맞추고 눈 반사에서 정보를 추출하기 위한 특수 기술을 소개합니다. Orca와 달리 우리의 방법은 "거울" 개체가 고정되어 있는 동안 움직이는 카메라로 촬영된 이미지에 의존하지 않고 정지한 카메라에서 작동하며, 이는 Figure 2에서 시각화되었습니다.

![](../../Data/논문_SeeingTheWorldThroughYourEyes/SWTE_4.png)
Figure 4. 이 논문에서 제안하는 방법의 핵심적인 부분을 시각적으로 설명하고 있습니다. 이 그림은 눈의 반사를 통해 3D 장면을 재구성하는 과정을 보여줍니다.

일반적인 NeRF 렌더링은 카메라의 원점에서 시작하여 특정 시야 방향으로 레이를 사용합니다. 그러나 이 연구에서는 레이가 각막에서 반사되는 것을 고려해야 합니다. 반사된 레이의 원점 O'는 초기 카메라 레이가 각막과 교차하는 지점이며, 새로운 레이 방향 d'는 d가 각막의 정규 -→n을 따라 반사된 것입니다.

따라서 우리가 관찰하는 눈의 이미지는 홍채 텍스처와 반사된 장면의 합성입니다. 이 합성은 고도로 세부적인 홍채 텍스처 때문에 표준 NeRF 훈련을 방해합니다. 일반적으로 장면의 명확한 이미지가 가정되는 표준 캡처와 달리, 우리가 얻는 눈의 이미지는 본질적으로 홍채 텍스처와 혼합되어 있습니다. 이 합성은 픽셀 대응을 방해하고 재구성 과정을 복잡하게 만듭니다.

이 문제를 해결하기 위해, 본 연구에서는 θ와 함께 홍채 텍스처 필드 Φ를 훈련시킵니다. Φ의 입력은 주어진 이미지에서 O'의 투영입니다. 눈 텍스처 필드는 현재 이미지의 눈에 대해 계산되며, 반사 필드는 세계 좌표의 3D 점을 취합니다. θ와 Φ로부터의 볼륨 렌더링 출력은 각막 이미지를 재구성하기 위해 함께 합성됩니다. 이때 재구성 손실 Lrecon을 적용합니다. 또한, 우리는 홍채 텍스처에 방사형 손실 Lradial을 적용하여, 추정된 텍스처가 방사형으로 일정하도록 유도함으로써 장면 영역의 흡수를 줄입니다.

이 그림은 이러한 과정을 시각적으로 보여주며, 논문의 주요 기여 중 하나인 홍채 텍스처 분해와 각막 포즈 정제를 설명합니다



### 3. Background: Eye Model

눈은 주로 흰자와 각막으로 구성되어 있으며, 각막은 홍채와 동공을 포함하고 있습니다. 각막은 눈물의 얇은 막으로 덮여 있어 매우 반사성이 강합니다. 이러한 특성 때문에 각막은 거울처럼 작용하며, 카메라와 각막의 조합은 캐터디옵트릭 시스템을 형성합니다.

이 연구에서는 눈의 모델을 타원체의 일부로 가정하며, 이는 Figure 3에서 설명하고 있습니다. 이 타원체는 다음의 방정식으로 설명될 수 있습니다.

(1−e)z^2 −2Rz + r^2 = 0

여기서 e는 이심률, R은 꼭지점에서의 곡률 반경, r^2 = x^2 + y^2 입니다. 건강한 성인의 경우, e는 대략 0.5이고 R은 약 7.8mm로, 사람들 사이에서 크게 변하지 않습니다. 타원체 부분의 경계는 꼭지점에서 기저까지의 거리인 tb로 결정됩니다. rL, 타원체 부분의 기저 반경은 약 5.5mm로 알려져 있으며, 이를 통해 tb를 약 2.18mm로 계산할 수 있습니다. 타원체 표면의 각 점에서의 법선을 계산하기 위해, 방정식 1의 그래디언트를 취하면 다음과 같이 됩니다.

−→n (x,y,z) = ⟨2x,2y,2(1−e)z−2R⟩

각막의 깊이를 계산하기 위해, 먼저 약한 원근 투영 모델을 가정합니다. 이는 기저의 지름이 최대 11mm이므로 깊이에 비해 작기 때문입니다. 다음으로, 각막의 투영은 타원이 될 것입니다. 타원의 장축 반경을 rimg라고 하면, 투영 모델 하에서 각막의 평균 깊이는 다음과 같이 계산될 수 있습니다.

depthavg = rL * f / rimg

이러한 눈의 모델은 각막의 반사를 통해 3D 장면을 재구성하는 데 사용됩니다.



### 4. Method

"Radiance field from reflection" 

NeRF는 볼륨 렌더링을 통해 파라미터화된 방사선 필드를 훈련시킵니다. 각 픽셀 색상은 파라미터화된 MLP θ를 사용하여 광선을 따라 색상과 밀도를 샘플링하여 계산됩니다. NeRF에서 광선은 이미지의 카메라 원점에서 시작하며, 방향은 카메라 평면에 픽셀의 투영을 향합니다. 이 방식으로 방사선 필드를 훈련시키면, 장면의 3D 재구성을 복구할 수 있습니다. 그러나, 우리의 설정에서는 사람의 눈에서 반사된 장면의 재구성을 원합니다. 그림 4에서는 눈에서 반사된 광선을 어떻게 사용하는지 보여줍니다. 반사된 광선은 원점에서 시작하며, 이 원점은 카메라 광선이 각막과 교차하는 지점인 O'이며, 방향은 반사된 광선 d'를 사용합니다. 우리는 표준 반사 방정식을 사용하여 반사된 광선을 명시적으로 계산합니다:

d' = d - 2(n·d)n

여기서 n은 hit point O'에서의 normal입니다. 각막과 관련된 픽셀에 대해 hit points와 normals를 한 번만 계산하면 됩니다. 우리는 각막의 기하학을 타원체로 모델링하기 때문에, 데이터 처리 단계에서 닫힌 형태의 타원체 광선 교차 공식을 사용하여 hit points와 normals를 직접 계산합니다.


"Texture Decomposition"
눈 이미지에서 홍채의 텍스처를 분리하는 과정에 대해 설명하고 있습니다. 이는 3D 재구성 과정에서 중요한 단계입니다.

우리가 관찰하는 눈 이미지는 홍채 텍스처와 반사된 장면의 합성입니다. 이 합성은 홍채 텍스처의 세부 사항 때문에 표준 NeRF 훈련을 방해합니다. 이 문제를 해결하기 위해, 이 연구에서는 볼륨 렌더링을 수행하는 방사장 θ와 함께 눈 텍스처 필드 Φ를 훈련시킵니다. 눈 텍스처 필드의 입력은 주어진 이미지에서 O'의 투영입니다.

볼륨 렌더링과 텍스처 추정의 결과는 각막 이미지를 재구성하기 위해 함께 합성됩니다. 이때, 재구성 손실 Lrecon을 적용합니다. 또한, 텍스처 필드 Φ에 방사형 손실 Lradial을 적용하여 추정된 텍스처가 방사형으로 일정하도록 유도하며, 이를 통해 눈 텍스처로의 장면 영역의 흡수를 줄입니다.

이러한 텍스처 분해 과정은 눈의 반사를 통해 3D 장면을 재구성하는 데 중요한 역할을 합니다. 이는 눈의 반사를 통해 주변 환경에 대한 정보를 얻는 데 새로운 가능성을 제시하며, 3D 장면 재구성의 새로운 방법론을 제시하고 있습니다.


"Cornea Pose Optimization" 

부분은 캡처된 이미지에서 각막의 크기가 작기 때문에 각막의 위치와 정규 추정에 불가피하게 일부 오류가 있음을 설명하고 있습니다. 이러한 오류가 있는 위치로 훈련하면 방사장 재구성의 품질에 크게 영향을 미칩니다. 이러한 위치 오류를 완화하기 위해, 이 연구에서는 각 각막의 위치를 독립적으로 최적화합니다. 각 각막에 대해, 우리는 변환 행렬 T = [R,t] ∈ SE(3)를 최적화하며, 여기서 R ∈ SO(3)는 회전을, t ∈ R3는 이동을 나타냅니다. 이 연구에서는 [18, 25, 50]과 유사하게 훈련하는 동안 각막의 위치를 최적화합니다.

실제 상황에서는 각막의 반경을 완벽하게 추정할 수 없기 때문에, 이 연구에서는 추정된 각막 반경의 노이즈에 대한 각막 위치 최적화의 견고성을 평가합니다. 실제 데이터에서 마주칠 수 있는 깊이 추정 오류를 시뮬레이트하기 위해, 각 이미지에 대해 관찰된 각막 rimg 반경을 다양한 노이즈 수준으로 조정하여 추정된 반경을 확대합니다. Figure 7에서는 다양한 노이즈 수준에 대한 방법의 성능 변화를 보여줍니다. 노이즈의 양이 증가함에 따라, 위치 최적화를 통한 재구성은 재구성된 기하학과 색상에 대해 위치 최적화 없는 재구성에 비해 견고합니다. 이는 위치 최적화가 이미지에서의 각막에 대한 초기 타원 피팅이 완벽하지 않은 실제 시나리오에서 우리의 방법이 작동하는 데 필수적임을 보여줍니다. 또한, 텍스처 분해 없이 우리의 방법과 텍스처 분해를 사용한 우리의 방법의 정량적 비교를 Table 1에서 보여줍니다. 텍스처 분해를 사용한 우리의 방법은 텍스처 분해 없이 SSIM과 LPIPS에서 더 나은 성능을 보여줍니다. 특히, 우리의 설정에서는 반사와 장면 자체 사이의 조명 차이가 심하므로 PSNR을 계산하지 않습니다.

![](../../Data/논문_SeeingTheWorldThroughYourEyes/SWTE_5.png)
Figure5. 정성적 합성 결과. 우리는 우리의 방법이 시뮬레이션에서 까다로운 측정으로부터 합리적인 재구성을 달성할 수 있음을 보여줍니다. 우리는 우리의 방법이 카메라 포즈와 관련하여 학습된 방사 필드의 축적을 시각화하여 장면의 3D 형상을 재구성할 수 있음을 보여줍니다. 누적은 카메라 광선을 따라 밀도의 적분으로 정의됩니다.









