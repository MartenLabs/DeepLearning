


## WaveNet

WaveNet은 오디오 파형의 결합 확률(joint probability) $\bf{x}=\{x_1,\dots,x_T\}$ 를 아래와 같은 조건부 확률로 분리하여 표현합니다.

$$\begin{equation} p(\bf{x})=\prod_{t=1}^{T} p(x_t|x_1,\dots,x_{t-1}) \end{equation}$$





## Dilated Causal Convolutions

![[WN_1.png]]
WaveNet 의 핵심 구조는 위 그림과 같은 Causal Convolution 입니다. Pooling Layer 가 존재하지 않고 Input 과 Output 의 크기를 동일하게 유지합니다.

인과 관계(Causal) 라는 말에서 알 수 있듯, 현재 시점의 데이터에 대한 예측($x_t$)이 미래의 데이터($x_{t+1}, x_{t+2},\dots$)에 영향을 미치지 않습니다.

모든 시점의 데이터를 알고 있는 훈련 단계에서는 재귀구조 없이 각 시점의 출력을 병렬적으로 학습할 수 있습니다. 때문에, 길이가 긴 데이터에 대해서도 빠른 훈련속도를 보장합니다.

그러나 Causal Convolution 은 출력과 연관이 있는 인지 범위(receptive field) 를 넓히기 위해서 추가해야하는 filter 의 길이와 레이어의 갯수가 많다는 단점이 있습니다.


---
**요약**:
WaveNet의 중심적인 구조는 "Causal Convolution"이다. 이 구조에서는 풀링 레이어가 없고, 입력과 출력의 크기가 동일하다. "인과 관계"는 현재 데이터의 예측이 미래 데이터에 영향을 주지 않는다는 것을 의미한다. 이 구조는 훈련 단계에서 빠른 속도로 긴 데이터를 학습할 수 있지만, 출력과 연결된 인지 범위를 넓히려면 많은 필터와 레이어가 필요하다는 단점이 있다.

**풀이**:
1. **WaveNet & Causal Convolution**: WaveNet이라는 기술에서 중요한 부분은 'Causal Convolution'이라는 특별한 방법을 사용한다는 것입니다. 이걸 간단하게 말하면, "원인과 결과"를 따져서 데이터를 처리하는 방법입니다.
   
2. **풀링 레이어 & 크기 유지**: 이 방법에서는 '풀링 레이어'라는 것을 사용하지 않아요. 그리고 데이터를 처리할 때 입력한 크기와 출력한 크기가 같아요.

3. **인과 관계**: 현재의 정보로 무언가를 예측할 때, 그 예측이 미래의 정보에 영향을 주지 않아요. 예를 들면, 오늘의 날씨를 예측할 때 내일의 날씨 정보를 사용하지 않는 것과 같아요.

4. **빠른 학습**: 이 방법을 사용하면, 많은 정보를 빠르게 학습할 수 있어요. 그래서 긴 정보도 빠르게 처리할 수 있어요.

5. **단점**: 하지만, 이 방법에는 단점도 있어요. 더 넓은 범위의 정보를 알기 위해서는 많은 필터와 레이어가 필요하다는 것입니다. 이건 마치 넓은 지역의 날씨를 알기 위해서 많은 기상 관측소가 필요한 것과 비슷해요.

**중요한 부분**: WaveNet에서 사용하는 'Causal Convolution' 방법은 빠르게 많은 정보를 학습할 수 있지만, 더 넓은 범위의 정보를 알기 위해 많은 자원이 필요하다는 단점이 있습니다.






---
![[WN_2.png]]
이에 논문에서는 희석된(dilated) caulsal convolution 구조를 제안합니다.

위 그림처럼 convolution 을 시행할 때 인접한 input 에 filter 를 적용하는 것이 아닌, 일정 간격을 두고 filter 를 적용합니다. 이를 반복하면 연산량의 추가없이, 몇 개의 레이어 만으로도 인지 범위를 크게 넓힐 수 있습니다.

본 논문에서는 정해진 크기(512)까지 간격을 2배씩 키우는 것(1,2,4,...,512)을 3회 반복 하여 총 30층의 레이어를 구성하였습니다.

---
**요약**:
논문에서는 '희석된(dilated) causal convolution'이라는 새로운 구조를 제안합니다. 이 방법에서는 연속적으로 있는 입력 데이터에 필터를 적용하는 것이 아니라, 일정한 간격을 두고 필터를 적용합니다. 이런 방식으로, 많은 연산 없이도 레이어 몇 개만으로 정보를 넓게 인식할 수 있게 됩니다. 논문에서는 이 방법을 사용하여 총 30층의 레이어를 만들었고, 간격은 1부터 시작하여 512까지 2배씩 증가하는 방식을 3번 반복하여 구성했습니다.

**풀이**:
1. **희석된(dilated) causal convolution**: 논문에서는 특별한 방법을 사용해 데이터를 처리하는 새로운 방법을 제안하고 있어요. 이건 마치 도로에 일정한 간격으로 표시된 보도블록처럼, 데이터를 처리할 때도 일정한 간격을 두고 정보를 보는 방법입니다.

2. **간격을 두고 보기**: 보통의 방법에서는 데이터를 연속적으로 보는데, 이 새로운 방법에서는 일정한 간격을 두고 데이터를 봐요. 이렇게 하면, 많은 계산 없이도 넓은 범위의 정보를 빠르게 인식할 수 있어요.

3. **논문에서의 방법**: 논문에서는 이 방법을 사용해서 30개의 층을 만들었어요. 그리고 데이터를 보는 간격을 처음에는 1로 시작해서, 2배씩 늘려서 512까지 증가시키는 방법을 3번 반복했어요.

**중요한 부분**: '희석된(dilated) causal convolution'은 데이터를 일정한 간격으로 보는 새로운 방법이에요. 이 방법을 사용하면, 많은 계산 없이도 넓은 범위의 정보를 빠르게 알 수 있어요.






---
## Softmax Distributions

각 sample 의 조건부 확률을 구하기 위해 softmax 분포를 사용합니다. PixelCNNs 에서는 분포의 모양에 대한 추가적인 가정을 요구하지 않아 임의의 분포를 표현하는데 훨씬 유연하다고 설명합니다.

원본 오디오 파형은 샘플당 16bit의 정수로 저장된 시퀀스입니다. 이를 softmax 분포로 모델링 하기 위해서는 65,536 개의 확률을 반환해야 합니다.

이를 간소화하기 위해 아래 수식과 같이 $\mu$-law Companding 변환이라고 부르는 비선형변환을 사용합니다.

$$ f(x_t) = sign(x_t) \frac{\ln(1+\mu|x_t|)}{\ln(1+\mu)} $$

$1<x_t<1,\mu=255$ 일 때, 샘플을 표현하는데 필요한 확률은 256개로 줄어듭니다.

---
**요약**:
논문에서는 각 샘플의 조건부 확률을 구하기 위해 'softmax 분포'를 사용합니다. PixelCNNs 방법에서는 이 분포를 사용하면 어떤 모양의 확률 분포도 유연하게 표현할 수 있습니다. 원래의 오디오 데이터는 16bit 정수로 되어 있어, 이를 softmax로 표현하려면 65,536 개의 확률 값을 반환해야 합니다. 그런데 이렇게 많은 확률 값을 처리하는 것은 비효율적이기 때문에, 특별한 방법인 'μ-law(뮤 법칙) Companding 변환'을 사용하여 이를 256개의 확률 값으로 줄입니다.

**풀이**:

1. **Softmax 분포**: 'Softmax'는 여러 가지 가능성 중에서 어떤 것이 가장 가능성이 높은지를 확률로 보여주는 방법입니다. 예를 들면, 어떤 과일이 사과일 확률, 배일 확률, 포도일 확률 등을 모두 보여줄 때 사용하는 방법이에요.

2. **오디오 데이터**: 오디오 데이터는 사실 많은 숫자들로 이루어져 있어요. 그리고 이 숫자들을 표현하기 위해서는 65,536개의 확률 값을 사용해야 해요. 하지만 이렇게 많은 숫자를 사용하는 건 너무 복잡하죠.

3. **μ-law Companding 변환**: 그래서 이 논문에서는 특별한 방법을 사용해서 많은 숫자들을 256개의 숫자로 줄이는 방법을 사용해요. 이 방법을 'μ-law Companding 변환'이라고 부릅니다. 

**중요한 부분**: 오디오 데이터를 표현할 때 너무 많은 숫자를 사용하는 것은 복잡하므로, 'μ-law Companding 변환'이라는 특별한 방법을 사용하여 이를 간단하게 256개의 숫자로 표현합니다.





---
## Gated activation units

일반적으로 많이 사용하는 ReLU 가 아닌, gated PixelCNN 논문에서 제시된 바 있는 게이트 활성 함수를 사용합니다.

$$ \begin{equation} \bf{z}=\tanh(W_{f,k} \ast \bf{x}) \odot \sigma (W_{g,k} \ast \bf{x}) \end{equation} $$

- $\ast$ : convolution 연산
- $\odot$ : element-wise 곱연산
- $\sigma(\cdot)$ : sigmoid 함수
- $k$ : Layer 번호
- $f, g$ : filter, gate
- $W$ : 학습가능한 convolution filter


---
**요약**:
논문에서는 일반적으로 많이 사용되는 'ReLU' 활성화 함수 대신 'gated PixelCNN'에서 제안된 특별한 활성화 함수, 즉 '게이트 활성 함수'를 사용합니다. 이 함수는 특정한 수식을 통해 정의됩니다. 또한, Resnet에서 사용된 'skip connection' 구조를 그대로 사용합니다.



**풀이**:

1. **Gated activation units**: 컴퓨터가 어떤 숫자를 보고 다음 작업을 결정할 때, 어떻게 그 숫자를 변형할지 결정하는 방법을 '활성화 함수'라고 해요. 대부분의 경우에는 'ReLU'라는 방법을 사용하는데, 이 논문에서는 다른 특별한 방법을 사용합니다. 이 방법을 '게이트 활성 함수'라고 부릅니다.

2. **수식**: '게이트 활성 함수'는 특정한 수식으로 표현되는데, 여기에는 여러 기호와 연산들이 포함되어 있어요. 이 수식은 컴퓨터가 어떻게 숫자를 변형할지 정확하게 알려주는 역할을 합니다.

**중요한 부분**: 논문에서는 특별한 활성화 함수인 '게이트 활성 함수'를 사용하며, 정보를 효율적으로 처리하기 위해 'skip connection'이라는 방법을 사용합니다.



**풀이2**:

$$\mathbf{z} = \tanh(W_{f,k} \ast \mathbf{x}) \odot \sigma (W_{g,k} \ast \mathbf{x})$$
이 수식을 각 부분별로 살펴보겠습니다.

1. **변수 및 기호**:
   - $\mathbf{z}$ : 결과 값. 
   - $\mathbf{x}$ : 입력 값.
   - $W$ : 학습 가능한 convolution 필터. 데이터를 변환하는 역할을 합니다.
   - $\ast$ : convolution 연산. 데이터의 특징을 추출하는 역할을 합니다.
   - $\odot$ : element-wise 곱셈. 각 요소별로 곱하는 연산입니다.
   - $\sigma(\cdot)$ : sigmoid 함수. 값을 0과 1 사이로 변환하는 함수입니다.
   - $k$  : 레이어 번호.
   - $f, g$ : filter와 gate를 의미합니다.

2. **수식의 구성**:
   - $\tanh(W_{f,k} \ast \mathbf{x})$ : 이 부분은 convolution 연산을 통해 입력 값을 변환하고, 그 결과를 $\tanh$ 함수를 통해 -1과 1 사이의 값으로 변환합니다.
   - $\sigma (W_{g,k} \ast \mathbf{x})$ : 이 부분도 convolution 연산을 통해 입력 값을 변환하고, 그 결과를 sigmoid 함수를 통해 0과 1 사이의 값으로 변환합니다.
   - 두 결과를 $\odot$ (element-wise 곱셈)을 사용해 곱하면 최종 결과인 $\mathbf{z}$를 얻게 됩니다.

**해석**:
이 수식은 입력 데이터 $\mathbf{x}$를 변환하여 새로운 값을 $\mathbf{z}$로 출력하는 역할을 합니다. 여기서 중요한 것은 두 가지 변환 방법을 사용한다는 점입니다. 하나는 $\tanh$ 함수를 사용한 방법이고, 다른 하나는 sigmoid 함수를 사용한 방법입니다. 이 두 방법을 통해 변환된 값을 곱하여 최종 결과를 만듭니다. 이렇게 두 가지 방법을 조합하면, 네트워크가 데이터의 다양한 특징을 더 잘 잡아내고, 더 복잡한 패턴을 학습할 수 있게 됩니다.




**why?**
여기서 제시된 게이트 활성 함수의 특성을 이해하기 위해서는, 각 구성 요소의 역할을 먼저 파악하는 것이 중요합니다.

1. **$\tanh$ 함수**: 
    - 이 함수는 출력 값을 -1 에서 1 사이로 변환합니다.
    - 이 함수는 선형적이지 않기 때문에, 네트워크에 비선형성을 추가합니다. 비선형성이 있어야만 복잡한 패턴을 학습할 수 있습니다.
    - $\tanh$ 함수는 입력의 강도나 방향에 따라 출력을 조절합니다.

2. **$\sigma$ 함수 (sigmoid 함수)**:
    - 이 함수는 출력 값을 0 에서 1 사이로 변환합니다.
    - 실제로 이 함수는 '게이트' 역할을 합니다. 즉, 어떤 정보를 통과시킬지, 어떤 정보를 차단할지 결정합니다.
    - 값이 0 에 가까우면 정보를 차단하고, 값이 1 에 가까우면 정보를 완전히 통과시킵니다.

두 함수를 조합하면, **다양한 특징**을 잡아낼 수 있게 됩니다:
- $\tanh$는 입력의 특징을 변환하고, $\sigma$는 그 변환된 특징 중 얼마나 중요한지를 결정합니다. 
- 예를 들어, 특정 패턴이 중요하지 않다면, $\sigma$함수는 그 정보를 억제하고, 중요한 패턴이라면 강조합니다.
- 이런 조합은 네트워크가 데이터 내의 다양한 특징과 패턴을 동시에 인식하고, 그 중요도에 따라 반응할 수 있게 합니다.

결국, 이런 복합적인 활성화 함수를 사용함으로써, 네트워크는 데이터의 다양한 특징과 복잡한 패턴을 더 잘 인식하고 학습할 수 있게 됩니다.






---
## Residual and Skip Connections

![[WN_3.png]]

**요약** :
1. **Residual and Skip Connections**: 컴퓨터가 정보를 처리할 때, 중간 중간에 정보를 건너뛰는 특별한 방법을 'skip connection'이라고 해요. 이 방법은 'Resnet'이라는 기술에서 처음 제안되었고, 이 논문에서도 그 방법을 사용합니다.



**Residual** :
"Residual"은 남아있는 또는 잔여의 것을 의미하는 단어입니다. 딥러닝, 특히 심층 신경망에서 "Residual"이 주로 언급될 때, 이는 "Residual Connection" 또는 "Residual Block"과 관련이 있습니다. 이 개념은 Microsoft Research에서 발표된 "Deep Residual Learning for Image Recognition" 논문에서 처음 소개되었습니다.

**Residual Connection (또는 Skip Connection)의 핵심 아이디어**:
- 심층 신경망은 훈련하기 어려운데, 이는 네트워크가 깊어질수록 그래디언트(gradient)가 소실되거나 폭발하는 문제 때문입니다.
- Residual Connection은 이 문제를 해결하기 위한 방법 중 하나로, 입력을 몇 레이어를 건너뛰고 직접 출력에 더하는 형태로 도입되었습니다.
- 이렇게 함으로써, 신경망은 "잔여" 정보를 학습하게 되어, 심층 네트워크도 효과적으로 훈련할 수 있게 되었습니다.

**간단한 예시**:
고려해보실 상황: 어떤 신경망 레이어의 입력이 \( X \)이고, 이 레이어가 학습해야 할 변환을 \( F(X) \)라고 합시다. 일반적인 신경망에서는 \( F(X) \)를 직접 학습하려고 하지만, Residual Network에서는 \( F(X) + X \)를 출력으로 합니다. 여기서 \( F(X) \)는 "잔여" 변환을 의미합니다. 

이 구조의 핵심적인 장점은, 심층 네트워크에서도 각 레이어가 학습해야 할 변환을 훨씬 쉽게 만들어 준다는 것입니다. 

따라서, "Residual"이란 단어는 네트워크가 이전 레이어의 입력과 현재 레이어의 출력 사이의 "잔여" 차이 또는 변환을 학습하게 된다는 개념을 나타냅니다.



**Residual == Skip connection**  but  **Skip connection != Residual **

"Residual Connection"과 "Skip Connection"은 많은 상황에서 서로 바꿔 사용될 수 있지만, 원래의 의미나 맥락에 따라 약간의 차이가 있습니다.

1. **Residual Connection**:
   - "Residual"은 잔여나 남은 것을 의미합니다. ResNet 아키텍처에서는 각 레이어가 입력과 출력 사이의 잔여 차이나 변환을 학습하도록 설계되었습니다.
   - Residual Connection에서는 입력을 해당 레이어의 출력에 직접 더하는 방식으로 도입됩니다. 즉, \( \text{output} = \text{input} + F(\text{input}) \)과 같은 형태로 표현됩니다.

2. **Skip Connection**:
   - "Skip"은 건너뛴다는 의미입니다. 따라서, Skip Connection은 입력 데이터를 몇 개의 레이어를 건너뛰고 다음 레이어의 출력에 직접 연결하는 구조를 의미합니다.
   - Skip Connection은 네트워크의 어떤 부분에서도 사용될 수 있으며, Residual Connection이라는 특별한 형태의 Skip Connection 중 하나라고 볼 수 있습니다.

**결론**: 
- "Residual Connection"은 "Skip Connection"의 한 형태입니다.
- 모든 "Residual Connection"은 "Skip Connection"입니다. 하지만, 모든 "Skip Connection"이 "Residual Connection"인 것은 아닙니다.
- 그러나 실제로 많은 문헌이나 논의에서 이 두 용어는 서로 바꿔 사용되므로, 문맥을 잘 파악하여 이해하는 것이 중요합니다.







---

## Conditional WaveNets

WaveNet은 Conditional Modeling $P(\bf{x}|\bf{h})$ 이 가능합니다. 즉, 조건을 추가하여 원하는 특성을 지닌 오디오를 생성할 수 있습니다. 논문에서는 이를 모델링 할 수 있는 2가지 방법을 제시합니다.

- **전역 조건(Global Conditioning)** : 모든 시점에 영향을 미치는 조건을 추가합니다. (예시 : TTS 에서의 발화자 정보)
- **지역 조건(Local Conditioning)** : 시점에 따라 다른 영향을 미치는 조건을 추가합니다. (예시 : TTS 에서의 발음, 강세 등)

# Experiments



## Multi-Speaker Speech Generation

텍스트가 주어지지 않은 Free-form 발화를 생성하는 문제입니다. VCTK 데이터셋에서 화자의 ID 만을 One-Hot Vector 로 변환해 전역 조건으로 사용했습니다.

텍스트가 없으므로 실제로 존재하지는 않지만 사람이 말하는 것처럼 들리는 음성을 성공적으로 생성하였습니다. 단일 모델 만으로 109개의 화자에 맞는 음성을 생성해냈습니다.

## **Text to Speech**

텍스트를 기반으로 단일 화자의 발화를 생성하는 문제입니다. 구글의 북미 영어, 중국어 관화 발화 데이터셋을 사용했습니다.

성능 비교를 위한 HMM(Hidden Markov Model), LSTM-RNN 모델과 함께, 서로 다른 지역 조건을 추가한 2개의 WaveNet 모델을 제시합니다.

- WaveNet(L) : Linguistic Features(음소, 음소 길이 등) 를 지역 조건으로 사용
- WaveNet(L+F) : Linguistic Feature 와 로그를 취한 기본 주파수($\log F_0$) 를 지역 조건으로 사용


![[WN_4.png]]
실험 참가자가 생성된 음성에 5단계(1점 - 최저, 5점 - 최고)로 매긴 점수를 평균하는 Mean Opinion Score(MOS) Test 결과입니다. 북미 영어와 중국어 관화에서 다른 모델에 비해 압도적으로 높은 점수를 얻었으며, 실제 음성과 비슷한 수준의 점수를 얻은 것을 확인할 수 있습니다.


![[WN_5.png]]
평가 대상으로 주어진 모델을 쌍으로 묶어 제시했을 때, 더 선호하는 모델을 선택하거나 선호가 없음을 선택하는 Subjective paired comparison test 평가 결과입니다. 기본 주파수를 추가한 WaveNet(L+F)는 WaveNet(L) 에 비교했을 때 조금 더 나은 선호를 보이지만, 두 모델 모두 기존 방법론에 비해서는 압도적인 선호를 보임을 확인할 수 있습니다.

---
**요약**:
WaveNet은 조건을 추가하여 원하는 특성을 지닌 오디오를 생성할 수 있는 구조를 제공합니다. 이를 "Conditional Modeling"이라고 합니다. 조건은 전역적 또는 지역적으로 추가될 수 있습니다. 또한, 논문에서는 다양한 응용 사례와 그 성능을 보여줍니다.



**풀이**:

1. **Conditional WaveNets**: WaveNet은 마치 레시피에 재료를 추가하듯이, 원하는 특성을 지닌 소리를 만들 수 있게 해주는 "조건"을 넣을 수 있어요. 이렇게 조건을 넣는 방법에는 두 가지가 있습니다.
    - **전역 조건**: 모든 소리에 같은 영향을 주는 조건. 예를 들면, 누가 소리를 내는지(발화자) 같은 정보를 넣는 것이죠.
    - **지역 조건**: 소리의 각 부분마다 다른 영향을 주는 조건. 예를 들면, 단어의 발음이나 강세를 조절하는 것입니다.

2. **Multi-Speaker Speech Generation**: 이 부분은 여러 사람의 목소리를 만들어내는 기술을 설명합니다. 특별한 정보(화자의 ID)만 주면, 그 사람의 목소리처럼 들리는 소리를 만들 수 있어요. 이 기술로 109명의 사람들의 목소리를 만들어냈습니다.

3. **Text to Speech**: 이 부분은 글을 읽어서 소리로 변환하는 기술을 설명합니다. 예를 들면, 우리가 스마트폰이나 컴퓨터에 글을 보여주면, 그것을 읽어주는 것이죠. 논문에서는 여러 기술을 비교하며, WaveNet이 어떻게 글을 소리로 잘 바꿔주는지를 보여줍니다.

**중요한 부분**: WaveNet은 다양한 "조건"을 넣어서 원하는 특성의 소리를 만들 수 있습니다. 이 기술은 여러 사람의 목소리를 만들거나, 글을 소리로 읽어주는 등 다양한 곳에서 사용될 수 있습니다.



이 두 모델은 WaveNet의 변형으로, 다양한 정보를 "지역 조건"으로 사용하여 텍스트를 음성으로 변환하는 데 활용됩니다.

1. **WaveNet(L)**:
    - **Linguistic Features**: 여기서의 'Linguistic Features'는 언어와 관련된 특성을 의미합니다. 예를 들면, 음소(소리의 가장 작은 단위)와 그 음소의 길이 등이 포함됩니다. 
    - 이 모델에서는 이러한 언어 특성만을 사용하여 텍스트를 음성으로 변환합니다. 다시 말해, 텍스트에 있는 각 글자나 단어가 어떤 소리로 들릴지를 결정하는 데 이 특성을 사용합니다.

2. **WaveNet(L+F)**:
    - **Linguistic Feature**: 여기서도 언어와 관련된 특성을 사용합니다. 따라서 WaveNet(L)과 동일한 특성이 이 모델에도 적용됩니다.
    - **로그를 취한 기본 주파수 $\log F_0$**: '기본 주파수'는 음성의 피치(높낮이)를 결정하는 주요 요소입니다. $\log F_0$는 이 기본 주파수에 로그(logarithm)를 취한 값입니다. 로그를 취하면 값의 범위가 줄어들어 모델이 더 잘 학습할 수 있습니다.
    - 이 모델에서는 언어 특성뿐만 아니라 음성의 높낮이 정보도 함께 사용하여 텍스트를 음성으로 변환합니다. 이를 통해 생성된 음성이 더 자연스럽게 들릴 수 있습니다.

**요약**:
- WaveNet(L)은 텍스트의 언어적 특성만을 사용하여 음성을 생성합니다.
- WaveNet(L+F)는 언어적 특성과 음성의 높낮이 정보를 함께 사용하여 더 자연스러운 음성을 생성합니다.



---
# Conclusion

원본 오디오 파형을 직접 생성할 수 있는 WaveNet 모델을 제시하였습니다.

Dilated convolution 을 사용하여 인지 범위를 대폭 늘이고, 오디오 신호의 long-range dependency 를 모델링했습니다.

또한 전역/국소 조건을 제시할 수 있는 조건부 모델로, 가장 자연스러운 TTS 음성을 생성했습니다.

이외에도 오디오 신호 모델링과 음성 인식에도 적용할 수 있는 가능성을 확인했습니다.