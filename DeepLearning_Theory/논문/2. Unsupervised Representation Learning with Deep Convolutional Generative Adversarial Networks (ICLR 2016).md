

|                    |                                      |
| ------------------ | ------------------------------------ |
| 태그               | Generative Model                     |
| Description        | DCGAN                                |
| Journal/Conference | ICLR                                 |
| Link               | https://arxiv.org/abs/1511.06434     |
| Year               | 2016                                 |
| 원문 링크          | https://arxiv.org/pdf/1511.06434.pdf |
 





### Deep Convolutional Generative Adversarial Networks
(심층 합성곱 생성적 적대 신경망)


#### $\star$ 요약

DCGAN은 GAN의 개선 모델로 GAN과 다른 점은 다음과 같다

- D(Discriminator)
	- Strided Convolution을 사용
	- Batch Normalization을 사용. 입력 레이어 (첫번째)에는 사용하지 않는다
	- activation function으로 Leaky ReLU를 사용

- G(Generator) 
	- Fractional Strided Convolution(Transposed Convolution)을 사용
	- Batch Normalization을 사용. 출력 레이어(마지막)에는 사용하지 않는다.
	- activation function으로 ReLU를 사용하고 마지막 레이어는 tanh를 사용

$\star$논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미. 이 연산은 convolution의 역연산이 아님



##### 나아진 점 또는 알아낸 것

- 나름 고해상도 이미지 생성 가능

- 거의 대부분의 상황에서 안정적인 학습 가능

- 단순히 이미지를 기억(overfitting)하는 것이 아님을 보여주었다

- convolution의 각 filter는 의미있는 부분에 대한 정보를 갖고 있다.
	- 논문에서는 침실 데이터를 사용하였는데, 어떤 필터는 창문에 대한 정보를 갖고 있는 식 논문에서는 이를 시각화 하여 보여줌

- input인 noise(z)는 생설될 이미지의 특징을 결정하는 벡터. 논문에서는
	- 웃는 여자를 생성한 noize $z_1$
	- 무표정 여자를 생성한 noise $z_2$
	- 무표정 남자를 생성한 noize $z3$
	- $z_4 := z_1 - z_2 + z_3$ 이라 할 때 $z_4$를 noize로 쓰면 웃는 남자를 생성해낸다.

- 왼쪽을 보는 사람과 오른쪽을 보는 사람을 생성한 두 벡터를 interpolationg하면 얼굴을 회전시킨 듯한 중간 결과물이 얻어진다.


DCGAN은 GAN과 학습 방법 자체는 별로 다를 것이 없다(D학습 후 G학습)

$\star$ G로 들어가는 입력 벡터를 뜻하는 Noise는 latent variable이라고도 하며, Auto-encoder에서 출력 영상을 만들기 위한 source와 비슷하기에 이 표현도 사용됨







##### 초록(Abstract)

최근에는 CNN을 통한 supervised learning 연구가 많이 이뤄졌지만 unsupervised learning은 별 주목을 받지 못했다. 우리는 Deep Convolutional CANs를 소개하여 그  간극을 좁히고자 한다. 여러 이미지 데이터셋을 학습시키면서 우리는 DCGAN의 G와 D 모두가 object로부터 유의미한 표현 구조를 찾았음을 보였다. 또, 이를 일반적인(general) 이미지 표현에도 응용해 보았다.






##### 서론(Introduction)

GAN은 최대우도(maximum likehood) 테크닉의 매력적인 대체재이다. 또한 그 학습 방법과 heuristic cost function가 적다는 것 때문에 representation learning에도 훌륭히 잘 쓸 수 있다. 다만 학습이 불한정하고 G가 터무니없는 output을 내뱉을 때가 있다. 그래서 상당히 제한적으로 쓰일 수 밖에 없었다. 

이 논문에서는, 우리는 다음과 같은 것들을 보일 것이다. 

- 거의 대부분의 상황에서 학습이 안정적인 Convolutional GAN을 제안하고 평가한다. 이것이 DCGAN이다.

- D에게 image classification를 시켜봤는데, 거의 state-of-the-art한 결과를 보인다.

- 특정 필터가 특정 object를 그려낸다는 것을 시각화한다.

- G에 들어가는 noise에 산술 연산을 한 결과로 많은 의미있는 이미지를 생성함을 보인다. 





##### 관련 연구(Related Works)

- ##### Representation Learning from Unlabeled Data

	Unsupervised representation learning은 꽤 잘 연구되었다. 전통적인 접근 방법으로는 clustering(K-means)이 있다.

	이미지 쪽에서는 image representation을 학습하기 위한 구조적 clustering, 
	auto-encoder를 학습시키는 것, what/where 분리 구조, image를 간략한 code로 encode하고 다시 이미지로 복원하는 decoder를 포함하는 사다리 구조 등등이 있었다.
	Deep belief networks도 구조적 표현방식을 학습하는 데 좋은 성능을 보였다.


- ##### Generating Natural Images

	이건 두 종류가 있다.
	 - parametric
	 - non-parametric

	database에 존재하는 이미지 찾기 등을 수행하는 non-parametric 모델들은 
	texture synthesis, super-resolution, in-painting등에 사용되었다.

	Parametric 모델은 꽤 널리 알려졌지만 (MNIST), 성공적인 것은 별로 없다 대부분 흐린(blurry) 이미지만을 생성해냈다.

	GAN이 생성한 것은 noise가 많고 이해해가 어려웠다.


- ##### Visualizing the Internals of CNNs

	Neural Networks의 문제점은 너무 black-box같다는 것이다.
	($\star$ 네트워크의 각 필터 등이 정확히 무엇을 의미하는지 사람이 이해할 수 없다)
	다만 각 필터의 의미를 찾으려는 시도는 있었다.







##### 접근법과 모델 아키텍쳐(Approach and Model Architecture)

GAN에 CNN을 써서 이미지 품질을 높이려는 시도는 지금까지 성공적이지 못했다.

우리는 많은 시도 끝에 다양한 데이터셋에서 안정적인 그리고 더 높은 해성도의 이미지를 생성하는 모델 구조를 찾아내었다. 핵심은 다음 3가지를 CNN구조에 적용시키는 것이다.

1. max-pooling 과 같은 미분불가능한 레이어를 strided convolution으로 바꿔 
	spatial downsampling이 가능하게 한 것이다. 이는 G에 사용된 것이고, D에는 unsampling 이 가능하게 바꿨다

2. 요즘 트랜드는 FC(Fully Connected) Layer를 없애고 convolution layer로 바꾸는 것.

3. Batch Normalization을 사용하여 학습을 안정화시킨다
	($\star$ 2019년 현재 BN은 거의 필수처럼 되어 있다.) 
	이는 weight 초기화가 나쁘게 된 경우와 깊은 모델에서 gradient flow를 도우며, 이는 학습 초기에 잘못된 방향으로 학습이 진행되어 망해가는 경우를 막아준다.

	그러나 sample이 요동치는 것을 막기 위해 G의 출력 레어이어와 D의 input layer에는 넣지 않았다.(수많은 시도 끝에 알아냄)


G에서는 activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다. Bounded activation(tanh)은 더 빠르게 수렴하고 학습샘플의 분포를 따라갔다. 
D에는 Leaky ReLU를 사용하여 높은 해상도를 만들 수 있게 하였다. 

이는 GAN과 다른 부분이다. 






##### 적대적 학습 상세(Details of Adversarial Training)

우리는 Large-scale Scene Understanding(LSUN), Imagenet-1K, Faces 데이터 셋으로 학습을 진행했다.

- pre-processing은 쓰지 않았고
- size 128인 mini-batch SGD
- (0, 0.02) 정규분포를 따르는 초기화
- Leaky ReLU의 기울기는 0.2
- Adam Optimizer(0.0002, 0.9)

로 했다. AdamOptimizer의 $\beta_1$을 0.5로 줄이는 것보다 학습 안정성이 좋았다.


모델의 구조는 아래와 같다
![Image](https://drive.google.com/uc?id=1cYKNkriYNvnhjoHIrSBMDxZPzG76FFRY)


단 1 epoch만 학습 시켰을 때의 결과. minibatch SGD를 썻기 떄문에 이미지를 기억한다고는 볼 수 없다. 따라서 overfitting 없이 잘 생성하고 있는 것이다. 
![Image](https://drive.google.com/uc?id=1YfGac38G7P8646l95eGxex898S1c05SP)


5 epoch만 학습시켰을 때의 결과 침대 근처 noise로 볼 때 오히려 underfitting이 일어난 것 같다.
![Image](https://drive.google.com/uc?id=1j7_CHQK2H3LGZVvSRmAmNpMqRa8hvUX8)







##### DCGAN의 능력의 경험적 검증(Empirical Validation of DCGANs Capabilities)

Unsupervised representation learning 알고리즘을 평가하는 일반적인 방법은 
supervised 데이터셋에 대해 특징 추출을 시킨 뒤 performance를 측정하는 것이다.

검증요약:
- CIFAR-10 데이터셋에 대해 검증한 결과 다른 방법들(K-means, Exemplar CNN 등)과 
	비교하여 정확도가 별 차이가 없었다.

- StreetView House Numbers dataset(SVHN)은 state-of-the-art 결과를 얻었다






##### 네트워크 내부 조사 및 시각화(Investigating and Visualizing the Internals of the Networks)

우리는 가장 가까운 학습 데이터 이미지를 찾거나, 최근접 픽셀이나 특징 혹은 
log-likelihood metric 같은 방법은 별로이기 때문에 사용하지 않았다.

생성된 2개의 이미지에 사용된 noise인 $z$ 를 선형 보간하며 그 보간된 $z$ 로 이미지를 생성시켜본  결과 한 이미지에서 다른 이미지로 서서히 변해가는 결과를 얻었다. 
이미지를 보면 창문 없는 방이 거대한 창문이 있는 방으로 변해가거나, TV가 창문으로 변해가는 과정을 볼 수 있다.

![Image](https://drive.google.com/uc?id=1Av-6ZcGlJ4fjEIO6-ZjTmbDItBqFxkgp)



벡터 산술 연산을 통해 
vec(웃는 여자) - vec(무표정 여자) + vec(무표정 남자) = vec(웃는남자)
같은 결과를 얻을 수 있다.
![Image](https://drive.google.com/uc?id=1ubnLZzy9e95Syp-AQdewIVJ8zdwR_gOF)

![Image](https://drive.google.com/uc?id=16wJsIjTD0eOm-P6x3LN8sBigA284Xfka)
![Image](https://drive.google.com/uc?id=17_m7HbJBUy8wYhwKFjHc85FTIeOhjg3W)




네트워크 내부의 각 필터는 이해할 수 없는 형식이 아닌 특정 object나 특징을 추출하였음을 알 수 있다.
![Image](https://drive.google.com/uc?id=1CeH8Aqf-phLeIZi4fTON2FuyJYaSQH7v)








##### 결론 및 추후 연구(Conclusion and future work)

우리는 안정적인 생성모델을 제안하였고 이 적대적 생성모델은 image representation에 탁월함을 보여 주었다. 그러나 아직 오래 학습시킬 시 필터 일부가 요동치는 것 등 모델에 불안정성이 남아 있다.

추후 연구는 이를 안정화하는 방법을 찾는 것이 될 것이다. 또한 이 framework를 영상 또는 음성 등의 다른 domain에도 확장시킬 수 있다.











# 나만의 정리

![[1. DCGAN_Model.png]]


### 요약 

DCGAN은 GAN의 개선 모델로 GAN과 다른 점은 다음과 같다

- D(Discriminator)
	- Strided Convolution을 사용
	- Batch Normalization을 사용. 입력 레이어 (첫번째)에는 사용하지 않는다
	- activation function으로 Leaky ReLU를 사용

- G(Generator) 
	- Fractional Strided Convolution(Transposed Convolution)을 사용
	- Batch Normalization을 사용. 출력 레이어(마지막)에는 사용하지 않는다.
	- activation function으로 ReLU를 사용하고 마지막 레이어는 tanh를 사용

$\star$논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미. 이 연산은 convolution의 역연산이 아님




### GAN Review

![[Data/논문_DCGAN/GAN_Model.png]]

![[Data/논문_DCGAN/이미지 분포.png]]

![[Data/논문_DCGAN/GAN_이론공식.png]]



### 기존 GAN의 한계

1. GAN의 결과가 불안정하다
	- 기존 GAN만 으로는 성능이 잘 나오지 않았다

2. Black-box method
	- Neural Network 자체의 한계라고 볼 수 있는데, 결정 변수나 주요 변수를 알 수 있는 다수의 머신러닝 기법들과 달리 Neural Network는 처음부터 끝까지 어떤 형태로 그러한 결과가 나오게 되었는지 그 과정을 알 수 없다.

3. Generative Model 평가
	- GAN은 결과물 자체가 새롭게 만들어진 Sample이다. 이를 기존 sample과 비교하여 얼마나 비슷한지 확인할 수 있는 정략적 척도가 없고, 사람이 판단하더라도 이는 주관적인 기준이기 때문에 얼마나 정확한지, 혹은 뛰어난지 판단하기 힘들다





### DCGAN의 목표

1. Generator가 단순 기억으로 generate하지 않는다는 것을 보여줘야 한다. 
2.  z(sampling 된 noise vector) 의 미세한 변동에 따른 generator 결과가 연속적으로 부드럽게 이어져야 한다. (이를 walking in the latent space라고 한다.)



### Architecture Guidelines

GAN과 DCGAN의 전체적인 구조는 거의 유사. 
다만 각각의 Discriminator와 Generator의 세부적인 구조가 달라진다.

논문발췌

``` txt
GAN에 CNN을 써서 이미지 품질을 높이려는 시도는 지금까지 성공적이지 못했다.

우리는 많은 시도 끝에 다양한 데이터셋에서 안정적인 그리고 더 높은 해성도의 이미지를 생성하는 모델 구조를 찾아내었다. 핵심은 다음 3가지를 CNN구조에 적용시키는 것이다.

1. max-pooling 과 같은 미분불가능한 레이어를 strided convolution으로 바꿔 
	spatial downsampling이 가능하게 한 것이다. 이는 G에 사용된 것이고, D에는 
	unsampling 이 가능하게 바꿨다

2. 요즘 트랜드는 FC(Fully Connected) Layer를 없애고 convolution layer로 바꾸는 것.

3. Batch Normalization을 사용하여 학습을 안정화시킨다
	(*2019년 현재 BN은 거의 필수처럼 되어 있다.) 
	이는 weight 초기화가 나쁘게 된 경우와 깊은 모델에서 gradient flow를 도우며,
	이는 학습 초기에 잘못된 방향으로 학습이 진행되어 망해가는 경우를 막아준다.

	그러나 sample이 요동치는 것을 막기 위해 G의 출력 레어이어와 D의 input layer에 
	는 넣지 않았다.(수많은 시도 끝에 알아냄)


G에서는 activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다. Bounded activation(tanh)은 더 빠르게 수렴하고 학습샘플의 분포를 따라갔다. 
D에는 Leaky ReLU를 사용하여 높은 해상도를 만들 수 있게 하였다. 

이는 GAN과 다른 부분이다. 
```







### 기존 GAN Architecture

![[gan-architecture.png]]




### GNN Architecture

![[cnn-architecture.png]]




### DCGAN Architecture

DCGAN은 결국, 기존 GAN에 존재했던 fully-connected 구조의 대부분을 CNN구조로 대체한것.

![[Architecture guidelines.png]]

- Discriminator에서는 모든 pooling layers를 strided convolutions로 바꾸고, Generator에서는 pooling layers를 fractional-strided convolution으로 바꾼다.

- Generator와 Discriminator에 batch-normalization을 사용한다. 논문에서는 이를 통해deep generators의 초기 실패를 막는다고 하였다. 그러나 모든 layer에 다 적용하면 sample oscillation과 model instability의 문제가 발생하여 Generator output layer와 Discriminator input layer에는 적용하지 않았다고 한다.

- Fully-connected hidden layers를 삭제한다.

- Generator에서 모든 활성화 함수는 ReLU를 쓰되, 마지막 출력단에서만 Tanh를 사용한다.

- Discriminator에서는 모든 활성화 함수를 LeakyReLU를 사용한다.







#### Strided Convolution이란?
![[padding_strides.gif]]


#### Fractionally-Strided Convolution이란?
![[padding_strides_transposed.gif]]

둘의 차이는 

기존 convolutions는 필터를 거치며 크기가 작아진 반면에 fractionally-strided convolution은 input에 padding을 하고 convolution을 수행하며 오히려 필터가 더 커지는 특징이 차이점 이다.

쉽게 transposed convolution이라고 불린다 논문에서는 Deconvolution이라고 불리는데 이는 잘못된 단어라고 한다.





##### Batch-normalization이란?

Batch Normalization은 최근 거의 모든 인경신경망에 쓰이고 있는 기법으로 기본적으로 Gradient Vanishing / Gradient Exploding이 일어나지 않도록 하는 아이디어 중의 하나이며, 지금까지는 이 문제를 Activation함수의 변화(ReLU 등), Careful Initialization, small learning rate 등으로 해결했지만, 이 논문에서는 이러한 간접적인 방법보다 training하는 과정 자체를 전체적으로 안정화하여 학습 속도를 가속시킬 수 있는 근본적인 방법을 제안하였다.


##### **Gradient Vanishing / Exploding 문제**

신경망에서 학습시 Gradient 기반의 방법들은 파라미터 값의 작은 변화가 신경망 출력에 얼마나 영향을 미칠 것인가를 기반으로 파라미터 값을 학습시키게 된다. 

만약 파라미터 값의 변화가 신경망 결과의 매우 작은 변화를 미치게 될 경우 파라미터를 효과적으로 학습 시킬 수 없게 된다.

**Gradient 라는 것이 결국 미분값 즉 변화량을 의미하는데 이 변화량이 매우 작아지거나(Vanishing) 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, Error rate 가 낮아지지 않고 수렴해버리는 문제가 발생** 하게 된다. 

그래서 이러한 문제를 해결하기 위해서 Sigmoid 나 tanh 등의 활성화 함수들은 매우 비선형적인 방식으로 입력 값을 매우 작은 출력 값의 범위로 squash 해버리는데, 가령 sigmoid는 실수 범위의 수를 [0, 1]로 맵핑해버린다. 

이렇게 출력의 범위를 설정할 경우, 매우 넓은 입력 값의 범위가 극도로 작은 범위의 결과 값으로 매핑된다. 

이러한 현상은 비선형성 레이어들이 여러개 있을 때 더욱 더 효과를 발휘하여(?) 학습이 악화된다. 

**첫 레이어의 입력 값에 대해 매우 큰 변화량이 있더라도 결과 값의 변화량은 극소가 되어버리는 것이다.** 

그래서 이러한 문제점을 해결하기 위해 활성화 함수로 자주 쓰이는 것이 **ReLU(Rectified Linear Unit)** 이다. 또한 아래와 같은 방법들도 존재한다. 

-   **Change activation function** : 활성화 함수 중 Sigmoid 에서 이 문제가 발생하기 때문에 ReLU 를 사용
-   **Careful initialization** : 가중치 초기화를 잘 하는 것을 의미
-   **Small learning rate** : Gradient Exploding 문제를 해결하기 위해 learning rate 값을 작게 설정함





### Generator Model 

![[1. DCGAN_Model.png]]

100 dimensional uniform distribution(Z) 이 들어오면 이들이 4개의 fractionally-strided convolution layer를 거치며 크기를 키워서 더 높은 차원의 64 x 64 pixel 이미지가 된다.




### Visualization 

**Generated bedrooms**
![[3. Figure_3.png]]

**Walking in the latent space**
![[4. Figure_4.png]]

앞서 DCGAN의 목표들 중 하나인 walking in the latent space를 직접 구현한 그림.

생성된 2개의 이미지에 사용된 noise인 $z$ 를 선형 보간하며 그 보간된 $z$ 로 이미지를 생성시켜본  결과 한 이미지에서 다른 이미지로 서서히 변해가는 결과를 얻었다. 
이미지를 보면 창문 없는 방이 거대한 창문이 있는 방으로 변해가거나, TV가 창문으로 변해가는 과정을 볼 수 있다.




**Visualize filters (no longer black-box)**
![[5. Figure_5.png]]
네트워크 내부의 각 필터는 이해할 수 없는 형식이 아닌 특정 object나 특징을 추출하였음을 알 수 있다.




**Applying arithmetic in the input space**
![[8. Glasses.png]]
![[7. Smilling.png]]
벡터 산술 연산을 통해 
vec(웃는 여자) - vec(무표정 여자) + vec(무표정 남자) = vec(웃는남자)
같은 결과를 얻을 수 있다.








reference 
https://angrypark.github.io/generative%20models/paper%20review/2017/08/03/DCGAN-paper-reading/#applying-arithmetic-in-the-input-space

https://www.youtube.com/watch?v=7btUjE2y4NA&t=1023s






