


#### 1. 먼저 해결할 일(task)에 대해 input, output이 무엇인지 분석한다. 

- 분류 문제인가? 회귀 분석 문제인가? 군집화 문제인가?
- 우리가 가지고 있는 데이터와 상호 호환이 되는가?

![](ML_2_1.png)



---
#### 2. 관련된 데이터를 이해한다. (Exploratory data analysis; EDA)

- 데이터의 분포 및 값을 검토
- 데이터에 대한 잠재적인 문제 발견, 본격적인 분석에 들어가기에 앞서 데이터의 수집, 모델링 시 주의할 점 파악 
- 가설 수립(어떤 모델이 보다 좋을 것이다)

![](ML_2_2.png)



---
#### 3. Train, Test 데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평가할 metric을 정의한다. 

- 용어 정의
	- Train set: 머신 러닝 모델의 학습을 위해 사용 
	- Validation set: 학습 중인 모델을 검증하기 위한 데이터 
	- Test set: 학습과 검증이 완료된 모델의 최종적인 성능을 평가

- 기계학습 모델이 Train 데이터로 학습했을 때, 실제 서비스 환경에서는 Train 데이터 들어올까? 
	- NO! 새로운 데이터가 들어온다 

- 실제 기계학습 필드에서는 학습을 한 데이터가 아닌 validation/test 데이털르 추가로 나누어 오버 피팅(과적합) 등 비정상 상태 여부를 파악한다.


- Validation, test가 따로 필요한 이유는 뭘까?
	- Validation set은 학습 중 epoch 단위 등으로 train과정의 중간 과정에서 튜닝을 위해 존재한다.
	- 즉, 이 과정에서 연구자에 의해 validation은 모니터링되고, 모델의 튜닝에 관여할 수 있다. 
	- 또한 validation set은 실험 환경에 따라 test set과 다를 수 있다.(test set은 실제 real - world 환경이여야 한다!)
	- 엄밀하게 구분하기 위해, 최종 평가는 Test set을 통해 진행한다.



---
#### 4. 피처엔지니어링과 모델링을 한다.

- 모델을 평가할 성능 지표(Metrics)을 정의한다. 
	- Classification(분류)
		- Accuracy(정확도), Recall, Precision, Sensitivity, Specificity
		- AUC(Area Under the ROC Curve)
		- F1 Score, Fn Score
		- Cohen's Kappa Coefficient
	
	  - Regression(회귀 분석)
		  - Mean Absolute Error, Root Mean Square Error
		  - R-squared(결정 계수; Coefficient of Determination)
	
	- Clustering(군집화)
		- Silhouette Score
		- Rand Index, Adjusted Rand Index
		- Mutual Information
		- Calinsk-Harabasz Index, Davies-Bouldin Index



---
#### 5. 모델 최적화의 목표인 손실 함수(loss function)를 정의한다.

- 피처 엔지니어링: 데이터의 도메인 지식을 이용하여 머신러닝 알고리즘을 작동시키는 Feature를 만드는 과정
	- 일종의 전처리 과정 
	- 고도화 된 End-to-end 딥러닝 모델의 경우 이 과정이 생략되는 경우도 있음.


- 모델링: 머신러닝 모델을 정의하는 과정



---
#### 6. 목적 함수(objective function)를 최소값으로 최적화(optimization)할 기법을 선택한다 .

- 손실 함수(loss function)이란?
	- 이벤트로 생성된 값과 실제 값 사이의 비용(cost) 즉 차이(loss)를 나타내는 함수
	- 에러 함수(error function), 비용 함수(cost function)도 비슷한 맥락
	- i.e. cross entropy loss, Bayesian expected loss,. logistic loss, L1, L2

- 최적화를 위한 목적 함수(objective funciton)는? 
	- 최적화 알고리즘에 태워지는 궁극적인 함수
	- 보통, 손실 함수 자체이거나 손실 함수의 음수 값 

- 최적화(optimization)문제 란?
	- 최적화 변수 값을 각 탐색 범위 내에서 조절함으로써 주어진 목적함수를 최소화 혹은 최대화하는 해를 찾아내는 기법 
		- 경사 하강법(gradient descent)
		- 뉴턴법 / 뉴턴-랩슨법 (Newton's step, Newton-Raphson)

		- 경사 하강법이 일반적으로 많이 쓰이며, 여러 파생 연구들이 많음 
			- SGD, Adam, Momentum 등 

![](ML_2_3.png)



---
#### 7. 모델 학습을 진행하고, 목표한 대로 나왔는지 확인한다. 

![](ML_2_4.gif)

- Logging system
	- TensorBoard (무료)
	
	- Wandb (유료)

- training error를 작게!
- test error 와 training error의 차이를 작게!
- 부적합 (underfit), 과적합(overfit)은 일어나지 않았는가?

- Recap
	- Underfit(부적합): Train error를 줄이지 못한 경우!
		- 모델의 용량(model capacity)을 키운다

	- Overfit(과적합): Train error는 줄였으나, Test Error가 너무 큰 경우!
		- 일반적으로는, 모델의 용량을 줄인다

![](ML_2_5.png)


- Overfit(과적합)을 방지하려면?
	1. Train data를 많이 모으거나 데이터 증강 기법(data augmentation) (TBD)을 사용한다.
	2. 피처의 개수를 줄여본다 -> 정형화가 쉽게 가능해진다!
	3. Regularization (정형화)을 사용한다. (TBD)

	- Recent view: 딥러닝을 사용하고 데이터가 많으면서 충분히 모델이 깊다면, 보다 더 과적합 시켜도 된다 . => Deep Double Descent(2019) (TBD)

![](ML_2_6.png)


---
#### 8. 1~7을 반복한다.

1. 먼저 해결할 일(task)에 대해 input, output이 무엇인지 분석한다. 

2. 관련된 데이터를 이해한다. (Exploratory data analysis; EDA)

3. Train, Test 데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평할 metric을 정의한다.

4. 피처엔지니어링과 모델링을 한다. 

5. 모델 최적화의 목표인 손실 함수(loss function)를 정의한다. 

6. 목적 함수(objective function)를 최소값으로 최적화(optimization)할 기법을 선택한다. 

7. 모델 학습을 진행하고, 목표한 대로 나왔는지 확인한다.

8. 1 ~ 7을 반복한다. 




---
# 경험적 위험도(empirical risk)와 ML의 일반화(generalization)



- ### 일반화 에러(generalization error), 실제 위험도(true risk)
	
	- 일반적인 지도학습에서, 음수가 아닌 실수(real-value)인 손실 함수(loss)를, 머신 러닝 모델 $f$에 대해서 나타낼 때, $L(f(x), y)$ = $L(\hat y, y)$ 라면,

	  어떤 새로운 데이터 $(x, y)$에 대해, ML모델 $f$의 실제 위험도 (true risk)를 아래와 같이 정의 할 수 있다.
$$R(f) = E[L(f(x), y)] = \int L(f(x), y) dP(x, y) $$
		 이때, 이 값을 일반화 에러(generalization error)라고도 한다.
		 딥러닝을 포함한 머신 러닝의 목표는 일반화 에러를 최소화 하는 최고의 모델 $f$를 찾는것
                                   ![](ML_2_7.png)



- ### 경험적 위험도(empirical risk)
	
	- 그렇지만, 일반적으로 우리는 실제 환경 데이터의 확률 분포 $P(x, y)$를 알지 못한다 즉, 실제 위험도(risk erorr)를 알 수 없다

	  그렇기 때문에 경험적 위험도(empirical risk)를 대신 최소화하여 근사한다.
		                   ![](ML_2_8.png)


	- 이러한 최소화하는 과정을 경험적 위험도 최소화(empirical risk minimization; ERM) 이라고 한다. 
	 
	  ***그러나, 이 경험적 최소화는 '근사'라는 의미처럼, 실제 위험도의 최소화를 의미하지 않는다  $\Rightarrow$ 모델의 검증을 위해 Train외에 Valid / Test 를 따로 하는 이유***



---
#### 7. 모델 학습을 진행하고, 목표한 대로 나왔는지 확인한다.   

- training error를 작게
       => **경험적 위험도(empirical risk)를 줄인다.**

- test error와 training error의 차이를 작게
       => **실제 위험도(true risk)와 training error를 작게**

- 부적합 (underfit), 과적합(overfit)은 일어나지 않았는가?
       => 부적합이 일어났을 때 : training error가 충분히 작아지지 않았을 때
       => 과적합이 있어났을 때 : training error와 test error의 차이가 커졌을 때

 그렇다면 underfit, overfit이 일어났을 때 어떻게 대응해야 할까?
       =>  **모델의 수용량(model capacity)을 조절하자**

![](ML_2_5.png)




- ### 모델 수용량(model capacity)조절.
	
	- 모델 수용량을 조절하는 것은 앞의 모델을 의미하는 $f \in F$ 에서 $F$를 조절한다는 의미 
	
	  $F$ : 가설(모델) $f$ 가 될 수 있는 모든 경우를 나타내는 집합, 가설 공간(hypothesis space)
	  
	  2차원으로 이야기하면, 모델의 학습이 가능하여 최적화가 가능한 부분이 $\theta$ 라고 한다면, 
	  $f(\theta)$ 가 될 수 있는 모든 공간을 가설공간 이라고 할 수 있다.
$$ f(\theta) = \hat y = b + \theta x$$
	 **"$F$  (가설 공간)를 조절한다" 란?**
		 => 다항식의 차수 (다항식의 차수 변경) $$f(\theta) = \hat y = b = \theta_1 x + \theta_2 x^2$$=> Artificial Neural Network 라면, layer의 깊이, 한 레이어에서 뉴런의 수 등


![](ML_2_9.png)

간단한 모델(capacity가 낮은 모델) 일수록 일반화(generalize)가 잘되지만, 보다 나은 성능을 위해 적합한 복잡성을 가진 모델을 골라야 한다.

=> 전형적으로 모델 복잡성이 커지면 커질수록 train error는 한계까지 계속 내려간다















