


#### 1. 먼저 해결할 일(task)에 대해 input, output이 무엇인지 분석한다. 

- 분류 문제인가? 회귀 분석 문제인가? 군집화 문제인가?
- 우리가 가지고 있는 데이터와 상호 호환이 되는가?

![](../../Data/16.이론_ML기초_2/ML_2_1.png)



---
#### 2. 관련된 데이터를 이해한다. (Exploratory data analysis; EDA)

- 데이터의 분포 및 값을 검토
- 데이터에 대한 잠재적인 문제 발견, 본격적인 분석에 들어가기에 앞서 데이터의 수집, 모델링 시 주의할 점 파악 
- 가설 수립(어떤 모델이 보다 좋을 것이다)

![](../../Data/16.이론_ML기초_2/ML_2_2.png)



---
#### 3. Train, Test 데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평가할 metric을 정의한다. 

- 용어 정의
	- Train set: 머신 러닝 모델의 학습을 위해 사용 
	- Validation set: 학습 중인 모델을 검증하기 위한 데이터 
	- Test set: 학습과 검증이 완료된 모델의 최종적인 성능을 평가

- 기계학습 모델이 Train 데이터로 학습했을 때, 실제 서비스 환경에서는 Train 데이터 들어올까? 
	- NO! 새로운 데이터가 들어온다 

- 실제 기계학습 필드에서는 학습을 한 데이터가 아닌 validation/test 데이털르 추가로 나누어 오버 피팅(과적합) 등 비정상 상태 여부를 파악한다.


- Validation, test가 따로 필요한 이유는 뭘까?
	- Validation set은 학습 중 epoch 단위 등으로 train과정의 중간 과정에서 튜닝을 위해 존재한다.
	- 즉, 이 과정에서 연구자에 의해 validation은 모니터링되고, 모델의 튜닝에 관여할 수 있다. 
	- 또한 validation set은 실험 환경에 따라 test set과 다를 수 있다.(test set은 실제 real - world 환경이여야 한다!)
	- 엄밀하게 구분하기 위해, 최종 평가는 Test set을 통해 진행한다.



---
#### 4. 피처엔지니어링과 모델링을 한다.

- 모델을 평가할 성능 지표(Metrics)을 정의한다. 
	- Classification(분류)
		- Accuracy(정확도), Recall, Precision, Sensitivity, Specificity
		- AUC(Area Under the ROC Curve)
		- F1 Score, Fn Score
		- Cohen's Kappa Coefficient
	
	  - Regression(회귀 분석)
		  - Mean Absolute Error, Root Mean Square Error
		  - R-squared(결정 계수; Coefficient of Determination)
	
	- Clustering(군집화)
		- Silhouette Score
		- Rand Index, Adjusted Rand Index
		- Mutual Information
		- Calinsk-Harabasz Index, Davies-Bouldin Index



---
#### 5. 모델 최적화의 목표인 손실 함수(loss function)를 정의한다.

- 피처 엔지니어링: 데이터의 도메인 지식을 이용하여 머신러닝 알고리즘을 작동시키는 Feature를 만드는 과정
	- 일종의 전처리 과정 
	- 고도화 된 End-to-end 딥러닝 모델의 경우 이 과정이 생략되는 경우도 있음.


- 모델링: 머신러닝 모델을 정의하는 과정



---
#### 6. 목적 함수(objective function)를 최소값으로 최적화(optimization)할 기법을 선택한다 .

- 손실 함수(loss function)이란?
	- 이벤트로 생성된 값과 실제 값 사이의 비용(cost) 즉 차이(loss)를 나타내는 함수
	- 에러 함수(error function), 비용 함수(cost function)도 비슷한 맥락
	- i.e. cross entropy loss, Bayesian expected loss,. logistic loss, L1, L2

- 최적화를 위한 목적 함수(objective funciton)는? 
	- 최적화 알고리즘에 태워지는 궁극적인 함수
	- 보통, 손실 함수 자체이거나 손실 함수의 음수 값 

- 최적화(optimization)문제 란?
	- 최적화 변수 값을 각 탐색 범위 내에서 조절함으로써 주어진 목적함수를 최소화 혹은 최대화하는 해를 찾아내는 기법 
		- 경사 하강법(gradient descent)
		- 뉴턴법 / 뉴턴-랩슨법 (Newton's step, Newton-Raphson)

		- 경사 하강법이 일반적으로 많이 쓰이며, 여러 파생 연구들이 많음 
			- SGD, Adam, Momentum 등 

![](../../Data/16.이론_ML기초_2/ML_2_3.png)



---
#### 7. 모델 학습을 진행하고, 목표한 대로 나왔는지 확인한다. 

![](../../Data/16.이론_ML기초_2/ML_2_4.gif)

- Logging system
	- TensorBoard (무료)
	
	- Wandb (유료)

- training error를 작게!
- test error 와 training error의 차이를 작게!
- 부적합 (underfit), 과적합(overfit)은 일어나지 않았는가?

- Recap
	- Underfit(부적합): Train error를 줄이지 못한 경우!
		- 모델의 용량(model capacity)을 키운다

	- Overfit(과적합): Train error는 줄였으나, Test Error가 너무 큰 경우!
		- 일반적으로는, 모델의 용량을 줄인다

![](../../Data/16.이론_ML기초_2/ML_2_5.png)


- Overfit(과적합)을 방지하려면?
	1. Train data를 많이 모으거나 데이터 증강 기법(data augmentation) (TBD)을 사용한다.
	2. 피처의 개수를 줄여본다 -> 정형화가 쉽게 가능해진다!
	3. Regularization (정형화)을 사용한다. (TBD)

	- Recent view: 딥러닝을 사용하고 데이터가 많으면서 충분히 모델이 깊다면, 보다 더 과적합 시켜도 된다 . => Deep Double Descent(2019) (TBD)

![](../../Data/16.이론_ML기초_2/ML_2_6.png)


---
#### 8. 1~7을 반복한다.

1. 먼저 해결할 일(task)에 대해 input, output이 무엇인지 분석한다. 

2. 관련된 데이터를 이해한다. (Exploratory data analysis; EDA)

3. Train, Test 데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평할 metric을 정의한다.

4. 피처엔지니어링과 모델링을 한다. 

5. 모델 최적화의 목표인 손실 함수(loss function)를 정의한다. 

6. 목적 함수(objective function)를 최소값으로 최적화(optimization)할 기법을 선택한다. 

7. 모델 학습을 진행하고, 목표한 대로 나왔는지 확인한다.

8. 1 ~ 7을 반복한다. 













