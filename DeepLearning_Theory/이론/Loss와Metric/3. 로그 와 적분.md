

### 로그 함수의 사용 이유:

1. **확률의 곱을 합으로 변환:** 로그 함수는 곱셈을 덧셈으로 변환하는 성질이 있다. 이는 확률의 곱을 다룰 때 매우 유용하다. 예를 들어, 여러 독립 이벤트의 결합 확률을 모델링할 때 로그 확률의 합으로 표현할 수 있다. 이는 계산을 간소화하고 수치적 안정성을 향상시킨다.

2. **소프트맥스와 크로스 엔트로피:** 다중 클래스 분류에서 소프트맥스 함수와 크로스 엔트로피 손실은 함께 사용된다. 크로스 엔트로피는 예측된 확률 분포와 실제 분포 사이의 차이를 측정하는데, 로그를 사용하여 이 차이를 계산한다. 로그를 사용함으로써, 예측이 틀릴 때 손실이 급격히 증가하는 효과를 만들어내어 모델이 더 정확한 예측을 하도록 돕는다.



### 적분의 사용 이유:

1. **연속 공간에서의 최적화:** 많은 최적화 문제에서는 연속적인 공간에서 파라미터의 최적 값을 찾아야 한다. 적분은 이러한 연속 공간에서 함수의 전체 동작을 이해하는 데 필수적인 도구이다. 예를 들어, 손실 함수의 기댓값을 계산할 때, 전체 입력 공간에 대해 적분을 사용하여 평균 손실을 구할 수 있다.
2. **확률 밀도 함수:** 확률 밀도 함수(probability density function, PDF)를 다룰 때 적분은 전체 확률이 1이 되도록 하는 데 필요하다. 또한, 특정 범위 내의 확률을 구할 때도 적분을 사용한다.



### 수치적 안정성과 계산의 용이성:

- **로그 함수**는 확률이 매우 낮은 이벤트를 다룰 때 수치적 안정성을 제공한다. 확률의 곱이 매우 작아지는 경우, 로그를 취하면 이 값들을 더 안정적으로 다룰 수 있다.
- **적분**은 연속적인 변화를 모델링하고, 평균 손실 같은 값을 정확히 계산하는 데 사용된다. 또한, 확률 분포의 특성을 분석하고 예측에 활용하는 데 필수적이다.




### 로그 함수와 큰 패널티

크로스 엔트로피 손실 함수는 주로 분류 문제에서 모델의 예측 확률과 실제 라벨 사이의 차이를 측정하는 데 사용된다. 이 함수에서 로그의 사용은 다음과 같은 이유로 중요하다:

1. **확률적 예측의 부정확성에 대한 패널티:** 모델이 실제로 발생한 이벤트의 확률을 낮게 예측할수록 (즉, 실제 라벨 $y=1$에 대해 $\hat{y}$가 0에 가까울수록), 로그 함수는 매우 큰 음수값을 반환한다. ($\log(\hat{y})$가 음의 무한대로 감소) 손실 함수에서 이 값을 음수로 곱하면 (즉, $-\log(\hat{y})$, 매우 큰 양의 손실값을 얻게 된다. 이는 모델에게 큰 패널티를 부여하여, 실제로 발생한 이벤트의 확률을 낮게 예측하는 것을 방지한다.

2. **수학적 유도:** 크로스 엔트로피 손실 함수는 정보 이론에서 유래했다. 정보량은 불확실성이 높은 사건이 실제로 발생했을 때 얻는 정보의 양을 측정한다. 이는 $-\log(p)$로 표현되며, 여기서 $p$는 사건의 확률입니다. 크로스 엔트로피는 이 정보량의 기대값을 실제 분포와 예측 분포 사이에서 계산한 것이다.

### 연속적 데이터 분포와 적분

연속적 데이터 분포의 경우, 데이터가 취할 수 있는 값의 범위가 연속적이다. 예를 들어, 사람의 키는 이산적인 값(예: 170cm, 171cm)이 아니라 연속적인 범위(예: 170.1cm, 170.2cm 등)에 걸쳐 있다. 이런 경우, 확률 밀도 함수(probability density function, PDF)를 사용하여 특정 범위 내의 확률을 표현하고, 적분을 사용하여 전체 확률을 계산한다.

적분은 연속적인 함수의 전체 영역에 대한 "합"을 구하는 수학적 방법. 예를 들어, 손실 함수의 기대값을 연속적인 데이터 분포에 대해 계산하고자 할 때, 적분을 사용하여 전체 가능한 값에 대한 손실의 평균을 구할 수 있다.

### 실제 계산 예시

연속적 데이터 분포에서의 평균 제곱 오차(MSE) 기대값 계산은 다음과 같습니다:

$E[(Y-\hat{Y})^2] = \int (y-\hat{y})^2 f(y) dy$

여기서, $f(y)$는 $Y$의 확률 밀도 함수. 이 적분은 모든 가능한 $y$ 값에 대해 $(y-\hat{y})^2$의 가중 평균을 구한다. 가중치는 $y$의 확률 밀도.

### 이산적 데이터 분포와 시그마

이산적 데이터 분포의 경우, 특정 값에 대한 확률을 직접 계산할 수 있으므로, 적분 대신 시그마$\Sigma$ 를 사용하여 확률의 합을 계산한다. 
예를 들어, 주사위 던지기의 결과와 같이 명확하게 구분되는 유한한 결과들 사이의 확률을 계산할 때 시그마를 사용한다.

### 결론
- **로그 함수**는 모델이 정확한 확률을 예측하도록 유도하며, 잘못된 예측에 대해 큰 패널티를 부여
- **적분**은 연속적 데이터 분포에 대한 평균 손실 또는 확률을 계산하는 데 필수적이다. 이산적 데이터에는 시그마를 사용하여 합을 계산.